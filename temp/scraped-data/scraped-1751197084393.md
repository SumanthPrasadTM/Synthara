# Web Scraping Results for: "Generate data for a deep learning model that estimates the amniotic fluid index (AFI) for fetal health analysis.  The dataset should include features like gestational age (in weeks), ultrasound measurements (maximum vertical pocket depth in cm), and AFI (in cm).  Include a categorical variable for fetal health status (e.g., normal, oligohydramnios, polyhydramnios).  Aim for a balanced representation across fetal health status categories."

**Generated on:** 2025-06-29T11:38:04.393Z
**Total Sources:** 3
**Total Content Length:** 3,26,182 characters

## Table of Contents

1. [www.nature.com](#source-1)
2. [onlinelibrary.wiley.com](#source-2)
3. [www.mdpi.com](#source-3)

---

## Source 1: www.nature.com {#source-1}

**URL:** https://www.nature.com/articles/s41467-023-42438-5
**Content Type:** Web Content
**Content Length:** 1,24,770 characters
**Scraped At:** 2025-06-29T11:38:04.391Z

**Detected Structure:** Plain Text

### Content:

[Skip to main content](https://www.nature.com/articles/s41467-023-42438-5#content)

Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
and JavaScript.

Fetal biometry and amniotic fluid volume assessment end-to-end automation using Deep Learning


[Download PDF](https://www.nature.com/articles/s41467-023-42438-5.pdf)

[Download PDF](https://www.nature.com/articles/s41467-023-42438-5.pdf)

## Abstract

Fetal biometry and amniotic fluid volume assessments are two essential yet repetitive tasks in fetal ultrasound screening scans, aiding in the detection of potentially life-threatening conditions. However, these assessment methods can occasionally yield unreliable results. Advances in deep learning have opened up new avenues for automated measurements in fetal ultrasound, demonstrating human-level performance in various fetal ultrasound tasks. Nevertheless, the majority of these studies are retrospective in silico studies, with a limited number including African patients in their datasets. In this study we developed and prospectively assessed the performance of deep learning models for end-to-end automation of fetal biometry and amniotic fluid volume measurements. These models were trained using a newly constructed database of 172,293 de-identified Moroccan fetal ultrasound images, supplemented with publicly available datasets. the models were then tested on prospectively acquired video clips from 172 pregnant people forming a consecutive series gathered at four healthcare centers in Morocco. Our results demonstrate that the 95% limits of agreement between the models and practitioners for the studied measurements were narrower than the reported intra- and inter-observer variability among expert human sonographers for all the parameters under study. This means that these models could be deployed in clinical conditions, to alleviate time-consuming, repetitive tasks, and make fetal ultrasound more accessible in limited-resource environments.

### Similar content being viewed by others

![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41746-024-01406-z/MediaObjects/41746_2024_1406_Fig1_HTML.png)

### [Whole examination AI estimation of fetal biometrics from 20-week ultrasound scans](https://www.nature.com/articles/s41746-024-01406-z?fromPaywallRec=false)

ArticleOpen access11 January 2025

![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-023-44689-0/MediaObjects/41598_2023_44689_Fig1_HTML.png)

### [Transfer learning for accurate fetal organ classification from ultrasound images: a potential tool for maternal healthcare providers](https://www.nature.com/articles/s41598-023-44689-0?fromPaywallRec=false)

ArticleOpen access20 October 2023

![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41746-025-01739-3/MediaObjects/41746_2025_1739_Fig1_HTML.png)

### [Uncovering ethical biases in publicly available fetal ultrasound datasets](https://www.nature.com/articles/s41746-025-01739-3?fromPaywallRec=false)

ArticleOpen access13 June 2025

## Introduction

Ultrasound (US) is a low-cost, non-invasive imaging modality that has been shown to independently reduce fetal mortality by up to 20%[1](https://www.nature.com/articles/s41467-023-42438-5#ref-CR1 "Grytten, J., Skau, I., Sørensen, R. & Eskild, A. Does the use of diagnostic technology reduce fetal mortality? Health Serv. Res. 53, 4437–4459 (2018)."). Yet, 99% of preventable fetal and maternal deaths occur in developing countries where access to fetal ultrasound is scarce and more than a third of operators have no training at all[2](https://www.nature.com/articles/s41467-023-42438-5#ref-CR2 "Wiafe, Y., Odoi, A. & Dassah, E. The role of obstetric ultrasound in reducing maternal and perinatal mortality. Ultrasound Imaging ch. 11, 2 (2011)."), [3](https://www.nature.com/articles/s41467-023-42438-5#ref-CR3 "Carrera, J. M. Obstetric ultrasounds in Africa: is it necessary to promote their appropriate use? Donald Sch. J. Ultrasound Obstet. Gynecol. 5, 289–296 (2011)."). The WHO recommends at least one US examination for each pregnancy[4](https://www.nature.com/articles/s41467-023-42438-5#ref-CR4 "Tunçalp, Ӧ et al. WHO recommendations on antenatal care for a positive pregnancy experience—going beyond survival. BJOG 124, 860–862 (2017)."); however, there is a shortage of physicians and sonographers able to perform this examination primarily in countries of the Global South[5](https://www.nature.com/articles/s41467-023-42438-5#ref-CR5 "Kim, E. T., Singh, K., Moran, A., Armbruster, D. & Kozuki, N. Obstetric ultrasound use in low and middle income countries: a narrative review. Reprod. Health 15, 129 (2018)."). These countries are not the only ones suffering from excessive and increasing fetal and maternal mortality. The USA ranks last amongst industrialized countries in terms of maternal mortality with notable ethnic differences: African-American women are three times more likely to die during pregnancy compared to non-Hispanic White women[6](https://www.nature.com/articles/s41467-023-42438-5#ref-CR6 "Joseph, K. S. et al. Maternal mortality in the United States: recent trends, current status, and future considerations. Obstet. Gynecol. 137, 763–771 (2021)."). Thus, democratizing access to healthcare resources dedicated to fetal and maternal health, regardless of ethnicity, socioeconomic status, or geographic location, is a global healthcare priority.

Two vital and systematic assessments of all routine screening scans are fetal biometry (FB) and amniotic fluid volume (AFV). FB and AFV help detect and manage potential life-threatening conditions. FB is used to determine gestational age (GA), which is essential to guide therapeutic interventions in the case of pre-term labor or pre-eclampsia and detect pregnancy-related complications, such as fetal growth restriction (FGR). FGR, sometimes defined as the “failure of the fetus to meet its growth potential due to a pathological factor”[7](https://www.nature.com/articles/s41467-023-42438-5#ref-CR7 "Melamed, N. et al. FIGO (International Federation of Gynecology and Obstetrics) initiative on fetal growth: best practice advice for screening, diagnosis, and management of fetal growth restriction. Int. J. Gynaecol. Obstet. 152 (Suppl 1), 3–57 (2021)."), is responsible for 30% of all stillbirths and poor neonatal outcomes. Its diagnosis can rely solely on US FB assessment when abdominal circumference (AC) or estimated fetal weight (EFW) falls below the 3rd percentile[8](https://www.nature.com/articles/s41467-023-42438-5#ref-CR8 "Nardozza, L. M. et al. Fetal growth restriction: current knowledge. Arch. Gynecol. Obstet. 295, 1061–1077 (2017)."), [9](https://www.nature.com/articles/s41467-023-42438-5#ref-CR9 "Lees, C. C. et al. ISUOG Practice Guidelines: diagnosis and management of small-for-gestational-age fetus and fetal growth restriction. Ultrasound Obstet. Gynecol. 56, 298–312 (2020)."). AFV abnormalities are strongly associated with increased mortality in the case of low AFV (oligohydramnios)[10](https://www.nature.com/articles/s41467-023-42438-5#ref-CR10 "Morris, R. K. et al. Association and prediction of amniotic fluid measurements for adverse pregnancy outcome: systematic review and meta-analysis. BJOG Int. J. Obstet. Gynaecol. 121, 686–699 (2014)."). The single deepest pocket (SDP) method has been proven to be as reliable as the amniotic fluid index method (AFI) for AFV assessment but to cause fewer false positive diagnoses for oligohydramnios and, therefore, fewer unnecessary labor inductions.

FB coupled with AFV assessments are time-consuming, repetitive, and error-prone tasks, and several studies have stressed the need for quality audits to ensure measurement reproducibility and lower inter and intra-observer variability[11](https://www.nature.com/articles/s41467-023-42438-5#ref-CR11 "Yaqub, M. et al. Quality‐improvement program for ultrasound‐based fetal anatomy screening using large‐scale clinical audit. Ultrasound Obstet. Gynecol. 54, 239–245 (2019)."), [12](https://www.nature.com/articles/s41467-023-42438-5#ref-CR12 "Kilani, R. et al. Inter-observer variability in fetal biometric measurements. Taiwan. J. Obstet. Gynecol. 57, 32–39 (2018)."), [13](https://www.nature.com/articles/s41467-023-42438-5#ref-CR13 "Sande, J. A., Ioannou, C., Sarris, I., Ohuma, E. O. & Papageorghiou, A. T. Reproducibility of measuring amniotic fluid index and single deepest vertical pool throughout gestation. Prenat. Diagn. 35, 434–439 (2015).").

Advances in deep learning (DL) applied to medical imaging have sparked interest in its application to measurement automation in fetal ultrasound, with studies showcasing human-level performances of DL models in standard plane classification and segmentation[14](https://www.nature.com/articles/s41467-023-42438-5#ref-CR14 "Płotka, S. et al. Deep learning fetal ultrasound video model match human observers in biometric measurements. Phys. Med. Biol. 67, 045013 (2022)."), [15](https://www.nature.com/articles/s41467-023-42438-5#ref-CR15 "Zeng, Y., Tsui, P.-H., Wu, W., Zhou, Z. & Wu, S. Fetal ultrasound image segmentation for automatic head circumference biometry using deeply supervised attention-gated V-Net. J. Digit. Imaging 34, 134–148 (2021)."), [16](https://www.nature.com/articles/s41467-023-42438-5#ref-CR16 "Kim, H. P. et al. Automatic evaluation of fetal head biometry from ultrasound images using machine learning. Physiol. Meas. 40, 065009 (2019)."), [17](https://www.nature.com/articles/s41467-023-42438-5#ref-CR17 "Burgos-Artizzu, X. P. et al. Evaluation of deep convolutional neural networks for automatic classification of common maternal fetal ultrasound planes. Sci. Rep. 10, 10200 (2020)."). Most of them are retrospective “in silico” studies conducted on Caucasian populations on fixed images, except for a few exceptions[18](https://www.nature.com/articles/s41467-023-42438-5#ref-CR18 "Pokaprakarn, T. et al. AI estimation of gestational age from blind ultrasound sweeps in low-resource settings. NEJM Evid. 1, 10 (2022)."). To the best of our knowledge, no African team has ever led a study on African patients to automate fetal ultrasound tasks using DL. We believe it to be of the utmost importance that the Global South should not simply import Artificial Intelligence (AI) breakthroughs in medicine from the Global North, but rather developed mindfully, and responsibly by researchers aware of the local constraints and characteristics[19](https://www.nature.com/articles/s41467-023-42438-5#ref-CR19 "Sendra-Balcells, C. et al. Generalisability of fetal ultrasound deep learning models to low-resource imaging settings in five African countries. Sci. Rep. 13, 2728 (2023).").

Furthermore, no previous work has tried to develop an understandable approach to the automation of both tasks respecting the quality guidelines set forth by the International Society of Ultrasound in Obstetrics and Gynecology (ISUOG) for the FB workflow or allowing an end-to-end automation of the AFV assessment workflow, (see Related Methods below for extensive comparison with existing methods). Recent approaches using “blind” cine-loops represent a paradigm shift as they do seem to allow for the democratization of gestational age estimation and their use by minimally trained sonographers but fail to promote both the autonomy and education of the operators[18](https://www.nature.com/articles/s41467-023-42438-5#ref-CR18 "Pokaprakarn, T. et al. AI estimation of gestational age from blind ultrasound sweeps in low-resource settings. NEJM Evid. 1, 10 (2022)."), [20](https://www.nature.com/articles/s41467-023-42438-5#ref-CR20 "Gomes, R. G. et al. A mobile-optimized artificial intelligence system for gestational age and fetal malpresentation assessment. Commun. Med. 2, 1–9 (2022).").

An end-to-end, understandable, FB and AFV assessment workflow automation could not only potentially alleviate practitioners’ burden, increase ultrasound sensitivity and specificity, and even enable minimally trained healthcare workers to perform these measurements in resource-stranded environments but also empower them to learn how to perform these tasks in the absence of such a tool.

Here we train and test DL models, in clinical conditions, to effectively automate these two tasks from standardized free-hand videos.

## Results

### Data

To train and test DL models meant to fully automate FB and AFV assessment, the models were trained on a newly built database of 172,293 de-identified fetal ultrasound images from 12,356 US exams done in six health centers in two different cities in Morocco between 2015 and 2021. In addition, publicly available datasets were used with the following ultrasound machines: General Electric’s Voluson E6, E8, E10, S8, and S10, and Aloka[17](https://www.nature.com/articles/s41467-023-42438-5#ref-CR17 "Burgos-Artizzu, X. P. et al. Evaluation of deep convolutional neural networks for automatic classification of common maternal fetal ultrasound planes. Sci. Rep. 10, 10200 (2020).").

Within the collected data, 30,249 2D standard biometry planes of the abdomen, brain, and femur were preprocessed to extract pixelated annotations. The preprocessing allows it to recognize the region of interest, then to detect the pixelated colored calipers and circumferences to generate the ground truth masks for the abdomen and brain. The femur was annotated directly by the annotators. Optical character recognition (OCR) techniques were used to extract the information and acronyms about the standard plan and the biometric measurements as measured by the doctors during screening. In the end, the annotators validated the extracted masks, standard plan, and measurements (see supplementary information file for details).

In total, fifteen human annotators (ranging from medical students to Radiology and Obstetrics professors) participated in the annotation process using our bespoke annotation platform based on the open-source tool Label Studio version 1.3.0[21](https://www.nature.com/articles/s41467-023-42438-5#ref-CR21 "Tkachenko, M., Malyuk, M., Holmanyuk, A. & Liubimov, N. (2020-2022). Label Studio: Data labeling software. Open source software available from                    https://github.com/heartexlabs/label-studio                                    .") that we adapted to our needs. Each annotation indicated the type of standard plane (abdomen, brain, femur), a polygonal segmentation in the case of the femur, and some of the quality criteria associated with it as described by the ISUOG guidelines[22](https://www.nature.com/articles/s41467-023-42438-5#ref-CR22 "Salomon, L. J. et al. ISUOG Practice guidelines: ultrasound assessment of fetal biometry and growth. Ultrasound Obstet. Gynecol. 53, 715–723 (2019).") (Table [1](https://www.nature.com/articles/s41467-023-42438-5#Tab1)). The annotators made a further distinction between transthalamic, transcerebellar, and transventricular planes. Quality criteria such as the zoom (head, abdomen, femur occupying more than half of the image – caliper placement – the angle of the femur to the horizontal <45°) were omitted in the annotation process. Instead, their detection was automated through fetal structure segmentation: calculating the surface ratio of the structure to the whole image or the angle of the femur to the horizontal to determine conformity to the criteria described by Salomon et al.[23](https://www.nature.com/articles/s41467-023-42438-5#ref-CR23 "Salomon, L. J. et al. Practice guidelines for performance of the routine mid-trimester fetal ultrasound scan. Ultrasound Obstet. Gynecol. 37, 116–126 (2011).") (Table [1](https://www.nature.com/articles/s41467-023-42438-5#Tab1)). That step was designed to ensure that the models select the best suitable plane on a given video loop, detecting the presence or absence of the quality criteria, and displaying them with the measurement, allowing an insight into the model’s choice as well as a correction if necessary.

**Table 1 Criteria for score-based biometry plane assessment developed by Salomon et al.[23](https://www.nature.com/articles/s41467-023-42438-5#ref-CR23 "Salomon, L. J. et al. Practice guidelines for performance of the routine mid-trimester fetal ultrasound scan. Ultrasound Obstet. Gynecol. 37, 116–126 (2011).")**

[Full size table](https://www.nature.com/articles/s41467-023-42438-5/tables/1)

Images were also annotated according to the presence or absence of an AF pocket, defined as an in-utero fluid pocket free of fetal parts or the umbilical cord. In the case of the presence of the AF pocket, annotators were asked to segment it manually.

Figure [1](https://www.nature.com/articles/s41467-023-42438-5#Fig1) shows a summary of the amount of annotated data for the segmentation of the three biometric structures and their classification based on their own quality criteria, along with the number of individual measurements in the annotated data for the classification and segmentation of AF pockets.

**Fig. 1: Summary of the retrospective data used during the segmentation and classification tasks along with the volume of data used for training, validation, and testing.**

[![figure 1](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_Fig1_HTML.png)](https://www.nature.com/articles/s41467-023-42438-5/figures/1)

‘Doctors’ refer to physicians who prospectively and manually annotated standard planes. ‘Semi-automatic’ refers to the process of the standard plane and biometric measurement recognition using Optical Character Recognition, validated by a trained research technician. Helena Pinheiro [https://www.hpinheiro.com/](https://www.hpinheiro.com/) created this illustration.

[Full size image](https://www.nature.com/articles/s41467-023-42438-5/figures/1)

### Segmentation and classification models

We assessed the performances of the segmentation and classification models on the retrospective test sets, comparing them to the experts’ annotations for standard plane detection, quality criteria detection, brain, abdomen, and femur structure segmentation, and AF pocket detection and segmentation.

We used a set of Mask-R-CNN architectures for the standard plane detection and anatomical regions (brain, abdomen, and femur) segmentation[24](https://www.nature.com/articles/s41467-023-42438-5#ref-CR24 "He, K., Gkioxari, G., Dollár, P. & Girshick, R. Mask R-CNN. In 2017 IEEE International Conference on Computer Vision (ICCV) 2980–2988 (Institute of Electrical and Electronics Engineers (IEEE), 2017)."). Mask-R-CNN models are widely used in the state-of-the-art literature. However, the datasets used for training and testing the models were not sufficient to efficiently evaluate their performance and they have been used only for one single task of fetal biometry. For example, Al-Bander et al. and Moccia et al. adapted the Mask-R-CNN architecture to assess HC measurement using the HC18 dataset[25](https://www.nature.com/articles/s41467-023-42438-5#ref-CR25 "Al-Bander, B., Alzahrani, T., Alzahrani, S., Williams, B. M. & Zheng, Y. Improving fetal head contour detection by object localisation with deep learning, Vol. 1065. In Medical Image Understanding and Analysis (eds. Zheng, Y., Williams, B. M. & Chen, K.) 142–150 (Springer Int. Publ., 2020)."), [26](https://www.nature.com/articles/s41467-023-42438-5#ref-CR26 "Moccia, S., Fiorentino, M. C. & Frontoni, E. Mask-R2CNN: a distance-field regression version of Mask-RCNN for fetal-head delineation in ultrasound images. Int. J. CARS 16, 1711–1718 (2021)."). Mask-R-CNN models are generally used, for instance, segmentation. The idea is to train models that can detect two or more instances of an object in the images, for example, two femurs, two heads in the case of twins, or separable regions of the amniotic fluid region. Mask-R-CNN has a backbone architecture with a certain number of network depth features that are taken from a certain number of final convolutional layers on a certain training schedule. The notation used to nominate the architectures used in the experiment is the same used by detectron2[27](https://www.nature.com/articles/s41467-023-42438-5#ref-CR27 "Wu, Y., Kirillov, A., Massa, F., Lo, W.-Y., and Girshick, R. Detectron2 (2019).                    https://github.com/facebookresearch/detectron2                                    ."). For example, R\_50\_C5\_3x is a Mask-R-CNN architecture with ResNet as a backbone. It has 50 depth features taken from the convolutional layer of the fifth stage and a training schedule of 3x, which means 1 iteration every 3 × 12 (36) epochs.

In our study, four Mask-R-CNN models were finetuned (R\_101\_C4\_3x, R\_101\_DC5\_3x, R\_50\_C4\_3x, R\_50\_DC5\_3x) for the segmentation of the brain, abdomen, and femur using 30249 annotated images (10527 brains, 10227 abdomens, and 9495 femurs). The R\_50\_DC5\_3x model achieves the best performance with an average DICE score of 0.89 and an Intersection over Union (IoU) score of 0.82 versus 0.96 and 0.90 respectively, reported with the FUVAI model[14](https://www.nature.com/articles/s41467-023-42438-5#ref-CR14 "Płotka, S. et al. Deep learning fetal ultrasound video model match human observers in biometric measurements. Phys. Med. Biol. 67, 045013 (2022).") (Fig. [2](https://www.nature.com/articles/s41467-023-42438-5#Fig2)). The Segmentation of the brain region achieved the best performance with a DICE score of 0.95 and an IoU of 0.91.

**Fig. 2: Overall DICE and IoU scores of four versions of four finetuned Mask-R-CNN models for the segmentation of the biometric planes.**

[![figure 2](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_Fig2_HTML.png)](https://www.nature.com/articles/s41467-023-42438-5/figures/2)

These models (R\_101\_C4\_3x, R\_101\_DC5\_3x, R\_50\_C4\_3x, R\_50\_DC5\_3x) were trained for the segmentation of the abdominal, femoral, and brain planes on the retrospective test set. The bar plot shows the segmentation performances on the three biometric structures, and the heatmap plots show the DICE (left) and IoU (right) scores per structure. The R\_50\_DC5\_3x model achieves the best performance with a DICE score of 0.89 and an IoU score of 0.82. The segmentation of the brain achieved the best performance with a DICE score of 0.95 and an IoU score of 0.91.

[Full size image](https://www.nature.com/articles/s41467-023-42438-5/figures/2)

For each biometry plane, classification models for quality criteria detection were assessed on the test set of the retrospective data (Fig. [3](https://www.nature.com/articles/s41467-023-42438-5#Fig3)). Assessment of the quality of the standard biometry plane allows for better reproducibility of the AC measurement, we assessed 4 quality criteria (kidneys not visible (A\_KN), plane showing portal sinus (A\_PS), plane showing stomach bubble (A\_SB), symmetrical plane (A\_SYM)) leaving out the image zoom quality criteria that are the only one that is not qualitative and can be inferred directly from the abdomen segmentation. Based on three finetuned models (INCEPTIONV3, RESNET50V2, and VGG16), we obtained F1 scores of 0.81, 0.80, and 0.80, respectively, INCEPTIONV3 shows the best results for all the criteria with an average area under the curve (AUC) of 0.86, and an F1 score of 0.81. The results also show that the A\_SB criterion is detected better compared to other criteria with an AUC of INCEPTIONV3 of 0.93.

**Fig. 3: Comparison of the receiver operating characteristics (ROC) curves of three finetuned models (INCEPTIONV3, RESNET50V2, and VGG16) for the brain and abdominal planes classification using their respective quality criteria.**

[![figure 3](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_Fig3_HTML.png)](https://www.nature.com/articles/s41467-023-42438-5/figures/3)

Overall, the three models show similar results for the cephalic plane quality criteria, and INCEPTIONV3 shows the best results for the abdominal criteria with an average AUC of 0.86. Legends: (kidneys not visible (A\_KN), portal sinus visible (A\_PS), stomach bubble visible (A\_SB), abdominal plane symmetry (A\_SYM), brain plane symmetry (B\_SYM), cerebellum not visible (B\_CB), cavum septum visible (B\_CS), posterior horn of lateral ventricle visible (B\_PVV) and thalami visible (B\_TH)) on the retrospective test set. The top row shows the classification per model, and the bottom row shows the results per quality criteria.

[Full size image](https://www.nature.com/articles/s41467-023-42438-5/figures/3)

For the classification of the brain plane, five quality criteria were assessed: cerebellum not visible (B\_CB), plane showing cavum septum pellucidity (B\_CS), plane showing posterior horn of lateral ventricles (B\_PVV), symmetrical plane (B\_SYM) and plane showing thalami (B\_TH). Similarly, the 3 classification models were finetuned for this task. They show very similar results with an average AUC of 0.83. We obtained F1 scores of 0.66, 0.62, and 0.62 for INCEPTIONV3, RESNET50V2, and VGG16, respectively. The results also show that the B\_CB criterion is well detected compared to other criteria with an AUC of INCEPTIONV3 of 0.95 (Fig. [3](https://www.nature.com/articles/s41467-023-42438-5#Fig3)).

For the femoral plane, the performances of the model designed to detect if both ends of the femur are clearly visible were poor as inter-observer variability was high in the training set; thus, it was not used for image quality scoring. For the femoral plane on the prospective part of the study, the size, subsequent femur to image sizes ratio, and angle of the femur were directly obtained from the femur segmentation stage and kept as the only quality criteria.

For the AF pocket classification, we compared the finetuned models (INCEPTIONV3, RESNET50V2, and VGG16) on the retrospective test set (Fig. [4](https://www.nature.com/articles/s41467-023-42438-5#Fig4)). The results show almost equivalent AUC scores of 0.89, and F1 scores of 0.81, 0.78, and 0.80, respectively. Similarly, we compared seven finetuned Mask-R-CNN models (‘R\_101\_C4\_3x’, ‘R\_101\_DC5\_3x’, ‘R\_101\_FPN\_3x’, ‘R\_50\_C4\_3x’, ‘R\_50\_DC5\_3x’, ‘R\_50\_FPN\_3x’, ‘X\_101\_32x8d\_FPN\_3x’) for the segmentation of the AF pocket region (Fig. [4](https://www.nature.com/articles/s41467-023-42438-5#Fig4)). These models were trained on 3773 images manually annotated with polygons by the experts out of 6199 ones that were annotated as containing AF pocket from the total number of 11926 images.

**Fig. 4: ROC curves and bar plot of the Amniotic Fluid Pocket (AFP) classification and segmentation performances on the retrospective test set.**

[![figure 4](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_Fig4_HTML.png)](https://www.nature.com/articles/s41467-023-42438-5/figures/4)

**a** AUC of three finetuned models for the AFP classification. The results show equivalent AUC scores of 0.89. **b** DICE and IoU scores of seven finetuned Mask-R-CNN models for the AFP segmentation. The results show that ‘X\_101\_32x8d\_FPN\_3x’ achieved the best performance with a DICE score of 0.78 and an IoU of 0.71.

[Full size image](https://www.nature.com/articles/s41467-023-42438-5/figures/4)

The results show that ‘X\_101\_32x8d\_FPN\_3x’ achieved the best performance with a DICE score of 0.78 and an IoU of 0.71 versus a DICE of 0.877 for the state-of-the-art model by Cho et al.[28](https://www.nature.com/articles/s41467-023-42438-5#ref-CR28 "Cho, H. C. et al. Automated ultrasound assessment of amniotic fluid index using deep learning. Med. Image Anal. 69, 101951 (2021).") who tested the model on only 125 images.

In this retrospective study, we adopted the finetuned R\_50\_DC5\_3x model for the segmentation of the brain, abdomen, and femur, the finetuned INCEPTIONV3 models for the quality criteria and the AF pocket detection, and the finetuned X\_101\_32x8d\_FPN\_3x model for the AF pocket segmentation. These models will then be evaluated based on the prospectively acquired data.

### Models performance on the prospective evaluation

From October 2021 to April 2022, 172 patients with singleton pregnancies were included in our prospective study, the average age of the participants was 30.38 years (minimum: 18, maximum: 44, standard deviation: 6.05), most of the included patients did not have any comorbidity (87%), ten patients lived with diabetes mellitus (6%) and three lived with a hypertensive disorder (2%). 34 patients (20%) were nulliparous, 47 (27%) were primiparous, and 91 (53%) were multiparous. Multiple pregnancies were not an exclusion criterion, and patients were included even in the case of partially complete examinations. However, duplicates and patients without an image or cine-loop available or no corresponding ground truth measurement obtained were excluded (Fig. [5](https://www.nature.com/articles/s41467-023-42438-5#Fig5)). In total, the study gathered: 142 different cine-loops containing a femoral plane; 144 containing an abdominal plane; 123 containing a cephalic plane; and 90 containing AF pockets. GA estimation from first-trimester ultrasound from crown-rump length measurement (CRL) was unavailable in almost all cases (see supplementary data [1](https://www.nature.com/articles/s41467-023-42438-5#MOESM4)).

**Fig. 5: Study flow chart.**

[![figure 5](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_Fig5_HTML.png)](https://www.nature.com/articles/s41467-023-42438-5/figures/5)

172 patients were analyzed and 99 were excluded mainly because the measurements corresponding to cine-loops were not saved by the operators ( _n_ = 43), followed by the absence of valid cine-loops recorded ( _n_ = 38), no data recorded during the study ( _n_ = 17) and duplicates ( _n_ = 1).

[Full size image](https://www.nature.com/articles/s41467-023-42438-5/figures/5)

Overall, the mean GA estimated by the operators was of 30 weeks and 3.13 days ± 6 weeks and 3.1 days (range: 15 weeks and 2 days – 41 weeks and 2 days), the mean measured HC, BPD, AC, FL, EFW, and SDP were respectively of 26.37 ± 5.88 cm (range: 11.29–34.71 cm), 7.41 ± 1.72 cm (range: 3.09–10.07 cm), 23.98 ± 6.58 cm (range: 8.95–38.18 cm), 5.28 ± 1.44 cm (range: 1.52–7.86 cm), 1606.78 ± 957.56 g (range: 108.81–3783.86 g) and 5.25 ± 2.22 cm (range: 2.15–17.37 cm).

The US machines and healthcare centers from which the prospective data differed from those of the retrospective data were retained. Three of the four centers where the prospective part of the study was conducted did not participate in the retrospective data collection. Several US machines used in the prospective testing were not present in the retrospective data as well: Mindray DC 40 and Resona 6, Philips Medical Systems Affinity 50 W, 70 G, and GE Voluson P8.

When possible, EFW and GA were computed from all measurements using the recommended Hadlock and Intergrowth formulae[29](https://www.nature.com/articles/s41467-023-42438-5#ref-CR29 "Hadlock, F. P., Harrist, R. B., Sharman, R. S., Deter, R. L. & Park, S. K. Estimation of fetal weight with the use of head, body, and femur measurements—a prospective study. Am. J. Obstet. Gynecol. 151, 333–337 (1985)."), [30](https://www.nature.com/articles/s41467-023-42438-5#ref-CR30 "Papageorghiou, A. T. et al. Ultrasound-based gestational-age estimation in late pregnancy. Ultrasound Obstet. Gynecol. 48, 719–726 (2016).") and all necessary measurements performed by the doctors with the corresponding available cine-loops.

Hadlock formula for EFW estimation[29](https://www.nature.com/articles/s41467-023-42438-5#ref-CR29 "Hadlock, F. P., Harrist, R. B., Sharman, R. S., Deter, R. L. & Park, S. K. Estimation of fetal weight with the use of head, body, and femur measurements—a prospective study. Am. J. Obstet. Gynecol. 151, 333–337 (1985)."):

log10EFW=1.335−0.0034×AC×FL+0.0316×BPD+0.0457×AC+0.1623×FL

Intergrowth recommended formula for GA estimation >14 weeks[30](https://www.nature.com/articles/s41467-023-42438-5#ref-CR30 "Papageorghiou, A. T. et al. Ultrasound-based gestational-age estimation in late pregnancy. Ultrasound Obstet. Gynecol. 48, 719–726 (2016)."):

loge(GA)=0.03243×(logeHC)2+0.001644×FL×logeHC+3.1813

The models segmented each relevant anatomical region and then extracted the planes with the highest composite score, including the quality score according to the ISUOG subjective quality criteria, the zooming of the image inferred from the anatomical segmentation to total image ratio, and the confidence of the model’s prediction (Fig. [6](https://www.nature.com/articles/s41467-023-42438-5#Fig6)).

**Fig. 6: Flow chart of the end-to-end automated extraction of biometric parameters from ultrasound cine-loops.**

[![figure 6](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_Fig6_HTML.png)](https://www.nature.com/articles/s41467-023-42438-5/figures/6)

In every cine-loop, all standard biometry planes are detected, the relevant anatomical structures are segmented, then the quality criteria of each plane are assessed and the highest-scoring plane is selected. There is no quality assessment in the case of the AF volume assessment, the AF pocket with the larger depth is selected from the cine-loop.

[Full size image](https://www.nature.com/articles/s41467-023-42438-5/figures/6)

The models were able to extract measurements from all the videos containing standard biometry planes. The 95% limits of agreement expressed in percentage using the Bland-Altman method were ±0.54% for HC, ±3.74% for BPD, ±0.14 % for AC, ±3.11% for FL, ±1.45% for GA, ±2.42% for EFW, and ±16.96 % for SDP. All percentages found are narrower than reported inter and intra-observer limits of agreements among sonographers (HC: ±3.0%, AC: ±5.3%, FL: ±6.6% for intra-observer difference, and HC: ±4.9%, AC: ±8.8%, FL: ±11.1 for inter-observer difference)[31](https://www.nature.com/articles/s41467-023-42438-5#ref-CR31 "Espinoza, J., Good, S., Russell, E. & Lee, W. Does the use of automated fetal biometry improve clinical workflow efficiency? J. Ultrasound Med. 32, 847–850 (2013).") (Fig. [7](https://www.nature.com/articles/s41467-023-42438-5#Fig7)). Visual assessment of the Bland-Altman plots shows random error for every parameter, the variability increasing with the size of the parameter. However, our results also show constant bias for SDP and FL, the predicted measurements for both parameters being consistently greater than those of the physicians.

**Fig. 7: Bland-Altman plots showing the variability between the models and the doctors HC, FL, EGA, AC, AF (single deepest pocket), BPD, and EFW.**

[![figure 7](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_Fig7_HTML.png)](https://www.nature.com/articles/s41467-023-42438-5/figures/7)

The plots are derived from _n_ = 172 biologically independent samples. The three horizontal lines in each plot represent the mean difference (middle line) and the limits of agreement (upper and lower lines), which are defined as the mean difference plus and minus 1.96 times the standard deviation of the differences. The error bars represent standard deviation (SD). Source data are provided as a Source Data file.

[Full size image](https://www.nature.com/articles/s41467-023-42438-5/figures/7)

This over-expectation of the femur segmentation by the model can be mitigated by reviewing the images manually. By selecting images with abnormal results, we found that the model often selected planes showcasing strictly horizontal femurs and that the predicted calipers were placed to avoid the grand trochanter in accordance with measurement guidelines. Participating physicians did not always follow these guidelines (Fig. [8](https://www.nature.com/articles/s41467-023-42438-5#Fig8))[30](https://www.nature.com/articles/s41467-023-42438-5#ref-CR30 "Papageorghiou, A. T. et al. Ultrasound-based gestational-age estimation in late pregnancy. Ultrasound Obstet. Gynecol. 48, 719–726 (2016).").

**Fig. 8: Examples of larger predicted (left) than measured (right) femur lengths (FL) and single deepest pockets (SDP) in the same study participants.**

[![figure 8](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_Fig8_HTML.png)](https://www.nature.com/articles/s41467-023-42438-5/figures/8)

The femur selected by the model (left) was strictly horizontal, abiding by the quality criteria, as opposed to the femur the physician selected (right). The AF pocket, correctly measured by the model (left), is larger than the one measured by the physician due to an error in caliper placement by the human operator.

[Full size image](https://www.nature.com/articles/s41467-023-42438-5/figures/8)

As for the SDP discrepancy, it appears as though the model actually detected deeper pockets that were not selected or measured by the clinician. However, the model’s failure can also be explained by a slight angulation of the probe from 90° results in a larger anteroposterior pocket diameter at the time of examination which will be construed as the SDP by our approach (Fig. [8](https://www.nature.com/articles/s41467-023-42438-5#Fig8)).

The ICC for each measurement was high (>0.9 for all parameters apart from SDP), showing excellent reliability of the measurements: AC = 0.982, HC = 0.987, BPD = 0.975, FL = 0.945, GA = 0.978, EFW = 0.9713, SDP = 0.692.

The MAE for each biometric parameter was 0.67 ± 0.69 cm for HC, 0.33 ± 0.22 cm for BPD, 0.27 ± 0.40 cm for FL, 0.91 ± 0.81 cm for AC, 9.85 ± 14.36 days for GA, 147.18 ± 177.97 g for the EFW and 1.46 ± 1.10 cm for SDP (Table [2](https://www.nature.com/articles/s41467-023-42438-5#Tab2)).

**Table 2 Table comparing measurements performed by clinicians, our approach, and the FUVAI model**

[Full size table](https://www.nature.com/articles/s41467-023-42438-5/tables/2)

The FUVAI model is the closest one to our approach for end-to-end automated biometric assessment from cine-loops and showed similar performances to those of trained sonographers[14](https://www.nature.com/articles/s41467-023-42438-5#ref-CR14 "Płotka, S. et al. Deep learning fetal ultrasound video model match human observers in biometric measurements. Phys. Med. Biol. 67, 045013 (2022).") (see related methods for more comparisons with existing methods).

We computed the MAE of each parameter using the open-source FUVAI model developed by Płotka et al.[14](https://www.nature.com/articles/s41467-023-42438-5#ref-CR14 "Płotka, S. et al. Deep learning fetal ultrasound video model match human observers in biometric measurements. Phys. Med. Biol. 67, 045013 (2022).") and compared them with our approach (Table [2](https://www.nature.com/articles/s41467-023-42438-5#Tab2)).

It showed inferior MAE compared with our approach for every biometric parameter except for BPD, we hypothesize that this is due to the fact that HC and BPD are measured from the same mask with our approach. However, it was often the case that operators took two distinct images to measure each, hence the difference in performance. We also note that our approach was able to correctly detect the entirety of the corresponding biometry plane while FUVAI failed to do so.

The MAE between the predicted SDP and the measured SDP was also lower than the one reported by Cho et al.[28](https://www.nature.com/articles/s41467-023-42438-5#ref-CR28 "Cho, H. C. et al. Automated ultrasound assessment of amniotic fluid index using deep learning. Med. Image Anal. 69, 101951 (2021).") with their state-of-the-art model for AF pocket segmentation: AF-net (1.46 cm with our approach vs. 2.666 cm for Cho et al.[28](https://www.nature.com/articles/s41467-023-42438-5#ref-CR28 "Cho, H. C. et al. Automated ultrasound assessment of amniotic fluid index using deep learning. Med. Image Anal. 69, 101951 (2021).") on a retrospectively annotated dataset).

There were no cases of oligohydramnios in the prospective set and 7 cases (7.07%) of polyhydramnios. The sensitivity and specificity of the models at detecting polyhydramnios were 86.6%, and 85.7%, respectively, when comparing them to the experts’ estimation.

The models’ estimated biometric parameters were computed during the prospective phase of the study at the earliest time after each examination was complete. No adverse effect was reported during the entirety of this study. Participants were not compensated for their participation in the study.

## Discussion

In this study, we were able to create a successful end-to-end method to automatically estimate FB and AFV from ultrasound cine-loops using the ISUOG quality criteria for standard biometry planes, with results that were similar to those of expert operators. These two tasks are part of the six fundamental items listed by the ISUOG in the recently updated practice guideline for the routine mid-trimester scan[31](https://www.nature.com/articles/s41467-023-42438-5#ref-CR31 "Espinoza, J., Good, S., Russell, E. & Lee, W. Does the use of automated fetal biometry improve clinical workflow efficiency? J. Ultrasound Med. 32, 847–850 (2013)."). They allow early detection of life-threatening conditions such as FGR, oligohydramnios, and polyhydramnios that are associated with increases in the risk of fetal mortality by respectively 19, 5, and 3 fold[32](https://www.nature.com/articles/s41467-023-42438-5#ref-CR32 "Pels, A., Beune, I. M., van Wassenaer‐Leemhuis, A. G., Limpens, J. & Ganzevoort, W. Early‐onset fetal growth restriction: a systematic review on mortality and morbidity. Acta Obstet. Gynecol. Scand. 99, 153–166 (2020)."), [33](https://www.nature.com/articles/s41467-023-42438-5#ref-CR33 "Figueroa, L. et al. Oligohydramnios: a prospective study of fetal, neonatal and maternal outcomes in low-middle income countries. Reprod. Health 17, 19 (2020)."), [34](https://www.nature.com/articles/s41467-023-42438-5#ref-CR34 "Tashfeen, K. & Hamdi, I. M. Polyhydramnios as a predictor of adverse pregnancy outcomes. Sultan Qaboos Univ. Med. J. 13, 57–62 (2013).").

At present, sonographers must navigate through a series of steps to capture the correct anatomical plane. This involves adjusting the probe angle and position to meet the appropriate quality standards, freezing the image, and accurately positioning the calipers. This entire procedure, excluding the assessment of amniotic fluid volume, typically involves an average of 12 steps. The assessment of amniotic fluid volume adds additional steps, as it requires identifying the largest AF pocket, freezing the screen, and then positioning the calipers[31](https://www.nature.com/articles/s41467-023-42438-5#ref-CR31 "Espinoza, J., Good, S., Russell, E. & Lee, W. Does the use of automated fetal biometry improve clinical workflow efficiency? J. Ultrasound Med. 32, 847–850 (2013)."). The method we have developed simplifies this process significantly, enabling reliable biometric tasks to be performed by merely recording the relevant structures. This reduces the process to just three steps: initiating the recording, sweeping through the desired anatomical structure, and concluding the recording. If incorporated into the clinical workflow, this approach has the potential to decrease scanning time, alleviate the workload of sonographers, and ensure the optimal reliability of the measurements taken.

In addition to streamlining the fetal ultrasound, our approach has the potential to serve as an aid to the sonographer in training in the recognition of the quality criteria of each standard biometry plane and gaining independence in their practice.

If deployed in conditions where healthcare workers receive minimal ultrasound training, as is often the case in countries of the Global South, this approach has the potential to help patients receive accurate fetal biometry assessment, gestational age estimation, fetal weight estimation, as well as amniotic fluid volume assessment which in turn are key to diagnosing fetal growth and amniotic fluid volume abnormalities.

Indeed, the 95% limits of agreement expressed in percentage between the models’ measurements and the doctors’ measurements for AC, HC, FL, and SDP were narrower than both reported intra- and inter-observer variability for human expert sonographers[13](https://www.nature.com/articles/s41467-023-42438-5#ref-CR13 "Sande, J. A., Ioannou, C., Sarris, I., Ohuma, E. O. & Papageorghiou, A. T. Reproducibility of measuring amniotic fluid index and single deepest vertical pool throughout gestation. Prenat. Diagn. 35, 434–439 (2015)."), [35](https://www.nature.com/articles/s41467-023-42438-5#ref-CR35 "Sarris, I. et al. Intra- and interobserver variability in fetal ultrasound measurements. Ultrasound Obstet. Gynecol. 39, 266–273 (2012)."). The differences between the US machines, the operators, and the healthcare facilities in the retrospective and the prospective data indicate that the developed models are generalizable. Furthermore, our deterministic method has the advantage of always giving the same output given the same cine-loop, which is not the case for human operators. This means that AI can reliably assess fetal growth status and potentially detect AFV abnormalities on fetal US cine-loops automating the third of the six items showcased in the ISUOG guidelines; and having the potential to address the shortage of sonographers in countries of the Global South.

HC, BPD, AC, and FL have been shown to be more reliable and reproducible amongst expert operators than SDP measurement with intra and inter CC > 0.990 amongst expert sonographers and clinically acceptable 95% limits of agreement[35](https://www.nature.com/articles/s41467-023-42438-5#ref-CR35 "Sarris, I. et al. Intra- and interobserver variability in fetal ultrasound measurements. Ultrasound Obstet. Gynecol. 39, 266–273 (2012)."), [36](https://www.nature.com/articles/s41467-023-42438-5#ref-CR36 "Perni, S. C. et al. Intraobserver and interobserver reproducibility of fetal biometry. Ultrasound Obstet. Gynecol. 24, 654–658 (2004)."). Our models showed intra CC superior to 0.94 for all the biometry metrics (AC = 0.982, HC = 0.987, BPD = 0.975, FL = 0.945) and reached narrower 95% limits of agreement than those reported in studies assessing their reliability and reproducibility between human sonographers.

The models we developed were specifically designed to extract the best biometric planes according to the ISUOG criteria. Although other models have been developed to automate quality control of 2D fetal ultrasound images through anatomical structure recognition, our study is the first to explicitly use the ISUOG quality criteria specifically for biometry plane classification[37](https://www.nature.com/articles/s41467-023-42438-5#ref-CR37 "Zhang, B., Liu, H., Luo, H. & Li, K. Automatic quality assessment for 2D fetal sonographic standard plane based on multitask learning. Medicine 100, e24427 (2021)."), [38](https://www.nature.com/articles/s41467-023-42438-5#ref-CR38 "Wu, L. et al. FUIQA: fetal ultrasound image quality assessment with deep convolutional networks. IEEE Trans. Cybern. 47, 1336–1349 (2017)."). Such an approach, if integrated into the clinical workflow, could be used to automate the biometry plane’s quality control. It could allow fast and inexpensive quality audits, accelerate the workflow of trained sonographers, and be a pedagogical tool to the sonographer in training. This could prove particularly useful in resource-stranded regions such as Africa, where only 38.3% of fetal US operators have received formal training, and only 40.4% of them have received a short theoretical course[3](https://www.nature.com/articles/s41467-023-42438-5#ref-CR3 "Carrera, J. M. Obstetric ultrasounds in Africa: is it necessary to promote their appropriate use? Donald Sch. J. Ultrasound Obstet. Gynecol. 5, 289–296 (2011).").

A similar study to ours compared the performances of a multi-task deep neural network (DNN) on FB assessment, testing it on 50 free-hand ultrasound videos with results comparable to those of trained sonographers. Our models outperformed the one described in the study (FUVAI)[14](https://www.nature.com/articles/s41467-023-42438-5#ref-CR14 "Płotka, S. et al. Deep learning fetal ultrasound video model match human observers in biometric measurements. Phys. Med. Biol. 67, 045013 (2022).") when comparing the proximity of the results showcased by the model versus the sonographers expressed in MAE (Table [2](https://www.nature.com/articles/s41467-023-42438-5#Tab2)) even if the DICE score coefficients and IoU were lower for the same tasks, potentially indicating greater generalizability of our models. FUVAI’s choice of standard biometry planes didn’t rely on the quality of the plane but rather on the confidence of the model when selecting it; in other words, on how closely it resembled images from the training set, which are not necessarily the best standard planes according to the ISUOG guidelines.

Another vast prospective study by Pokaprakarn et al.[18](https://www.nature.com/articles/s41467-023-42438-5#ref-CR18 "Pokaprakarn, T. et al. AI estimation of gestational age from blind ultrasound sweeps in low-resource settings. NEJM Evid. 1, 10 (2022).") took an original approach and assessed the performance of a DNN to estimate GA from blind loops taken by non-trained operators. The DNN proved to be more accurate than expert sonographers at estimating GA with an MAE of 3.9 ± 0.12 days vs 9.85 ± 14.36 days with our approach, which could be a game changer in resource-stranded environments. A recent study using the same dataset from the Fetal Age and Machine Learning Initiative (FAMLI) developed a DL tool to assess fetal biometry and fetal presentation on mobile devices showing non-inferiority to trained sonographers performing the measurements (−1.4 ± 4.5 days)[20](https://www.nature.com/articles/s41467-023-42438-5#ref-CR20 "Gomes, R. G. et al. A mobile-optimized artificial intelligence system for gestational age and fetal malpresentation assessment. Commun. Med. 2, 1–9 (2022)."). These two studies manifest the potential of AI to be used in the clinical workflow to democratize access to quality fetal ultrasound worldwide. However, due to the nature of DNNs and the choice of blind sweeps, it is challenging to get a sense of how the model came up with its output, and impossible to extract AC or EFW for FGR risk assessment. Instead, our models mimic trained sonographers thanks to the separation of the FB workflow into classification, quality scoring, and segmentation tasks. They are thus understandable, with errors in the models’ outputs easily detectable by sonographers.

SDP estimation has the widest variability with reported inter-observer limits of agreement of −51% to +52% and an ICC of 0.42[13](https://www.nature.com/articles/s41467-023-42438-5#ref-CR13 "Sande, J. A., Ioannou, C., Sarris, I., Ohuma, E. O. & Papageorghiou, A. T. Reproducibility of measuring amniotic fluid index and single deepest vertical pool throughout gestation. Prenat. Diagn. 35, 434–439 (2015)."), [39](https://www.nature.com/articles/s41467-023-42438-5#ref-CR39 "Hughes, D. S. et al. Accuracy of the ultrasound estimate of the amniotic fluid volume (amniotic fluid index and single deepest pocket) to identify actual low, normal, and high amniotic fluid volumes as determined by quantile regression. J. Ultrasound Med. 39, 373–378 (2020)."). Our approach for AFV assessment is vastly more reliable, with limits of agreement of only ±16.96 % and an ICC of 0.692 for SDP measurement. This high variability amongst human operators might be explained by the “subjective” choice of the SDP. We brought the subjective choice closer to an objective one by segmenting and measuring every single AF pocket in a given cine-loop. In contrast, several studies present automated techniques to segment AF pockets and measure the pocket’s depth. Cho et al.[33](https://www.nature.com/articles/s41467-023-42438-5#ref-CR33 "Figueroa, L. et al. Oligohydramnios: a prospective study of fetal, neonatal and maternal outcomes in low-middle income countries. Reprod. Health 17, 19 (2020)."), for example, developed a CNN showcasing results similar to those of sonographers in segmenting AF pockets (DICE similarity coefficient: 0.877 ± 0.086) and with an MAE of 2.666 ± 2.986 cm in the measurement of the pocket’s depth versus a DICE score of 0.783 in our study but an MAE of 1.46 ± 1.10 cm on prospectively acquired video loops. A second study by Sun et al.[40](https://www.nature.com/articles/s41467-023-42438-5#ref-CR40 "Sun, S. et al. Complementary network for accurate amniotic fluid segmentation from ultrasound images. IEEE Access 9, 108223–108235 (2021).") complemented the work of Cho et al.[28](https://www.nature.com/articles/s41467-023-42438-5#ref-CR28 "Cho, H. C. et al. Automated ultrasound assessment of amniotic fluid index using deep learning. Med. Image Anal. 69, 101951 (2021).") and developed a dual-path network approach to AF pocket segmentation to better account for reverberation artifacts in AF pockets, achieving a higher DICE similarity coefficient of 0.8599 ± 0.1074 on their dataset. However, both of these studies use 2D fixed images, only automating the segmentation part of the clinical workflow of AFV assessment. Ours proved to be clinically more precise and useful as they detected polyhydramnios with a sensitivity and specificity of 86.6%, and 85.7%, respectively.

As far as we are aware, our research is pioneering in its prospective evaluation of a model designed for estimating Amniotic Fluid Volume (AFV) using ultrasound videos. In practical application, healthcare professionals could verify the image chosen by the model, possibly rectifying any mistakes made either by themselves or the model, or they could browse through the selected pockets until they locate one that meets their satisfaction. Interestingly, this method could also be adapted for AFV evaluation from blind repeated craniocaudal perpendicular sweeps, thereby enabling even healthcare workers with minimal training to execute it.

A potential constraint of our methodology, stemming from the substantial size and computational demands of the models, is the requirement for an Internet connection for their deployment. This restricts their application to regions with Internet availability. Nonetheless, within the realm of telemedicine, Internet connectivity is typically a prerequisite, occasionally depending on a satellite link. Via telemedicine platforms, a proficient sonographer instructs an operator using a video stream of the ultrasound scan. Even under these circumstances, our automated technique can be employed to simplify the capture of ideal measurements and reduce the scan duration, thereby broadening access to quality imaging for prenatal care.

## Methods

In their comprehensive analysis of deep learning algorithms applied to fetal ultrasound-image examination, Fiorentino et al.[41](https://www.nature.com/articles/s41467-023-42438-5#ref-CR41 "Fiorentino, M. C., Villani, F. P., Di Cosmo, M., Frontoni, E. & Moccia, S. A review on deep-learning algorithms for fetal ultrasound-image analysis. Med. Image Anal. 83, 102629 (2023).") highlighted recent advancements in the use of these algorithms for identifying 2D fetal standard planes. Predominantly, the research focused on Convolutional Neural Networks (CNNs) for single-task operations, while some explored multi-task standard plane detection by identifying crucial anatomical structures. For instance, Baumgartner et al.[42](https://www.nature.com/articles/s41467-023-42438-5#ref-CR42 "Baumgartner, C. F. et al. SonoNet: real-time detection and localisation of fetal standard scan planes in freehand ultrasound. IEEE Trans. Med. Imaging 36, 2204–2215 (2017).") adapted the VGG16 architecture to detect 13 fetal standard planes, achieving a mean F1 score of 0.80 with their model, SonoNet. A few authors proposed multi-task models incorporating attention mechanisms for the detection of abdomen, head, and femur standard planes. Cai et al.[43](https://www.nature.com/articles/s41467-023-42438-5#ref-CR43 "Cai, Y. et al. Spatio-temporal visual attention modeling of standard biometry plane-finding navigation. Med. Image Anal. 65, 101762 (2020)."), for example, trained a multi-task neural network with a temporal attention module and achieved F1 scores of 0.84, 0.89, and 0.81, respectively, on a test set of 280 videos lasting 3–7 s.

Fiorentino et al.[41](https://www.nature.com/articles/s41467-023-42438-5#ref-CR41 "Fiorentino, M. C., Villani, F. P., Di Cosmo, M., Frontoni, E. & Moccia, S. A review on deep-learning algorithms for fetal ultrasound-image analysis. Med. Image Anal. 83, 102629 (2023).") also reported on numerous research papers related to 2D fetal biometry estimation, with most focusing on a single structure, such as brain segmentation for HC measurement, abdomen segmentation for AC measurement, and femur segmentation for FL measurement. HC measurement has been the subject of intensive research due to the availability of the publicly annotated dataset HC18, despite the fact that the gold standard for GA and EFW formulae includes other biometric parameters such as AC and FL. Zeng et al.[15](https://www.nature.com/articles/s41467-023-42438-5#ref-CR15 "Zeng, Y., Tsui, P.-H., Wu, W., Zhou, Z. & Wu, S. Fetal ultrasound image segmentation for automatic head circumference biometry using deeply supervised attention-gated V-Net. J. Digit. Imaging 34, 134–148 (2021).") proposed a modified version of V-Net that incorporates an attention mechanism and achieved a Dice score of 0.98 and an MAE of 1.95 mm. Similarly, Moccia et al.[26](https://www.nature.com/articles/s41467-023-42438-5#ref-CR26 "Moccia, S., Fiorentino, M. C. & Frontoni, E. Mask-R2CNN: a distance-field regression version of Mask-RCNN for fetal-head delineation in ultrasound images. Int. J. CARS 16, 1711–1718 (2021).") adapted a Mask-R-CNN method and achieved comparable results with a Dice score of 0.98 and an MAE of 1.95 mm. Notably, only one study reported in the review used videos for the prospective evaluation of models for BPD and HC measurements[44](https://www.nature.com/articles/s41467-023-42438-5#ref-CR44 "Rasheed, K., Junejo, F., Malik, A. & Saqib, M. Automated fetal head classification and segmentation using ultrasound video. IEEE Access 9, 160249–160267 (2021)."). In contrast, very few papers have addressed abdomen and femur segmentation for AC and LF measurements, respectively. Using small datasets, Kim et al.[16](https://www.nature.com/articles/s41467-023-42438-5#ref-CR16 "Kim, H. P. et al. Automatic evaluation of fetal head biometry from ultrasound images using machine learning. Physiol. Meas. 40, 065009 (2019).") proposed an abdomen segmentation model that achieved a Dice score of 0.92, while Zhu et al.[45](https://www.nature.com/articles/s41467-023-42438-5#ref-CR45 "Zhu, F. et al. Automatic measurement of fetal femur length in ultrasound images: a comparison of random forest regression model and SegNet. Math. Biosci. Eng. 18, 7790–7805 (2021).") proposed a femur segmentation model that achieved a Dice score of 0.92 and an MAE of 0.46 mm.

Most methods employed U-Net-based architectures, which are known for their semantic segmentation performance. However, Mask-R-CNN-based architectures were also utilized, as they allow for the segmentation of individual objects and the assessment of classification performance. Recently, some researchers have attempted a different approach, directly extrapolating measurements using regression models rather than running a segmentation model first and then approximating the measurement. To our knowledge, this approach has only been tested for HC estimation[46](https://www.nature.com/articles/s41467-023-42438-5#ref-CR46 "Li, P., Zhao, H., Liu, P. & Cao, F. Automated measurement network for accurate segmentation and parameter modification in fetal head ultrasound images. Med. Biol. Eng. Comput. 58, 2879–2892 (2020).").

Very few papers have focused on multiple biometry estimation. To our knowledge, only one paper proposed a method for segmenting multiple anatomical structures for fetal biometry[14](https://www.nature.com/articles/s41467-023-42438-5#ref-CR14 "Płotka, S. et al. Deep learning fetal ultrasound video model match human observers in biometric measurements. Phys. Med. Biol. 67, 045013 (2022)."). The authors proposed the FUVAI model, which combined U-Net with ConvLSTM architectures and was trained on a large private dataset to estimate HC, AC, and FL measurements using 274,275 2D ultrasound images. The model was tested on 57,001 2D images and achieved a Dice score of 0.96 and an MAE of 2.5 mm.

For 2D amniotic fluid volume (AFV) assessment, Fiorentino et al. reported only three research papers[28](https://www.nature.com/articles/s41467-023-42438-5#ref-CR28 "Cho, H. C. et al. Automated ultrasound assessment of amniotic fluid index using deep learning. Med. Image Anal. 69, 101951 (2021)."), [40](https://www.nature.com/articles/s41467-023-42438-5#ref-CR40 "Sun, S. et al. Complementary network for accurate amniotic fluid segmentation from ultrasound images. IEEE Access 9, 108223–108235 (2021)."), [47](https://www.nature.com/articles/s41467-023-42438-5#ref-CR47 "Li, Y., Xu, R., Ohya, J. & Iwata, H. Automatic fetal body and amniotic fluid segmentation from fetal ultrasound images by encoder-decoder network with inner layers. In 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) 1485–1488 (Institute of Electrical and Electronics Engineers (IEEE), 2017)."). Using just 310 2D images, Cho et al. trained an adapted U-Net architecture called AF-Net and evaluated it on a test set of 125 2D images, achieving a Dice score of 0.87 and an MAE of 2.6 cm[28](https://www.nature.com/articles/s41467-023-42438-5#ref-CR28 "Cho, H. C. et al. Automated ultrasound assessment of amniotic fluid index using deep learning. Med. Image Anal. 69, 101951 (2021).").

The use of different private datasets for evaluating these approaches, combined with the lack of public datasets, makes comparison challenging. All of the best performances were achieved using large, private datasets[42](https://www.nature.com/articles/s41467-023-42438-5#ref-CR42 "Baumgartner, C. F. et al. SonoNet: real-time detection and localisation of fetal standard scan planes in freehand ultrasound. IEEE Trans. Med. Imaging 36, 2204–2215 (2017)."), [43](https://www.nature.com/articles/s41467-023-42438-5#ref-CR43 "Cai, Y. et al. Spatio-temporal visual attention modeling of standard biometry plane-finding navigation. Med. Image Anal. 65, 101762 (2020)."), [48](https://www.nature.com/articles/s41467-023-42438-5#ref-CR48 "Prieto, J. C. et al. An automated framework for image classification and segmentation of fetal ultrasound images for gestational age estimation. Proc. SPIE Int. Soc. Opt. Eng. 11596, 115961N (2021)."), [49](https://www.nature.com/articles/s41467-023-42438-5#ref-CR49 "Płotka, S. et al. FetalNet: Multi-task deep learning framework for fetal ultrasound biometric measurements. In Neural Information Processing. ICONIP. Communications in Computer and Information Science, Vol. 1517 (eds. Mantoro, T., Lee, M., Ayu, M. A., Wong, K. W. & Hidayanto, A. N.) (Springer, Cham, 2021)."), indicating that a data-centric approach leads to better generalization. However, very few studies have focused on multi-organ analysis and end-to-end pipelines, with a lack of interpretation of results. Most are retrospective “in silico” studies conducted on Caucasian populations. To our knowledge, no research has proposed end-to-end pipelines for multiple fetal biometry structure segmentation, standard plan classification, and quality criteria assessments following ISUOG guidelines. Furthermore, our AFV assessment outperforms state-of-the-art results and is the first to be integrated and validated with a prospective study from cine-loops designed for minimally trained healthcare workers. Additionally, no prior prospective study has aimed to automate FB and AFV assessment using a large dataset of 2D ultrasound images of African patients examined in low-resource settings (see supplementary information file for details).

### Models and training

In the training of the seven Mask-R-CNN models, we adopted an image-centric training procedure[12](https://www.nature.com/articles/s41467-023-42438-5#ref-CR12 "Kilani, R. et al. Inter-observer variability in fetal biometric measurements. Taiwan. J. Obstet. Gynecol. 57, 32–39 (2018)."). Images were resized such that their scale (shorter edge) is 800 pixels[27](https://www.nature.com/articles/s41467-023-42438-5#ref-CR27 "Wu, Y., Kirillov, A., Massa, F., Lo, W.-Y., and Girshick, R. Detectron2 (2019).                    https://github.com/facebookresearch/detectron2                                    ."). PyTorch (version 1.10) framework was used for model training, validation, and testing. The models were trained with 80% of the data, validated with 10%, and tested with 10%. We trained on the NVIDIA Tesla K80 GPU for 2000 iterations, with a learning rate of 0.01 which was decreased by ten at the 500 iterations. We used a weight decay of 0.0001 and a momentum of 0.9. The used loss function is similar to the one described in Ref. [24](https://www.nature.com/articles/s41467-023-42438-5#ref-CR24 "He, K., Gkioxari, G., Dollár, P. & Girshick, R. Mask R-CNN. In 2017 IEEE International Conference on Computer Vision (ICCV) 2980–2988 (Institute of Electrical and Electronics Engineers (IEEE), 2017)."). It combines the classification loss, the bounding-box loss, and the average binary cross-entropy loss of the mask.

In the training of the three classification models to infer the quality criteria of the abdomen and brain plans and to classify 11926 annotated images as containing AF pockets or not, the fully connected top layers were first replaced by an average pooling layer, then followed by a dense layer with a sigmoid activation function containing four outputs for the abdomen model, five outputs for the brain model and two outputs for the AF pocket model. TensorFlow (version 2.0) was used for model training, validation, and testing. We used 60% of the data for training, 20% for validation, and 20% for testing. The input images were resized to 224 × 224 pixels for the VGG16 model and to 299 × 299 for INCEPTIONV3 and RESNET50V2. For the brain and abdomen quality criteria classification, these images were first cropped based on their corresponding masks and then resized. The models were trained on the NVIDIA Tesla K80 GPU until convergence over 100 epochs using a batch size of 32 and an initial learning rate of 10−3 that is reduced by a factor of 0.2 once learning stagnates. The training is stopped early when there is no improvement in the validation loss for the last 15 epochs, or when we reach 100 epochs. We use binary cross-entropy loss and Adam as the optimizer of Keras (version 2.3.1). To prevent overfitting, we apply, on the fly, various data augmentation techniques using the following transformations: rotation between −15 and 15 degrees, zoom by 10%, brightness range between 0.2 and 0.8, as well as horizontal and vertical flipping.

From the training results of all these models, we adopted the R\_50\_DC5\_3x model for the segmentation of the brain, abdomen, and femur, the INCEPTIONV3 models for the quality criteria classification and the AF pocket detection, and X\_101\_32x8d\_FPN\_3x model for the segmentation of AF pocket.

### Approximations of the biometric measurements

The biometric measurements are extracted from the output masks of the segmentation models. For the abdomen and brain, AC and HC are computed from the circumferences of the ellipses approximated by first, finding the contours and then direct least square fitting[42](https://www.nature.com/articles/s41467-023-42438-5#ref-CR42 "Baumgartner, C. F. et al. SonoNet: real-time detection and localisation of fetal standard scan planes in freehand ultrasound. IEEE Trans. Med. Imaging 36, 2204–2215 (2017)."), [43](https://www.nature.com/articles/s41467-023-42438-5#ref-CR43 "Cai, Y. et al. Spatio-temporal visual attention modeling of standard biometry plane-finding navigation. Med. Image Anal. 65, 101762 (2020)."). BPD is the minor axis of the brain ellipse. For the femur, FL represents the measure of the major axis of the extremities bounding box, and for the AF pocket, the SDP is the measure of the vertical axis of the bounding box. After the measurements are approximated in pixels, they are converted into centimeters using the DICOM’s pixel spacing tag (see supplementary information file for details).

### Study design

We validated the DL models on prospectively consecutively acquired transabdominal US videos from pregnant patients (>18 years, evolutive pregnancy >14 weeks, non-emergency related scan indication,) gathered at four healthcare centers in Morocco (Casablanca and Oujda) from October 2021 to April 2022 by 7 different radiologists and obstetricians (experience in fetal US > 10 years) and annotated during the examination using the machine’s ellipse and caliper facilities. The participating physicians were asked to measure HC, BPD, AC, and FL following the ISUOG criteria as well as the single deepest AF pocket (SDP) to assess AFV.

On top of their routine examination, the physicians had to take four additional cine-loops: three additional cine-loops containing all the standard biometry planes, and a cine-loop containing all AF pockets: an axial cephalic loop going from the base of the skull to the vertex, an axial abdominal loop going from the four-chamber view of the heart to a cross-section of the kidneys, a sagittal femur loop, and an amniotic loop sweeping perpendicularly through all the right, then the left AF pockets (Fig. [1](https://www.nature.com/articles/s41467-023-42438-5#Fig1)).

The physicians had no knowledge of the predicted values for all biometric parameters until the end of the study, the team evaluating the models’ performances was also tasked to gather the prospective data and hence had access to the predicted and measured values for each. The biometric parameters were inferred by the models at the end of the study, seven months after its beginning. On the modeling side, the best segmentation and classification models that were trained on retrospective data were run on each video to extract HC, BPD, AC, or FL measurements depending on the plane. All the detected AF pockets on the “amniotic” cine-loops were segmented and their depth was computed, retaining the deepest one as the predicted SDP. This approach is directly inspired by the standard steps taken by expert-trained sonographers to select the single deepest pocket. They consist of the following tasks: (1) Sweep through all AF pockets, (2) Subjectively select the SDP, and (3) Measure the SDP’s depth. Oligohydramnios was defined as an SDP < 2 cm and polyhydramnios as an SDP > 8 cm[50](https://www.nature.com/articles/s41467-023-42438-5#ref-CR50 "Kehl, S. et al. Single deepest vertical pocket or amniotic fluid index as evaluation test for predicting adverse pregnancy outcome (SAFE trial): a multicenter, open-label, randomized controlled trial. Ultrasound Obstet. Gynecol. 47, 674–679 (2016).").

The primary outcomes were the models performances in fetal biometry and single deepest pocket measurements, expressed in mean absolute error, limits of agreement with the sonographers, and Intraclass correlation coefficients.

The secondary outcomes were the performances of the models at detecting AFV and fetal growth abnormalities (FGR) using sensitivity, and specificity metrics.

This study follows the STARD 2015 guidelines[51](https://www.nature.com/articles/s41467-023-42438-5#ref-CR51 "Bossuyt, P. M. et al. STARD 2015: an updated list of essential items for reporting diagnostic accuracy studies. BMJ 351, h5527 (2015).") as detailed in the supplementary information STARD checklist.

Approval for this study was granted by the Institutional Review Board of Oujda’s Faculty of Medicine (Comité d’Ethique pour la Recherche Biomédicale d’Oujda). Study participants provided their informed written consent and were not compensated for their participation to this study.

The full protocol of this study can be found on clinicaltrials.gov under the ID: NCT05059093.

### Evaluation and statistical analysis

DICE score coefficients and Intersection of Union (IoU) were computed for the Mask-RCNNs on the retrospective dataset. For the classification tasks, the receiving operating characteristics (ROC) curves were computed.

The intended sample size was estimated at 122 patients with all corresponding measurements and cine-loops correctly performed (see supplementary information file: Sample Size Estimation, for more details). We computed the mean absolute errors (MAE) between the models’ measurements and the operators on the prospective cine-loops using the R package ‘Metrics’ (version 0.1.4) of R software (R version 4.2.1). Intraclass correlation coefficients (ICC) were calculated using the Package ‘merTools’ (version 0.5.2). ICC is a desirable measure of reliability that reflects both the degree of correlation and agreement between measurements. Wilcoxon rank sum test was calculated for each measurement using the ‘PairedData’ (version 1.1.1) R package. We also compared the performance of our approach to the FUVAI[14](https://www.nature.com/articles/s41467-023-42438-5#ref-CR14 "Płotka, S. et al. Deep learning fetal ultrasound video model match human observers in biometric measurements. Phys. Med. Biol. 67, 045013 (2022).") model using the percentage of correctly classified planes and MAE using the R package ‘Metrics’ (version 0.1.4). Bland-Altman plots were used for the visual assessment of the models’ reliability and the 95% limits of agreement were calculated and expressed in percentage using the ‘blandr’ package (version 0.5.1) of the R software. Firstly, The measurements from the operators and the model were passed to the blandr.statistics function to generate Bland-Altman statistics. After which, plots were generated using the package ggplot2 (version 3.3.6). Assessment of the models’ performances was carried out alongside prospective data collection.

### Reporting summary

Further information on research design is available in the [Nature Portfolio Reporting Summary](https://www.nature.com/articles/s41467-023-42438-5#MOESM5) linked to this article.

## Data availability

Source data are provided with this paper. Part of the de-identified fetal ultrasound data used in this study comes from a publicly available dataset on Zenodo published by Burgos-Artizzu, X. P. et al.[17](https://www.nature.com/articles/s41467-023-42438-5#ref-CR17 "Burgos-Artizzu, X. P. et al. Evaluation of deep convolutional neural networks for automatic classification of common maternal fetal ultrasound planes. Sci. Rep. 10, 10200 (2020).") available at [https://zenodo.org/record/3904280](https://zenodo.org/record/3904280). The rest of the de-identified fetal ultrasound data collected for the purpose of this study is available under restricted access due to privacy, ethical and legal considerations, access can be obtained by contacting the corresponding author at saadslimani@deepecho.io who will provide a response within 14 days and supply the data use agreement limiting its use to non-commercial research purposes.

## Code availability

The pre-trained models used in this study are available publicly: Classification models codes are available here: [https://github.com/keras-team/keras/tree/v2.13.1/keras/applications](https://github.com/keras-team/keras/tree/v2.13.1/keras/applications). Segmentation models were developed using detectron2, available here: [https://github.com/facebookresearch/detectron2/](https://github.com/facebookresearch/detectron2/). The corresponding author will provide their finetuned weights of the models used in this study, for research and reproducibility purposes upon request at saad.slimani@deepecho.io within 14 days, subject to a data use agreement for non-commercial use.

## References

01. Grytten, J., Skau, I., Sørensen, R. & Eskild, A. Does the use of diagnostic technology reduce fetal mortality? _Health Serv. Res._ **53**, 4437–4459 (2018).

    [Article](https://doi.org/10.1111%2F1475-6773.12721) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=29349772) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6232411) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Does%20the%20use%20of%20diagnostic%20technology%20reduce%20fetal%20mortality%3F&journal=Health%20Serv.%20Res.&doi=10.1111%2F1475-6773.12721&volume=53&pages=4437-4459&publication_year=2018&author=Grytten%2CJ&author=Skau%2CI&author=S%C3%B8rensen%2CR&author=Eskild%2CA)

02. Wiafe, Y., Odoi, A. & Dassah, E. The role of obstetric ultrasound in reducing maternal and perinatal mortality. _Ultrasound Imaging_ ch. 11, 2 (2011).

03. Carrera, J. M. Obstetric ultrasounds in Africa: is it necessary to promote their appropriate use? _Donald Sch. J. Ultrasound Obstet. Gynecol._ **5**, 289–296 (2011).

    [Article](https://doi.org/10.5005%2Fjp-journals-10009-1205) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Obstetric%20ultrasounds%20in%20Africa%3A%20is%20it%20necessary%20to%20promote%20their%20appropriate%20use%3F&journal=Donald%20Sch.%20J.%20Ultrasound%20Obstet.%20Gynecol.&doi=10.5005%2Fjp-journals-10009-1205&volume=5&pages=289-296&publication_year=2011&author=Carrera%2CJM)

04. Tunçalp, Ӧ et al. WHO recommendations on antenatal care for a positive pregnancy experience—going beyond survival. _BJOG_ **124**, 860–862 (2017).

    [Article](https://doi.org/10.1111%2F1471-0528.14599) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=28190290) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=WHO%20recommendations%20on%20antenatal%20care%20for%20a%20positive%20pregnancy%20experience%E2%80%94going%20beyond%20survival&journal=BJOG&doi=10.1111%2F1471-0528.14599&volume=124&pages=860-862&publication_year=2017&author=Tun%C3%A7alp%2C%D3%A6)

05. Kim, E. T., Singh, K., Moran, A., Armbruster, D. & Kozuki, N. Obstetric ultrasound use in low and middle income countries: a narrative review. _Reprod. Health_ **15**, 129 (2018).

    [Article](https://link.springer.com/doi/10.1186/s12978-018-0571-y) [CAS](https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXksVOjur0%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=30029609) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6053827) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Obstetric%20ultrasound%20use%20in%20low%20and%20middle%20income%20countries%3A%20a%20narrative%20review&journal=Reprod.%20Health&doi=10.1186%2Fs12978-018-0571-y&volume=15&publication_year=2018&author=Kim%2CET&author=Singh%2CK&author=Moran%2CA&author=Armbruster%2CD&author=Kozuki%2CN)

06. Joseph, K. S. et al. Maternal mortality in the United States: recent trends, current status, and future considerations. _Obstet. Gynecol._ **137**, 763–771 (2021).

    [Article](https://doi.org/10.1097%2FAOG.0000000000004361) [CAS](https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BB3sfosleguw%3D%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=33831914) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8055191) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Maternal%20mortality%20in%20the%20United%20States%3A%20recent%20trends%2C%20current%20status%2C%20and%20future%20considerations&journal=Obstet.%20Gynecol.&doi=10.1097%2FAOG.0000000000004361&volume=137&pages=763-771&publication_year=2021&author=Joseph%2CKS)

07. Melamed, N. et al. FIGO (International Federation of Gynecology and Obstetrics) initiative on fetal growth: best practice advice for screening, diagnosis, and management of fetal growth restriction. _Int. J. Gynaecol. Obstet._ **152** (Suppl 1), 3–57 (2021).

    [Article](https://doi.org/10.1002%2Fijgo.13522) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=33740264) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8252743) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=FIGO%20%28International%20Federation%20of%20Gynecology%20and%20Obstetrics%29%20initiative%20on%20fetal%20growth%3A%20best%20practice%20advice%20for%20screening%2C%20diagnosis%2C%20and%20management%20of%20fetal%20growth%20restriction&journal=Int.%20J.%20Gynaecol.%20Obstet.&doi=10.1002%2Fijgo.13522&volume=152&pages=3-57&publication_year=2021&author=Melamed%2CN)

08. Nardozza, L. M. et al. Fetal growth restriction: current knowledge. _Arch. Gynecol. Obstet._ **295**, 1061–1077 (2017).

    [Article](https://link.springer.com/doi/10.1007/s00404-017-4341-9) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=28285426) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Fetal%20growth%20restriction%3A%20current%20knowledge&journal=Arch.%20Gynecol.%20Obstet.&doi=10.1007%2Fs00404-017-4341-9&volume=295&pages=1061-1077&publication_year=2017&author=Nardozza%2CLM)

09. Lees, C. C. et al. ISUOG Practice Guidelines: diagnosis and management of small-for-gestational-age fetus and fetal growth restriction. _Ultrasound Obstet. Gynecol._ **56**, 298–312 (2020).

10. Morris, R. K. et al. Association and prediction of amniotic fluid measurements for adverse pregnancy outcome: systematic review and meta-analysis. _BJOG Int. J. Obstet. Gynaecol._ **121**, 686–699 (2014).

    [Article](https://doi.org/10.1111%2F1471-0528.12589) [CAS](https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BC2cnktlKlsQ%3D%3D) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Association%20and%20prediction%20of%20amniotic%20fluid%20measurements%20for%20adverse%20pregnancy%20outcome%3A%20systematic%20review%20and%20meta-analysis&journal=BJOG%20Int.%20J.%20Obstet.%20Gynaecol.&doi=10.1111%2F1471-0528.12589&volume=121&pages=686-699&publication_year=2014&author=Morris%2CRK)

11. Yaqub, M. et al. Quality‐improvement program for ultrasound‐based fetal anatomy screening using large‐scale clinical audit. _Ultrasound Obstet. Gynecol._ **54**, 239–245 (2019).

    [Article](https://doi.org/10.1002%2Fuog.20144) [CAS](https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BB3cznsFWlsQ%3D%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=30302849) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6771606) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Quality%E2%80%90improvement%20program%20for%20ultrasound%E2%80%90based%20fetal%20anatomy%20screening%20using%20large%E2%80%90scale%20clinical%20audit&journal=Ultrasound%20Obstet.%20Gynecol.&doi=10.1002%2Fuog.20144&volume=54&pages=239-245&publication_year=2019&author=Yaqub%2CM)

12. Kilani, R. et al. Inter-observer variability in fetal biometric measurements. _Taiwan. J. Obstet. Gynecol._ **57**, 32–39 (2018).

    [Article](https://doi.org/10.1016%2Fj.tjog.2017.12.006) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=29458900) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Inter-observer%20variability%20in%20fetal%20biometric%20measurements&journal=Taiwan.%20J.%20Obstet.%20Gynecol.&doi=10.1016%2Fj.tjog.2017.12.006&volume=57&pages=32-39&publication_year=2018&author=Kilani%2CR)

13. Sande, J. A., Ioannou, C., Sarris, I., Ohuma, E. O. & Papageorghiou, A. T. Reproducibility of measuring amniotic fluid index and single deepest vertical pool throughout gestation. _Prenat. Diagn._ **35**, 434–439 (2015).

    [Article](https://doi.org/10.1002%2Fpd.4504) [CAS](https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BC2M7os1yrtA%3D%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=25297394) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Reproducibility%20of%20measuring%20amniotic%20fluid%20index%20and%20single%20deepest%20vertical%20pool%20throughout%20gestation&journal=Prenat.%20Diagn.&doi=10.1002%2Fpd.4504&volume=35&pages=434-439&publication_year=2015&author=Sande%2CJA&author=Ioannou%2CC&author=Sarris%2CI&author=Ohuma%2CEO&author=Papageorghiou%2CAT)

14. Płotka, S. et al. Deep learning fetal ultrasound video model match human observers in biometric measurements. _Phys. Med. Biol._ **67**, 045013 (2022).

    [Article](https://doi.org/10.1088%2F1361-6560%2Fac4d85) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Deep%20learning%20fetal%20ultrasound%20video%20model%20match%20human%20observers%20in%20biometric%20measurements&journal=Phys.%20Med.%20Biol.&doi=10.1088%2F1361-6560%2Fac4d85&volume=67&publication_year=2022&author=P%C5%82otka%2CS)

15. Zeng, Y., Tsui, P.-H., Wu, W., Zhou, Z. & Wu, S. Fetal ultrasound image segmentation for automatic head circumference biometry using deeply supervised attention-gated V-Net. _J. Digit. Imaging_ **34**, 134–148 (2021).

    [Article](https://link.springer.com/doi/10.1007/s10278-020-00410-5) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=33483862) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7887128) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Fetal%20ultrasound%20image%20segmentation%20for%20automatic%20head%20circumference%20biometry%20using%20deeply%20supervised%20attention-gated%20V-Net&journal=J.%20Digit.%20Imaging&doi=10.1007%2Fs10278-020-00410-5&volume=34&pages=134-148&publication_year=2021&author=Zeng%2CY&author=Tsui%2CP-H&author=Wu%2CW&author=Zhou%2CZ&author=Wu%2CS)

16. Kim, H. P. et al. Automatic evaluation of fetal head biometry from ultrasound images using machine learning. _Physiol. Meas._ **40**, 065009 (2019).

    [Article](https://doi.org/10.1088%2F1361-6579%2Fab21ac) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=31091515) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Automatic%20evaluation%20of%20fetal%20head%20biometry%20from%20ultrasound%20images%20using%20machine%20learning&journal=Physiol.%20Meas.&doi=10.1088%2F1361-6579%2Fab21ac&volume=40&publication_year=2019&author=Kim%2CHP)

17. Burgos-Artizzu, X. P. et al. Evaluation of deep convolutional neural networks for automatic classification of common maternal fetal ultrasound planes. _Sci. Rep._ **10**, 10200 (2020).

    [Article](https://doi.org/10.1038%2Fs41598-020-67076-5) [ADS](http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&bibcode=2020NatSR..1010200B) [CAS](https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXht1KjurrL) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=32576905) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7311420) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Evaluation%20of%20deep%20convolutional%20neural%20networks%20for%20automatic%20classification%20of%20common%20maternal%20fetal%20ultrasound%20planes&journal=Sci.%20Rep.&doi=10.1038%2Fs41598-020-67076-5&volume=10&publication_year=2020&author=Burgos-Artizzu%2CXP)

18. Pokaprakarn, T. et al. AI estimation of gestational age from blind ultrasound sweeps in low-resource settings. _NEJM Evid._ **1**, 10 (2022).

    [Article](https://doi.org/10.1056%2FEVIDoa2100058) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9980216) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=AI%20estimation%20of%20gestational%20age%20from%20blind%20ultrasound%20sweeps%20in%20low-resource%20settings&journal=NEJM%20Evid.&doi=10.1056%2FEVIDoa2100058&volume=1&publication_year=2022&author=Pokaprakarn%2CT)

19. Sendra-Balcells, C. et al. Generalisability of fetal ultrasound deep learning models to low-resource imaging settings in five African countries. _Sci. Rep._ **13**, 2728 (2023).

    [Article](https://doi.org/10.1038%2Fs41598-023-29490-3) [ADS](http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&bibcode=2023NatSR..13.2728S) [CAS](https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3sXjtlKmtr0%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=36792642) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9932015) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Generalisability%20of%20fetal%20ultrasound%20deep%20learning%20models%20to%20low-resource%20imaging%20settings%20in%20five%20African%20countries&journal=Sci.%20Rep.&doi=10.1038%2Fs41598-023-29490-3&volume=13&publication_year=2023&author=Sendra-Balcells%2CC)

20. Gomes, R. G. et al. A mobile-optimized artificial intelligence system for gestational age and fetal malpresentation assessment. _Commun. Med._ **2**, 1–9 (2022).

    [Article](https://doi.org/10.1038%2Fs43856-022-00194-5) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=A%20mobile-optimized%20artificial%20intelligence%20system%20for%20gestational%20age%20and%20fetal%20malpresentation%20assessment&journal=Commun.%20Med.&doi=10.1038%2Fs43856-022-00194-5&volume=2&pages=1-9&publication_year=2022&author=Gomes%2CRG)

21. Tkachenko, M., Malyuk, M., Holmanyuk, A. & Liubimov, N. (2020-2022). Label Studio: Data labeling software. Open source software available from [https://github.com/heartexlabs/label-studio](https://github.com/heartexlabs/label-studio).

22. Salomon, L. J. et al. ISUOG Practice guidelines: ultrasound assessment of fetal biometry and growth. _Ultrasound Obstet. Gynecol._ **53**, 715–723 (2019).

    [Article](https://doi.org/10.1002%2Fuog.20272) [CAS](https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BB3M3jvVGntg%3D%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=31169958) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=ISUOG%20Practice%20guidelines%3A%20ultrasound%20assessment%20of%20fetal%20biometry%20and%20growth&journal=Ultrasound%20Obstet.%20Gynecol.&doi=10.1002%2Fuog.20272&volume=53&pages=715-723&publication_year=2019&author=Salomon%2CLJ)

23. Salomon, L. J. et al. Practice guidelines for performance of the routine mid-trimester fetal ultrasound scan. _Ultrasound Obstet. Gynecol._ **37**, 116–126 (2011).

    [Article](https://doi.org/10.1002%2Fuog.8831) [CAS](https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BC3M7gtFWqug%3D%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=20842655) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Practice%20guidelines%20for%20performance%20of%20the%20routine%20mid-trimester%20fetal%20ultrasound%20scan&journal=Ultrasound%20Obstet.%20Gynecol.&doi=10.1002%2Fuog.8831&volume=37&pages=116-126&publication_year=2011&author=Salomon%2CLJ)

24. He, K., Gkioxari, G., Dollár, P. & Girshick, R. Mask R-CNN. In _2017 IEEE International Conference on Computer Vision (ICCV)_ 2980–2988 (Institute of Electrical and Electronics Engineers (IEEE), 2017).

25. Al-Bander, B., Alzahrani, T., Alzahrani, S., Williams, B. M. & Zheng, Y. Improving fetal head contour detection by object localisation with deep learning, Vol. 1065. In _Medical Image Understanding and Analysis_ _(_ eds. Zheng, Y., Williams, B. M. & Chen, K.) 142–150 (Springer Int. Publ., 2020).

26. Moccia, S., Fiorentino, M. C. & Frontoni, E. Mask-R2CNN: a distance-field regression version of Mask-RCNN for fetal-head delineation in ultrasound images. _Int. J. CARS_ **16**, 1711–1718 (2021).

    [Article](https://link.springer.com/doi/10.1007/s11548-021-02430-0) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Mask-R2CNN%3A%20a%20distance-field%20regression%20version%20of%20Mask-RCNN%20for%20fetal-head%20delineation%20in%20ultrasound%20images&journal=Int.%20J.%20CARS&doi=10.1007%2Fs11548-021-02430-0&volume=16&pages=1711-1718&publication_year=2021&author=Moccia%2CS&author=Fiorentino%2CMC&author=Frontoni%2CE)

27. Wu, Y., Kirillov, A., Massa, F., Lo, W.-Y., and Girshick, R. Detectron2 (2019). [https://github.com/facebookresearch/detectron2](https://github.com/facebookresearch/detectron2).

28. Cho, H. C. et al. Automated ultrasound assessment of amniotic fluid index using deep learning. _Med. Image Anal._ **69**, 101951 (2021).

    [Article](https://doi.org/10.1016%2Fj.media.2020.101951) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=33515982) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Automated%20ultrasound%20assessment%20of%20amniotic%20fluid%20index%20using%20deep%20learning&journal=Med.%20Image%20Anal.&doi=10.1016%2Fj.media.2020.101951&volume=69&publication_year=2021&author=Cho%2CHC)

29. Hadlock, F. P., Harrist, R. B., Sharman, R. S., Deter, R. L. & Park, S. K. Estimation of fetal weight with the use of head, body, and femur measurements—a prospective study. _Am. J. Obstet. Gynecol._ **151**, 333–337 (1985).

    [Article](https://doi.org/10.1016%2F0002-9378%2885%2990298-4) [CAS](https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL2M7hvFCgtg%3D%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=3881966) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Estimation%20of%20fetal%20weight%20with%20the%20use%20of%20head%2C%20body%2C%20and%20femur%20measurements%E2%80%94a%20prospective%20study&journal=Am.%20J.%20Obstet.%20Gynecol.&doi=10.1016%2F0002-9378%2885%2990298-4&volume=151&pages=333-337&publication_year=1985&author=Hadlock%2CFP&author=Harrist%2CRB&author=Sharman%2CRS&author=Deter%2CRL&author=Park%2CSK)

30. Papageorghiou, A. T. et al. Ultrasound-based gestational-age estimation in late pregnancy. _Ultrasound Obstet. Gynecol._ **48**, 719–726 (2016).

    [Article](https://doi.org/10.1002%2Fuog.15894) [CAS](https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BC28jlt1yisQ%3D%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=26924421) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6680349) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Ultrasound-based%20gestational-age%20estimation%20in%20late%20pregnancy&journal=Ultrasound%20Obstet.%20Gynecol.&doi=10.1002%2Fuog.15894&volume=48&pages=719-726&publication_year=2016&author=Papageorghiou%2CAT)

31. Espinoza, J., Good, S., Russell, E. & Lee, W. Does the use of automated fetal biometry improve clinical workflow efficiency? _J. Ultrasound Med._ **32**, 847–850 (2013).

    [Article](https://doi.org/10.7863%2Fjum.2013.32.5.847) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=23620327) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Does%20the%20use%20of%20automated%20fetal%20biometry%20improve%20clinical%20workflow%20efficiency%3F&journal=J.%20Ultrasound%20Med.&doi=10.7863%2Fjum.2013.32.5.847&volume=32&pages=847-850&publication_year=2013&author=Espinoza%2CJ&author=Good%2CS&author=Russell%2CE&author=Lee%2CW)

32. Pels, A., Beune, I. M., van Wassenaer‐Leemhuis, A. G., Limpens, J. & Ganzevoort, W. Early‐onset fetal growth restriction: a systematic review on mortality and morbidity. _Acta Obstet. Gynecol. Scand._ **99**, 153–166 (2020).

    [Article](https://doi.org/10.1111%2Faogs.13702) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=31376293) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Early%E2%80%90onset%20fetal%20growth%20restriction%3A%20a%20systematic%20review%20on%20mortality%20and%20morbidity&journal=Acta%20Obstet.%20Gynecol.%20Scand.&doi=10.1111%2Faogs.13702&volume=99&pages=153-166&publication_year=2020&author=Pels%2CA&author=Beune%2CIM&author=Wassenaer%E2%80%90Leemhuis%2CAG&author=Limpens%2CJ&author=Ganzevoort%2CW)

33. Figueroa, L. et al. Oligohydramnios: a prospective study of fetal, neonatal and maternal outcomes in low-middle income countries. _Reprod. Health_ **17**, 19 (2020).

    [Article](https://link.springer.com/doi/10.1186/s12978-020-0854-y) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=32000798) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6993413) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Oligohydramnios%3A%20a%20prospective%20study%20of%20fetal%2C%20neonatal%20and%20maternal%20outcomes%20in%20low-middle%20income%20countries&journal=Reprod.%20Health&doi=10.1186%2Fs12978-020-0854-y&volume=17&publication_year=2020&author=Figueroa%2CL)

34. Tashfeen, K. & Hamdi, I. M. Polyhydramnios as a predictor of adverse pregnancy outcomes. _Sultan Qaboos Univ. Med. J._ **13**, 57–62 (2013).

    [Article](https://doi.org/10.12816%2F0003196) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=23573383) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3616801) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Polyhydramnios%20as%20a%20predictor%20of%20adverse%20pregnancy%20outcomes&journal=Sultan%20Qaboos%20Univ.%20Med.%20J.&doi=10.12816%2F0003196&volume=13&pages=57-62&publication_year=2013&author=Tashfeen%2CK&author=Hamdi%2CIM)

35. Sarris, I. et al. Intra- and interobserver variability in fetal ultrasound measurements. _Ultrasound Obstet. Gynecol._ **39**, 266–273 (2012).

    [Article](https://doi.org/10.1002%2Fuog.10082) [CAS](https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BC38nos1aqsQ%3D%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=22535628) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Intra-%20and%20interobserver%20variability%20in%20fetal%20ultrasound%20measurements&journal=Ultrasound%20Obstet.%20Gynecol.&doi=10.1002%2Fuog.10082&volume=39&pages=266-273&publication_year=2012&author=Sarris%2CI)

36. Perni, S. C. et al. Intraobserver and interobserver reproducibility of fetal biometry. _Ultrasound Obstet. Gynecol._ **24**, 654–658 (2004).

    [Article](https://doi.org/10.1002%2Fuog.1717) [CAS](https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BD2crlvFOkug%3D%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=15476300) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Intraobserver%20and%20interobserver%20reproducibility%20of%20fetal%20biometry&journal=Ultrasound%20Obstet.%20Gynecol.&doi=10.1002%2Fuog.1717&volume=24&pages=654-658&publication_year=2004&author=Perni%2CSC)

37. Zhang, B., Liu, H., Luo, H. & Li, K. Automatic quality assessment for 2D fetal sonographic standard plane based on multitask learning. _Medicine_ **100**, e24427 (2021).

    [Article](https://doi.org/10.1097%2FMD.0000000000024427) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=33530242) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7850658) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Automatic%20quality%20assessment%20for%202D%20fetal%20sonographic%20standard%20plane%20based%20on%20multitask%20learning&journal=Medicine&doi=10.1097%2FMD.0000000000024427&volume=100&publication_year=2021&author=Zhang%2CB&author=Liu%2CH&author=Luo%2CH&author=Li%2CK)

38. Wu, L. et al. FUIQA: fetal ultrasound image quality assessment with deep convolutional networks. _IEEE Trans. Cybern._ **47**, 1336–1349 (2017).

    [Article](https://doi.org/10.1109%2FTCYB.2017.2671898) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=28362600) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=FUIQA%3A%20fetal%20ultrasound%20image%20quality%20assessment%20with%20deep%20convolutional%20networks&journal=IEEE%20Trans.%20Cybern.&doi=10.1109%2FTCYB.2017.2671898&volume=47&pages=1336-1349&publication_year=2017&author=Wu%2CL)

39. Hughes, D. S. et al. Accuracy of the ultrasound estimate of the amniotic fluid volume (amniotic fluid index and single deepest pocket) to identify actual low, normal, and high amniotic fluid volumes as determined by quantile regression. _J. Ultrasound Med._ **39**, 373–378 (2020).

    [Article](https://doi.org/10.1002%2Fjum.15116) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=31423632) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Accuracy%20of%20the%20ultrasound%20estimate%20of%20the%20amniotic%20fluid%20volume%20%28amniotic%20fluid%20index%20and%20single%20deepest%20pocket%29%20to%20identify%20actual%20low%2C%20normal%2C%20and%20high%20amniotic%20fluid%20volumes%20as%20determined%20by%20quantile%20regression&journal=J.%20Ultrasound%20Med.&doi=10.1002%2Fjum.15116&volume=39&pages=373-378&publication_year=2020&author=Hughes%2CDS)

40. Sun, S. et al. Complementary network for accurate amniotic fluid segmentation from ultrasound images. _IEEE Access_ **9**, 108223–108235 (2021).

    [Article](https://doi.org/10.1109%2FACCESS.2021.3098844) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Complementary%20network%20for%20accurate%20amniotic%20fluid%20segmentation%20from%20ultrasound%20images&journal=IEEE%20Access&doi=10.1109%2FACCESS.2021.3098844&volume=9&pages=108223-108235&publication_year=2021&author=Sun%2CS)

41. Fiorentino, M. C., Villani, F. P., Di Cosmo, M., Frontoni, E. & Moccia, S. A review on deep-learning algorithms for fetal ultrasound-image analysis. _Med. Image Anal._ **83**, 102629 (2023).

    [Article](https://doi.org/10.1016%2Fj.media.2022.102629) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=36308861) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=A%20review%20on%20deep-learning%20algorithms%20for%20fetal%20ultrasound-image%20analysis&journal=Med.%20Image%20Anal.&doi=10.1016%2Fj.media.2022.102629&volume=83&publication_year=2023&author=Fiorentino%2CMC&author=Villani%2CFP&author=Cosmo%2CM&author=Frontoni%2CE&author=Moccia%2CS)

42. Baumgartner, C. F. et al. SonoNet: real-time detection and localisation of fetal standard scan planes in freehand ultrasound. _IEEE Trans. Med. Imaging_ **36**, 2204–2215 (2017).

    [Article](https://doi.org/10.1109%2FTMI.2017.2712367) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=28708546) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=SonoNet%3A%20real-time%20detection%20and%20localisation%20of%20fetal%20standard%20scan%20planes%20in%20freehand%20ultrasound&journal=IEEE%20Trans.%20Med.%20Imaging&doi=10.1109%2FTMI.2017.2712367&volume=36&pages=2204-2215&publication_year=2017&author=Baumgartner%2CCF)

43. Cai, Y. et al. Spatio-temporal visual attention modeling of standard biometry plane-finding navigation. _Med. Image Anal._ **65**, 101762 (2020).

    [Article](https://doi.org/10.1016%2Fj.media.2020.101762) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=32623278) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Spatio-temporal%20visual%20attention%20modeling%20of%20standard%20biometry%20plane-finding%20navigation&journal=Med.%20Image%20Anal.&doi=10.1016%2Fj.media.2020.101762&volume=65&publication_year=2020&author=Cai%2CY)

44. Rasheed, K., Junejo, F., Malik, A. & Saqib, M. Automated fetal head classification and segmentation using ultrasound video. _IEEE Access_ **9**, 160249–160267 (2021).

    [Article](https://doi.org/10.1109%2FACCESS.2021.3131518) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Automated%20fetal%20head%20classification%20and%20segmentation%20using%20ultrasound%20video&journal=IEEE%20Access&doi=10.1109%2FACCESS.2021.3131518&volume=9&pages=160249-160267&publication_year=2021&author=Rasheed%2CK&author=Junejo%2CF&author=Malik%2CA&author=Saqib%2CM)

45. Zhu, F. et al. Automatic measurement of fetal femur length in ultrasound images: a comparison of random forest regression model and SegNet. _Math. Biosci. Eng._ **18**, 7790–7805 (2021).

    [Article](https://doi.org/10.3934%2Fmbe.2021387) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=34814276) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Automatic%20measurement%20of%20fetal%20femur%20length%20in%20ultrasound%20images%3A%20a%20comparison%20of%20random%20forest%20regression%20model%20and%20SegNet&journal=Math.%20Biosci.%20Eng.&doi=10.3934%2Fmbe.2021387&volume=18&pages=7790-7805&publication_year=2021&author=Zhu%2CF)

46. Li, P., Zhao, H., Liu, P. & Cao, F. Automated measurement network for accurate segmentation and parameter modification in fetal head ultrasound images. _Med. Biol. Eng. Comput._ **58**, 2879–2892 (2020).

    [Article](https://link.springer.com/doi/10.1007/s11517-020-02242-5) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=32975706) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Automated%20measurement%20network%20for%20accurate%20segmentation%20and%20parameter%20modification%20in%20fetal%20head%20ultrasound%20images&journal=Med.%20Biol.%20Eng.%20Comput.&doi=10.1007%2Fs11517-020-02242-5&volume=58&pages=2879-2892&publication_year=2020&author=Li%2CP&author=Zhao%2CH&author=Liu%2CP&author=Cao%2CF)

47. Li, Y., Xu, R., Ohya, J. & Iwata, H. Automatic fetal body and amniotic fluid segmentation from fetal ultrasound images by encoder-decoder network with inner layers. In _39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)_ 1485–1488 (Institute of Electrical and Electronics Engineers (IEEE), 2017).

48. Prieto, J. C. et al. An automated framework for image classification and segmentation of fetal ultrasound images for gestational age estimation. _Proc. SPIE Int. Soc. Opt. Eng._ **11596**, 115961N (2021).

    [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=33935344) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8086527) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=An%20automated%20framework%20for%20image%20classification%20and%20segmentation%20of%20fetal%20ultrasound%20images%20for%20gestational%20age%20estimation&journal=Proc.%20SPIE%20Int.%20Soc.%20Opt.%20Eng.&volume=11596&publication_year=2021&author=Prieto%2CJC)

49. Płotka, S. et al. FetalNet: Multi-task deep learning framework for fetal ultrasound biometric measurements. In _Neural Information Processing. ICONIP_. _Communications in Computer and Information Science_, Vol. 1517 (eds. Mantoro, T., Lee, M., Ayu, M. A., Wong, K. W. & Hidayanto, A. N.) (Springer, Cham, 2021).

50. Kehl, S. et al. Single deepest vertical pocket or amniotic fluid index as evaluation test for predicting adverse pregnancy outcome (SAFE trial): a multicenter, open-label, randomized controlled trial. _Ultrasound Obstet. Gynecol._ **47**, 674–679 (2016).

    [Article](https://doi.org/10.1002%2Fuog.14924) [CAS](https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BC2MblsVahtw%3D%3D) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=26094600) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=Single%20deepest%20vertical%20pocket%20or%20amniotic%20fluid%20index%20as%20evaluation%20test%20for%20predicting%20adverse%20pregnancy%20outcome%20%28SAFE%20trial%29%3A%20a%20multicenter%2C%20open-label%2C%20randomized%20controlled%20trial&journal=Ultrasound%20Obstet.%20Gynecol.&doi=10.1002%2Fuog.14924&volume=47&pages=674-679&publication_year=2016&author=Kehl%2CS)

51. Bossuyt, P. M. et al. STARD 2015: an updated list of essential items for reporting diagnostic accuracy studies. _BMJ_ **351**, h5527 (2015).

    [Article](https://doi.org/10.1136%2Fbmj.h5527) [PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&dopt=Abstract&list_uids=26511519) [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4623764) [Google Scholar](http://scholar.google.com/scholar_lookup?&title=STARD%202015%3A%20an%20updated%20list%20of%20essential%20items%20for%20reporting%20diagnostic%20accuracy%20studies&journal=BMJ&doi=10.1136%2Fbmj.h5527&volume=351&publication_year=2015&author=Bossuyt%2CPM)


[Download references](https://citation-needed.springer.com/v2/references/10.1038/s41467-023-42438-5?format=refman&flavour=references)

## Acknowledgements

This study was entirely funded by Deepecho.inc. Authors would like to thank Leila Noureddine, Yasmine Guenni, Abed Tlemcani, Amine Fourari, Youssef Sakhi, and Nacer Abid for their hard and continuous work on image annotation. We would also like to thank Helena Pinheiro (hpinheiro.com) for the illustrations.

## Author information

### Authors and Affiliations

01. Deepecho, 10106, Rabat, Morocco

    Saad Slimani, Abdelhak Mahmoudi, Taha Rehah, Youssef Bouyakhf & El Houssine Bouyakhf

02. Ibn Rochd University Hospital, Hassan II University, 20100, Casablanca, Morocco

    Saad Slimani, Dalal Laoudiyi, Amine Lamrissi, Mohamed Jalal & Said Bouhya

03. Telecommunications Systems Services and Networks lab (STRS Lab), INPT, 10112, Rabat, Morocco

    Salaheddine Hounka & Amina Radgui

04. Ecole Normale Supérieure, LIMIARF, Mohammed V University in Rabat, 4014, Rabat, Morocco

    Abdelhak Mahmoudi

05. Mohammed VI University Hospital, 60049, Oujda, Morocco

    Hanane Saadi

06. Université Mohammed VI des Sciences de la Santé, Hôpital Universitaire Cheikh Khalifa, 82403, Casablanca, Morocco

    Amal Bouziyane

07. Abou Madi Radiology Clinic, 20060, Casablanca, Morocco

    Mustapha Akiki

08. Laboratory of Biodiversity, Ecology, and Genome, Department of Biology, Faculty of Sciences, Mohammed V University in Rabat, 1014, Rabat, Morocco

    Bouabid Badaoui

09. African Sustainable Agriculture Research Institute (ASARI), Mohammed VI Polytechnic University (UM6P), 43150, Laâyoune, Morocco

    Bouabid Badaoui

10. Radboud Institute for Molecular Life Sciences, Epigenomics & Single Cell Biophysics, 6525 XZ, Nijmegen, the Netherlands

    Musa Mhlanga


Authors

01. Saad Slimani


    [View author publications](https://www.nature.com/search?author=Saad%20Slimani)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Saad%20Slimani) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Saad%20Slimani%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

02. Salaheddine Hounka


    [View author publications](https://www.nature.com/search?author=Salaheddine%20Hounka)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Salaheddine%20Hounka) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Salaheddine%20Hounka%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

03. Abdelhak Mahmoudi


    [View author publications](https://www.nature.com/search?author=Abdelhak%20Mahmoudi)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Abdelhak%20Mahmoudi) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Abdelhak%20Mahmoudi%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

04. Taha Rehah


    [View author publications](https://www.nature.com/search?author=Taha%20Rehah)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Taha%20Rehah) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Taha%20Rehah%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

05. Dalal Laoudiyi


    [View author publications](https://www.nature.com/search?author=Dalal%20Laoudiyi)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Dalal%20Laoudiyi) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Dalal%20Laoudiyi%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

06. Hanane Saadi


    [View author publications](https://www.nature.com/search?author=Hanane%20Saadi)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Hanane%20Saadi) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Hanane%20Saadi%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

07. Amal Bouziyane


    [View author publications](https://www.nature.com/search?author=Amal%20Bouziyane)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Amal%20Bouziyane) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Amal%20Bouziyane%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

08. Amine Lamrissi


    [View author publications](https://www.nature.com/search?author=Amine%20Lamrissi)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Amine%20Lamrissi) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Amine%20Lamrissi%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

09. Mohamed Jalal


    [View author publications](https://www.nature.com/search?author=Mohamed%20Jalal)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Mohamed%20Jalal) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Mohamed%20Jalal%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

10. Said Bouhya


    [View author publications](https://www.nature.com/search?author=Said%20Bouhya)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Said%20Bouhya) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Said%20Bouhya%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

11. Mustapha Akiki


    [View author publications](https://www.nature.com/search?author=Mustapha%20Akiki)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Mustapha%20Akiki) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Mustapha%20Akiki%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

12. Youssef Bouyakhf


    [View author publications](https://www.nature.com/search?author=Youssef%20Bouyakhf)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Youssef%20Bouyakhf) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Youssef%20Bouyakhf%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

13. Bouabid Badaoui


    [View author publications](https://www.nature.com/search?author=Bouabid%20Badaoui)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Bouabid%20Badaoui) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Bouabid%20Badaoui%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

14. Amina Radgui


    [View author publications](https://www.nature.com/search?author=Amina%20Radgui)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Amina%20Radgui) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Amina%20Radgui%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

15. Musa Mhlanga


    [View author publications](https://www.nature.com/search?author=Musa%20Mhlanga)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Musa%20Mhlanga) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Musa%20Mhlanga%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

16. El Houssine Bouyakhf


    [View author publications](https://www.nature.com/search?author=El%20Houssine%20Bouyakhf)





    Search author on:[PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=El%20Houssine%20Bouyakhf) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22El%20Houssine%20Bouyakhf%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)


### Contributions

S.S. conceived of the presented idea, original concept, was responsible for the study design, supervised the project, collected data, and co-authored the manuscript. S.H. was the lead programmer, performed computational analysis, designed models, extracted the data, created figures, and co-authored the manuscript. A.M. supervised the project from data collection to models training and evaluation and co-authored the manuscript. T.R. contributed to programming, model design, and data extraction. These authors contributed equally: D.L., H.S., A.B., A.L., M.J., S.B., M.A.: performed ultrasound examinations, collected data, and helped supervise the project. Y.B.: original concept, supervised the project. B.B. advised the project, performed statistical analysis, helped develop the statistical analysis plan, and contributed to manuscript writing. A.R.: advised the project. M.M.: contributed to manuscript writing and advised the project. E.B. helped supervise the project and verified manuscript and analytical methods.

### Corresponding author

Correspondence to
[Saad Slimani](mailto:saad.slimani@deepecho.io).

## Ethics declarations

### Competing interests

S.S., A.M., Y.B., and E.B. are shareholders and employees of Deepecho inc. S.H. and T.R. are employees of Deepecho.inc. The remaining authors declare no competing interests.

## Peer review

### Peer review information

_Nature Communications_ thanks Wesley Lee and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. A peer review file is available.

## Additional information

**Publisher’s note** Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

## Supplementary information

### [Supplementary Information](https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_MOESM1_ESM.pdf)

### [Peer Review File](https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_MOESM2_ESM.pdf)

### [Description of Additional Supplementary Files](https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_MOESM3_ESM.pdf)

### [Supplementary Data 1](https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_MOESM4_ESM.csv)

### [Reporting Summary](https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-023-42438-5/MediaObjects/41467_2023_42438_MOESM5_ESM.pdf)

## Rights and permissions

**Open Access** This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit [http://creativecommons.org/licenses/by/4.0/](http://creativecommons.org/licenses/by/4.0/).

[Reprints and permissions](https://s100.copyright.com/AppDispatchServlet?title=Fetal%20biometry%20and%20amniotic%20fluid%20volume%20assessment%20end-to-end%20automation%20using%20Deep%20Learning&author=Saad%20Slimani%20et%20al&contentID=10.1038%2Fs41467-023-42438-5&copyright=The%20Author%28s%29&publication=2041-1723&publicationDate=2023-11-03&publisherName=SpringerNature&orderBeanReset=true&oa=CC%20BY)

## About this article

[![Check for updates. Verify currency and authenticity via CrossMark](<Base64-Image-Removed>)](https://crossmark.crossref.org/dialog/?doi=10.1038/s41467-023-42438-5)

### Cite this article

Slimani, S., Hounka, S., Mahmoudi, A. _et al._ Fetal biometry and amniotic fluid volume assessment end-to-end automation using Deep Learning.
_Nat Commun_ **14**, 7047 (2023). https://doi.org/10.1038/s41467-023-42438-5

[Download citation](https://citation-needed.springer.com/v2/references/10.1038/s41467-023-42438-5?format=refman&flavour=citation)

- Received: 24 January 2023

- Accepted: 10 October 2023

- Published: 03 November 2023

- DOI: https://doi.org/10.1038/s41467-023-42438-5


### Share this article

Anyone you share the following link with will be able to read this content:

Get shareable link

Sorry, a shareable link is not currently available for this article.

Copy to clipboard

Provided by the Springer Nature SharedIt content-sharing initiative


### Subjects

- [Diagnosis](https://www.nature.com/subjects/diagnosis)
- [Machine learning](https://www.nature.com/subjects/machine-learning)

## This article is cited by

- ### [Ensemble learning for fetal ultrasound and maternal–fetal data to predict mode of delivery after labor induction](https://doi.org/10.1038/s41598-024-65394-6)



  - Iolanda Ferreira
  - Joana Simões
  - Ana Luísa Areia

_Scientific Reports_ (2024)

- ### [PSFHSP-Net: an efficient lightweight network for identifying pubic symphysis-fetal head standard plane from intrapartum ultrasound images](https://doi.org/10.1007/s11517-024-03111-1)



  - Ruiyu Qiu
  - Mengqiang Zhou
  - Huijin Wang

_Medical & Biological Engineering & Computing_ (2024)

Close bannerClose

![Nature Briefing](https://www.nature.com/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg)

Sign up for the _Nature Briefing_ newsletter — what matters in science, free to your inbox daily.

Email address

Sign up

I agree my information will be processed in accordance with the _Nature_ and Springer Nature Limited [Privacy Policy](https://www.nature.com/info/privacy).

Close bannerClose

Get the most important science stories of the day, free in your inbox. [Sign up for Nature Briefing](https://www.nature.com/briefing/signup/?brieferEntryPoint=MainBriefingBanner)

---

## Source 2: onlinelibrary.wiley.com {#source-2}

**URL:** https://onlinelibrary.wiley.com/doi/10.1155/2015/319204
**Content Type:** Web Content
**Content Length:** 78,518 characters
**Scraped At:** 2025-06-29T11:38:04.392Z

**Detected Structure:** Tables

### Content:

[![](https://static.adzerk.net/Advertisers/10514a59b3834d1ab1340412794f6713.png)](https://ssai.onlinelibrary.wiley.com/r?e=eyJ2IjoiMS4xMyIsImF2IjoyNjI5MzQ4LCJhdCI6NCwiYnQiOjAsImNtIjozODY3MTc1NzgsImNoIjo2MTE0NywiY2siOnt9LCJjciI6NTQ5OTk1OTc1LCJkaSI6ImMwMTlkYTgzNjliNDRmODVhYWFlMWIzYThhM2Y3YWU1IiwiZGoiOjAsImlpIjoiYzY2M2Y0ODc2MGRmNDllMTk1YmMxZWVkZmMwMTM4OGUiLCJkbSI6MywiZmMiOjgzNDYyOTIwNiwiZmwiOjc5Nzk5MzY3NiwiaXAiOiI1LjE4My45MS4xNTUiLCJrdyI6InBvcy1sZWFkZXJib2FyZCxwbGYtd29sLGFzc2lkLTEwLjExNTUvMjAxNS8zMTkyMDQsdm9sLTIwMTUsaXNzLTEsYXhzLW9wZW4iLCJudyI6MTE0OTIsInBjIjowLCJvcCI6MCwibXAiOjAsImVjIjowLCJnbSI6MCwiZXAiOm51bGwsInByIjoyNDAwMzcsInJ0IjoxLCJycyI6NTAwLCJzYSI6Ijk3Iiwic2IiOiJpLTA4MWJkMzA3OTM4Y2ViZTMwIiwic3AiOjI4MzY0MDMsInN0IjoxMzAyODYwLCJ1ayI6InVlMS04ZDIxMjljNzlhZGU0YzM5YmZiNzg5ZDRjMjM2YzcwNSIsInpuIjozMDczNzAsInptIjpbMzA3MzcwXSwidHMiOjE3NTExOTcwNjM3NDksImJmIjp0cnVlLCJwbiI6ImI0NWFjNDViLTk0NWUtNDM2My1hZmE3LWI0MDY1YjdmMWI3NiIsImdyIjp0cnVlLCJnYyI6dHJ1ZSwiZ0MiOnRydWUsImdzIjoibm9uZSIsInR6IjoiVVRDIiwidXIiOiJodHRwczovL2NvcnBvcmF0ZXNvbHV0aW9ucy53aWxleS5jb20vcmVzdWx0cy8_dXRtX3NvdXJjZT1XaWxleSZ1dG1fbWVkaXVtPVdPTCZ1dG1fY2FtcGFpZ249TWVkaWFLaXRzIn0&s=0hVJcIkI_oHoPQudDklpTgcXx2s "")

[Journal of Pregnancy](https://onlinelibrary.wiley.com/journal/7097 "Journal of Pregnancy homepage")

[Volume 2015, Issue 1](https://onlinelibrary.wiley.com/toc/7097/2015) 319204 [![Journal of Pregnancy](https://onlinelibrary.wiley.com/pb-assets/journal-banners/7097-1715768554737.jpg)](https://onlinelibrary.wiley.com/journal/7097 "Journal of Pregnancy homepage")

Research Article

Open Access

[Creative Commons license information](http://creativecommons.org/licenses/by/3.0/)

# Reference Ranges of Amniotic Fluid Index in Late Third Trimester of Pregnancy: What Should the Optimal Interval between Two Ultrasound Examinations Be?

[Shripad Hebbar](https://onlinelibrary.wiley.com/authored-by/Hebbar/Shripad),

Corresponding Author

Shripad Hebbar

- [drshripadhebbar@yahoo.co.in](mailto:drshripadhebbar@yahoo.co.in "Link to email address")

- [orcid.org/0000-0001-6826-7017](https://orcid.org/0000-0001-6826-7017)

Department of Obstetrics and Gynaecology, Kasturba Medical College, Manipal University, Manipal 576 104, India [manipal.edu](http://manipal.edu/ "Link to external resource")

[Search for more papers by this author](https://onlinelibrary.wiley.com/authored-by/Hebbar/Shripad)
[Lavanya Rai](https://onlinelibrary.wiley.com/authored-by/Rai/Lavanya),

Lavanya Rai

Department of Obstetrics and Gynaecology, Kasturba Medical College, Manipal University, Manipal 576 104, India [manipal.edu](http://manipal.edu/ "Link to external resource")

[Search for more papers by this author](https://onlinelibrary.wiley.com/authored-by/Rai/Lavanya)
[Prashant Adiga](https://onlinelibrary.wiley.com/authored-by/Adiga/Prashant),

Prashant Adiga

Department of Obstetrics and Gynaecology, Kasturba Medical College, Manipal University, Manipal 576 104, India [manipal.edu](http://manipal.edu/ "Link to external resource")

[Search for more papers by this author](https://onlinelibrary.wiley.com/authored-by/Adiga/Prashant)
[Shyamala Guruvare](https://onlinelibrary.wiley.com/authored-by/Guruvare/Shyamala),

Shyamala Guruvare

- [orcid.org/0000-0001-7933-2400](https://orcid.org/0000-0001-7933-2400)

Department of Obstetrics and Gynaecology, Kasturba Medical College, Manipal University, Manipal 576 104, India [manipal.edu](http://manipal.edu/ "Link to external resource")

[Search for more papers by this author](https://onlinelibrary.wiley.com/authored-by/Guruvare/Shyamala)

[Shripad Hebbar](https://onlinelibrary.wiley.com/authored-by/Hebbar/Shripad),

Corresponding Author

Shripad Hebbar

- [drshripadhebbar@yahoo.co.in](mailto:drshripadhebbar@yahoo.co.in "Link to email address")

- [orcid.org/0000-0001-6826-7017](https://orcid.org/0000-0001-6826-7017)

Department of Obstetrics and Gynaecology, Kasturba Medical College, Manipal University, Manipal 576 104, India [manipal.edu](http://manipal.edu/ "Link to external resource")

[Search for more papers by this author](https://onlinelibrary.wiley.com/authored-by/Hebbar/Shripad)
[Lavanya Rai](https://onlinelibrary.wiley.com/authored-by/Rai/Lavanya),

Lavanya Rai

Department of Obstetrics and Gynaecology, Kasturba Medical College, Manipal University, Manipal 576 104, India [manipal.edu](http://manipal.edu/ "Link to external resource")

[Search for more papers by this author](https://onlinelibrary.wiley.com/authored-by/Rai/Lavanya)
[Prashant Adiga](https://onlinelibrary.wiley.com/authored-by/Adiga/Prashant),

Prashant Adiga

Department of Obstetrics and Gynaecology, Kasturba Medical College, Manipal University, Manipal 576 104, India [manipal.edu](http://manipal.edu/ "Link to external resource")

[Search for more papers by this author](https://onlinelibrary.wiley.com/authored-by/Adiga/Prashant)
[Shyamala Guruvare](https://onlinelibrary.wiley.com/authored-by/Guruvare/Shyamala),

Shyamala Guruvare

- [orcid.org/0000-0001-7933-2400](https://orcid.org/0000-0001-7933-2400)

Department of Obstetrics and Gynaecology, Kasturba Medical College, Manipal University, Manipal 576 104, India [manipal.edu](http://manipal.edu/ "Link to external resource")

[Search for more papers by this author](https://onlinelibrary.wiley.com/authored-by/Guruvare/Shyamala)

First published: 15 January 2015

[https://doi.org/10.1155/2015/319204](https://doi.org/10.1155/2015/319204)

Citations: [8](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#citedby-section)

**Academic Editor:** Sinuhe Hahn

**This article is part of Special Issue:**

## Abstract

_Background_. Amniotic fluid index (AFI) is one of the major and deciding components of fetal biophysical profile and by itself it can predict pregnancy outcome. Very low values are associated with intrauterine growth restriction and renal anomalies of fetus, whereas high values may indicate fetal GI anomalies, maternal diabetes mellitus, and so forth. However, before deciding the cut-off standards for abnormal values for a local population, what constitutes a normal range for specific gestational age and the ideal interval of testing should be defined. _Objectives_. To establish reference standards for AFI for local population after 34 weeks of pregnancy and to decide an optimal scan interval for AFI estimation in third trimester in low risk antenatal women. _Materials and Methods_. A prospective estimation of AFI was done in 50 healthy pregnant women from 34 to 40 weeks at weekly intervals. The trend of amniotic fluid volume was studied with advancing gestational age. Only low risk singleton pregnancies with accurately established gestational age who were available for all weekly scan from 34 to 40 weeks were included in the study. Women with gestational or overt diabetes mellitus, hypertensive disorders of the pregnancy, prelabour rupture of membranes, and congenital anomalies in the foetus and those who delivered before 40 completed weeks were excluded from the study. For the purpose of AFI measurement, the uterine cavity was arbitrarily divided into four quadrants by a vertical and horizontal line running through umbilicus. Linear array transabdominal probe was used to measure the largest vertical pocket (in cm) in perpendicular plane to the abdominal skin in each quadrant. Amniotic fluid index was obtained by adding these four measurements. Statistical analysis was done using SPSS software (Version 16, Chicago, IL). Percentile curves (5th, 50th, and 95th centiles) were constructed for comparison with other studies. Cohen’s _d_ coefficient was used to examine the magnitude of change at different time intervals. _Results_. Starting from 34 weeks till 40 weeks, 50 ultrasound measurements were available at each gestational age. The mean (standard deviation) of AFI values (in cms) were 34 W: 14.59 (1.79), 35 W: 14.25 (1.57), 36 W: 13.17 (1.56), 37 W: 12.48 (1.52), 38 W: 12.2 (1.7), and 39 W: 11.37 (1.71). The 5th percentile cut-off was 8.7 cm at 40 weeks. There was a gradual decline of AFI values as the gestational age approached term. Significant drop in AFI was noted at two-week intervals. AFI curve generated from the study varied significantly when compared with already published data, both from India and abroad. _Conclusion_. Normative range for AFI values for late third trimester was established. Appreciable changes occurred in AFI values as gestation advanced by two weeks. Hence, it is recommended to follow up low risk antenatal women every two weeks after 34 weeks of pregnancy. The percentile curves of AFI obtained from the present study may be used to detect abnormalities of amniotic fluid for our population.

## 1\. Introduction

The ultimate goal of antepartum surveillance program is to improve perinatal outcome and to decrease intrauterine fetal demise besides prevention of maternal morbidity and mortality \[[1](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0001), [2](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0002)\]. A fetus in distress should be identified at the earliest so that timely delivery will not only salvage the fetus but also prevent long term neurological impairments such as injury to fetal central nervous system \[[3](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0003)\]. Though it is said that such an event is more common in high risk pregnancies, the fetuses belonging to low risk mothers are not totally immune \[[4](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0004)\]. There are definite guidelines for frequency of antenatal testing for high risk pregnant women, but what constitutes an ideal screening program for low risk pregnancies is still unknown \[[5](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0005)\].

Amniotic fluid assessment by ultrasound is one of the important tools in assessing the fetal health in all risk categories especially beyond the period of viability \[[6](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0006)\]. Though there are several ways \[[7](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0007)\] to assess quantity of amniotic fluid ranging from clinical palpation to measurement of single deepest vertical pocket \[[8](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0008)\], amniotic fluid index (AFI) by four-quadrant technique as described by Phelan et al. \[[9](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0009)\] in 1987 and among them AFI is popular and reliable method of quantifying amniotic fluid till today. AFI is one of the essential components of fetal biophysical profile (BPP) and its values correlate well with adequacy of fetal renal perfusion. Normally it peaks at 32 to 34 weeks of gestation and thereafter there is a gradual reduction in amniotic fluid due to increase in concentrating capacity of fetal kidneys \[[10](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0010)\]. However, a drastic reduction in its quantity may indicate underlying placental insufficiency, which has definite implications on growing fetus. The values between 8 and 25 are considered to be normal, 5–8 low normal, and less than 5 oligoamnios \[[11](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0011)\]. At values less than 5, there is higher incidence of perinatal morbidity and mortality and many a time immediate delivery is the only way out \[[12](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0012), [13](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0013)\]. Hence it is very important to scan the patient to note such a trend periodically during antenatal visits. AFI is the fifth parameter in traditional five-point biophysical profile and second parameter in rapid two-point modified BPP (the other one being NST) \[[14](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0014)\]. Though there is no definite said protocol for identifying compromised fetus, many believe that biweekly nonstress test and AFI assessment should be offered to all women at risk \[[15](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0015)\]. But what constitutes an ideal frequency of AFI monitoring for low risk pregnancy is still unknown. Frequent monitoring adds to the cost and maternal anxiety and optimizing the ultrasound examinations is the need of the day.

The present study is an effort to examine the quantum of decrease in AFI in the third trimester and interval of scanning to detect a significant change, thereby formulating guidelines for antenatal ultrasound examinations in low risk women.

## 2\. Aims and Objectives

The purpose of the present investigation is


- (1)
to study the pattern of change in AFI on weekly basis from 34 weeks till delivery;

- (2)
to constitute reference ranges of AFI from 34 to 40 weeks of gestation;

- (3)
to find the time interval by which there is a significant fall in AFI, which will help obstetrician to plan an ideal protocol for antenatal ultrasound examination in the third trimester.


## 3\. Materials and Methods

This was a prospective observational study conducted at the Department of Obstetrics and Gynaecology, Kasturba Medical College, Manipal, from January 2012 to December 2012. Institutional ethical committee approval was obtained prior to study. Inclusion criteria were low risk singleton pregnancy, starting gestational age of 34 weeks, reliable last menstrual period and dates correlated and confirmed by comparison with first trimester CRL (Crown Rump Length). Once initial criteria were met, those who were subsequently diagnosed to have abnormalities of liquor volume due to conditions such as hypertensive disorders, gestational diabetes, and placental insufficiency were excluded from the study, so as to obtain normative data. Only those patients who delivered at 40 weeks were included in the study as we wanted longitudinal data till term. The final study subjects were 50 low risk pregnant women who underwent serial scans at weekly interval starting from 34 weeks till term.

The subjects belonged to the local population consisting mainly of Tuluva, Billava, Bunt, Koraga, Kulala, Devadiga, Konkanis, Shivalli Brahmins, Bayri Muslim, and Catholic communities, the spoken language mainly being Kannada, Tulu, and Konkani. The women were medium built, the average height was of 152 to 156 cms, and prepregnancy weight was between 45 and 50 kg.

The ultrasound examination was carried out after instructing the patient to empty her bladder. The examinations were performed with a convex 3.5 MHz probe (Philips HD11XE ultrasound equipment). The patient was asked to lie down in supine position. Uterus was arbitrarily divided into four quadrants using linea nigra as a vertical line and a transverse line passing through umbilicus, as described by Phelan et al. \[[9](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0009)\]. The transducer was placed in each of these quadrants in sagittal plane perpendicular to patient’s abdomen and maximum depth of amniotic fluid was calculated in centimeters excluding the cord loops and small fetal parts. Caution was exercised to avoid excessive pressure on the transducer as it can alter AFI measurements. The values of all four quadrants were added to obtain the final amniotic fluid index (AFI).

### 3.1. Sample Size Estimation

Khadilkar et al. \[[16](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0016)\] from the Department of Obstetrics and Gynaecology, Grant Medical College, Mumbai, conducted a prospective, cross sectional study in low risk healthy pregnant subjects to obtain a gestational reference range for AFI among Indian women. They noted that the mean and standard deviation of AFI (cm) at 34 weeks of gestation was 14.2 and 2.4, respectively. We hypothesised that a difference of 1.5 cm in the mean AFI would be significantly different from the normal values and accordingly estimated sample size to show a desired level of power of 90% and level of significance 0.05, by using the formula,



![mathematical equation](https://onlinelibrary.wiley.com/cms/asset/58e9a341-4734-4908-9540-12fd5147f9cc/jp319204-math-0001.png)(1)

where _z_ _α_ = 1.96 (critical value that divides the central 95% of _z_ distribution from 5% in the tails), _z_ _β_ = 1.28 (critical value that separates the lower 10% of distribution from upper 90%), _σ_ = standard deviation, and _μ_ 1 − _μ_ 0 = difference of two means.

Accordingly it was estimated that 27 patients are required and we decided to recruit 50 patients to have satisfactory results.

## 4\. Statistical Methods

Data was analyzed using SPSS version 16 for windows (SPSS Inc., Chicago, IL, USA). Descriptive analysis was performed to obtain mean, standard deviation, and percentile values for AFI from 34 to 40 weeks. Microsoft Excel 2010 was used to plot percentile values (5th, 50th, and 95th) across various gestational ages. A polynomial regression analysis of 3rd order was used to find the best fit. The decline in AFI value was calculated at weekly interval and the magnitude of change was analyzed by effect size estimation (Cohen _d_ coefficient) \[[17](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0017)\].

The formula for Cohen’s _d_ is given as follows:



![mathematical equation](https://onlinelibrary.wiley.com/cms/asset/72c8c7b2-3d16-49f7-a4df-be5160b9b3dc/jp319204-math-0002.png)(2)

where _M_ 1 and _M_ 2 are the means and _s_ 1 and _s_ 2 are the standard deviations of two groups.

## 5\. Results

Of the 50 patients who were recruited for the study and were between the age of 22 to 28 years, more than half (32 patients, 64%) were primigravidae and 18 (36%) were multigravidae. None of them had any antenatal complications. All of them delivered at around 39+ to 40 weeks. 16 (32%) patients required caesarean delivery for obstetric indication such as failed induction, cephalopelvic disproportion, and fetal distress in labour. The mean (standard deviation) birth weight of the neonates (measured in kg) was 2.83 (0.34), with 1st minute APGAR score (mean and standard deviation) of 8.48 (1.09) and 5th minute APGAR was 8.72 (1.01). As mentioned in methodology, we have excluded those who delivered before term as we required AFI from 34 weeks to 40 weeks of gestation for analysis purpose.

Table [1](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#tbl-0001 "Link to table") describes the descriptive data for AFI. The AFI values differed throughout the gestation and there was a gradual decline in the values as pregnancy advanced. The 5th, 50th, and 95th percentiles ranged from 11.7, 14.6, and 17.3, respectively, at 34 weeks to 8.7, 10.8, and 13.7, respectively, at 40 weeks. It is interesting to note that all the values were within 8 to 25 cm range (which is accepted and established normal range for AFI values worldwide). The maximum value of AFI in any single patient was 17.6 cm and minimum 8.5 cm in our series of low risk antenatal pregnant women. If minimum (5th centile) and maximum (95th centile) are considered as normal range, it was noted that the corresponding values too were different at different gestational ages; the more advanced the gestational age, the lesser the values. These changes are graphically represented in Figure [1](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#fig-0001).

| Gestational age | Mean | Standard deviation | 5th percentile | 10th percentile | 50th percentile | 90th percentile | 95th percentile |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 34 weeks | 14.59 | 1.79 | 11.7 | 12.0 | 14.6 | 17.0 | 17.3 |
| 35 weeks | 14.25 | 1.57 | 11.1 | 11.8 | 14.2 | 16.2 | 16.4 |
| 36 weeks | 13.17 | 1.56 | 10.6 | 11.0 | 13.2 | 15.3 | 15.7 |
| 37 weeks | 12.48 | 1.52 | 10.1 | 10.2 | 12.6 | 14.7 | 15.1 |
| 38 weeks | 12.20 | 1.70 | 9.8 | 10.0 | 12.1 | 14.4 | 14.7 |
| 39 weeks | 11.37 | 1.71 | 8.8 | 9.1 | 11.4 | 14.0 | 14.4 |
| 40 weeks | 10.99 | 1.55 | 8.7 | 8.8 | 10.8 | 13.5 | 13.7 |

[![Details are in the caption following the image](https://onlinelibrary.wiley.com/cms/asset/8d2824b3-692c-40b6-9c10-07015226db56/jp319204-fig-0001-m.png)](https://onlinelibrary.wiley.com/cms/asset/3b061723-75b9-49c1-aa37-0dc91b9bda85/jp319204-fig-0001-m.jpg)

**Figure 1**

[Open in figure viewer](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#) [PowerPoint](https://onlinelibrary.wiley.com/action/downloadFigures?id=fig-0001&partId=&doi=10.1155%2F2015%2F319204)

Graphical representation of AFI centiles at various gestational ages.

We used difference in mean values of one week to the next week to evaluate the decreasing trend of amniotic fluid from 34 to 40 weeks of gestation (Table [2](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#tbl-0002 "Link to table")). Dark shaded area indicates cells where calculations are not required as they are the same weeks or previous weeks. It can be seen that many cells have the values less than 1, but still the difference may be calculated statistically significant if ordinary statistical tests such as paired _t_ test were applied and hence we have used Cohen’s test which very well detects the magnitude of change.

| From | To |
| --- | --- |
| 35 weeks | 36 weeks | 37 weeks | 38 weeks | 39 weeks | 40 weeks |
| --- | --- | --- | --- | --- | --- |
| 34 weeks | 0.34 | 1.42 | 2.12 | 2.39 | 3.22 | 3.61 |
| 35 weeks | \* | 1.08 | 1.77 | 2.05 | 2.88 | 3.26 |
| 36 weeks | \* | \* | 0.7 | 0.97 | 1.8 | 2.19 |
| 37 weeks | \* | \* | \* | 0.27 | 1.1 | 1.49 |
| 38 weeks | \* | \* | \* | \* | 0.83 | 1.22 |
| 39 weeks | \* | \* | \* | \* | \* | 0.39 |

- \*Comparison not done.

Table [3](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#tbl-0003 "Link to table") indicates Cohen’s _d_ values for week to week comparison and it can be seen that not much change was seen in immediate week, but changes became significant when the interval between two scans was more than 2 weeks or more in most of the comparisons. Hence from this table there is substantial evidence that liquor volume decreases significantly over the period of 14 days more in low risk antenatal women.

| From | To |
| --- | --- |
| 35 weeks | 36 weeks | 37 weeks | 38 weeks | 39 weeks | 40 weeks |
| --- | --- | --- | --- | --- | --- |
| 34 weeks | 0.21 | 0.85 | 1.29 | 1.38 | 1.86 | 2.18 |
| 35 weeks | # | 0.7 | 1.16 | 1.27 | 1.77 | 2.12 |
| 36 weeks | # | # | 0.46 | 0.6 | 1.11 | 1.42 |
| 37 weeks | # | # | # | 0.17 | 0.69 | 0.98 |
| 38 weeks | # | # | # | # | 0.49 | 0.76 |
| 39 weeks | # | # | # | # | # | 0.24 |

- 0.2–0.49 small effect, 0.5–0.8 medium effect, and >0.8 large effect.
- #Comparison not done.

Our results indicated that from 34 weeks onwards there is a gradual reduction in AFI. Using polynomial regression analysis, we have established reference standards for AFI ranges from 34 to 40 weeks (Figure [2](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#fig-0002)). The regression analysis further showed that there was a good degree of correlation between GA (gestational age) and AFI ( _R_ 2 = 0.89 to 0.95; _P_ < 0.005).

[![Details are in the caption following the image](https://onlinelibrary.wiley.com/cms/asset/e3f1c691-4bce-44e0-8c3b-8605fb4af32e/jp319204-fig-0002-m.png)](https://onlinelibrary.wiley.com/cms/asset/b7d4cfc4-30b7-43c7-acf5-d2a9e4251f06/jp319204-fig-0002-m.jpg)

**Figure 2**

[Open in figure viewer](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#) [PowerPoint](https://onlinelibrary.wiley.com/action/downloadFigures?id=fig-0002&partId=&doi=10.1155%2F2015%2F319204)

Curve of AFI values (5th, 50th, and 95th centiles) from 34 to 40 weeks following smoothing procedure from polynomial regression of 3rd degree.

The following equations were derived by third degree polynomial regression using **y** (AFI in cm) as dependent variable and **x** (gestation age in weeks) as independent variable, where _Y_ 5th, _Y_ 50th, and _Y_ 95th indicate 5th, 50th, and 95th centile values for AFI and GA indicates gestational age in weeks:



![mathematical equation](https://onlinelibrary.wiley.com/cms/asset/61735448-5319-4907-aa05-e76938e58e6b/jp319204-math-0003.png)(3)

## 6\. Discussion

Amniotic fluid production and regulation is a complex and dynamic process involving the fetus, placenta, and mother. Amniotic fluid volume gradually increases till 32–34 weeks of gestation and thereafter there is a gradual reduction till term \[[18](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0018), [19](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0019)\]. The critical AFI range of 8 to 25 cm signifies fetal well-being and the deviation from this range is associated with increase in fetal and maternal complications due to oligoamnios and polyhydramnios. The third trimester AFI values are proportionate to fetal urine production \[[20](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0020), [21](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0021)\] and hence in normal range indicate good placental perfusion and fetal nutrient and oxygen transfer. Hence monitoring the AFI has become a standard of antenatal care.

There is wide variation in reference standards for mean AFI values according to population, race, and geography. Table [4](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#tbl-0004 "Link to table") compares our finding with that of other authors \[[16](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0016), [22](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0022)–[25](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0025)\]. We have also graphically interpreted findings in the other studies (either mean or 50th percentile values) in Figure [3](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#fig-0003). However, it is noticeable that majority of the studies agree that from 34 weeks onward there is a gradual fall in AFI values. The two studies \[[16](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0016), [25](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0025)\] are from India, but the reported AFI range has a wide range. This may be because their observations were based upon retrospective cross sectional data. It is noticeable that AFI reference values published by Singh et al. are 2 to 3 cm more than all other series at all gestational ages; we presume this may be because the study was done in Indraprastha Apollo Hospital, New Delhi, where patients from very high socioeconomic status are catered. Khadilkar et al. reported their findings from patients attending antenatal clinic of Grant Medical College, Bombay, and our findings too match with their data. Hence, it can be opined that AFI standards have to be defined for specific populations in order to eliminate bias resulting from socioeconomic groups, geographical locations, race, and so forth. However, it must be noted that almost all authors have reported a steady decline in AFI values with the advancing gestational age, except Birang et al. from Iran. Their series included retrospective cross sectional data and the number differed from minimum of 12 observations at 35 weeks to maximum of 68 observations at 39 weeks. This might be the reason for their finding of rapid fall of AFI from 34 to 35 weeks, plateauing between 37 and 39 weeks and once again slow fall at 40 weeks. Such observations indicate weakness of cross sectional cohort, as the same patients are not followed up sequentially.

| Authors | AFI values | 34 W | 35 W | 36 W | 37 W | 38 W | 39 W | 40 W |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
|  | 5th centile | 7.6 | 7.4 | 7.2 | 7.0 | 6.8 | 6.1 | 5.9 |
| Khadilkar et al. 2003 \[[16](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0016)\] | 50th centile | 14.2 | 13.8 | 13.5 | 12.8 | 12.2 | 11.5 | 11.3 |
|  | 95th centile | 19 | 18.5 | 18.3 | 18.2 | 17.6 | 16.8 | 16.6 |
|  |
|  | Mean (St. Dev) | 13.7 (3.1) | 12.6 (2.2) | 11.1 (2.6) | 12.1 (2.4) | 11.4 (2.1) | 11.8 (1.7) | 11.0 (1.0) |
| Hinh and Ladinsky 2005 \[[22](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0022)\] | Min | 8.5 | 8.6 | 7.1 | 6.7 | 6.3 | 8.4 | 9.4 |
|  | Max | 18.8 | 16.8 | 16.3 | 15.9 | 15.4 | 14.8 | 12.7 |
|  |
|  | 10th centile | 10.2 | 9.7 | 9.1 | 8.4 | 7.7 | 7 | 6.2 |
| MacHado et al. 2007 \[[23](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0023)\] | 50th centile | 14.4 | 14.1 | 13.9 | 13.5 | 13.2 | 12.8 | 12.4 |
|  | 90th centile | 19.5 | 19.4 | 19.3 | 19.1 | 18.9 | 18.6 | 18.3 |
|  |
|  | Mean (St. Dev) | 13.8 (1.18) | 12.9 (0.60) | 12.7 (1.55) | 12.8 (0.84) | 12.8 (0.89) | 12.8 (1.19) | 12.5 (0.98) |
| Birang 2008 \[[24](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0024)\] | 5th centile | 8.3 | 7.3 | 7.1 | 7.1 | 7.1 | 7.0 | 6.6 |
|  | 95th centile | 23.7 | 23.2 | 22.8 | 22.1 | 20 | 18.7 | 18 |
|  |
|  | Mean | 17.1 | 16.9 | 16.3 | 16.2 | 15.7 | 15.3 | 14.8 |
| Singh et al. 2013 \[[25](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0025)\] | 5th centile | 11.0 | 10 | 9.7 | 10.1 | 9.9 | 8.1 | 8.8 |
|  | 95th centile | 24.5 | 24.1 | 24.8 | 24.2 | 24.1 | 23.7 | 18 |
|  |
|  | Mean | 14.59 (1.79) | 14.25 (1.57) | 13.17 (1.56) | 12.48 (1.52) | 12.2 (1.7) | 11.37 (1.71) | 10.99 (1.55) |
| Present study | 5th centile | 11.7 | 11.1 | 10.6 | 10.1 | 9.8 | 8.8 | 8.7 |
|  | 95th centile | 17.3 | 16.4 | 15.7 | 15.1 | 14.7 | 14.4 | 13.7 |

[![Details are in the caption following the image](https://onlinelibrary.wiley.com/cms/asset/17ad9e4e-c533-4445-b8b1-78e7de0feaa3/jp319204-fig-0003-m.png)](https://onlinelibrary.wiley.com/cms/asset/68b31eb8-669e-4ac9-8784-6b5f713e57a7/jp319204-fig-0003-m.jpg)

**Figure 3**

[Open in figure viewer](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#) [PowerPoint](https://onlinelibrary.wiley.com/action/downloadFigures?id=fig-0003&partId=&doi=10.1155%2F2015%2F319204)

Comparison of AFI values at different gestational ages in various studies.

Amniotic fluid once thought to be a stagnant pool with approximate turn over time of twenty-four hours. In high risk pregnancies complicated by chronic placental insufficiency liquor is known to drastically reduce in a shorter time and it has been recommended to perform AFI estimation once in three days or at times even frequently depending upon other fetal well-being surveillance tools such as Doppler assessment of fetal circulation. However, there is no universal consensus regarding the frequency of AFI estimation in low risk antenatal women. Hence, it is important to determine a critical interval at which the fall in AFI becomes clinically significant.

We have not used statistical significance test (involving estimation of _P_ value) such as _paired_ _t_ _test_ for comparing AFI values at different gestational ages, as these tests tend to give significant _P_ values even when a minor variation exists in the means of two groups. When sample size is sufficiently large, even the fractional differences are likely to be reported as significant _P_ values, hence giving meaningless interpretations. Instead, we have calculated effect size estimate (Cohen _d_) to quantify the changes in the AFI over a period of time.

Effect size is a simple measure for quantifying the difference between two groups or the same group over time, on a common scale. There are several methods mentioned in the literature to calculate the effect sizes (Cohen 1988 \[[17](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0017)\], Rosenthal and Rosnow 1991 \[[26](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0026)\], Partial Eta squared Richardson 2011 \[[27](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#bib-0027)\]) and so forth. However, we have used Cohen’s _d_ estimate as described by Cohen 1988, to calculate effect sizes as this method is easy, simple to understand and can be applied to any measured outcome in scientific study.

From our statistical analysis, we have found that there is no much decrease in AFI at interval of one week, but thereafter the differences become large and significant. Hence, it appears that when the liquor is within normal range, the chances of fetal jeopardy are unlikely to occur within next week; one can safely repeat the AFI after 2 weeks. At the time of estimation of AFI, one can also perform other tests for foetal well-being such as documentation of gross foetal body movements, foetal tone, and foetal breathing movements to be assured that foetus is not hypoxic. In addition, interval biometry may be done at whenever required to quantify satisfactory foetal growth. In the absence of any maternal or foetal risk factors, we are of the opinion that AFI estimation once in fortnight is good enough to ensure satisfactory pregnancy outcome.

## 7\. Conclusions

We have established not only gestational specific normative AFI reference standards for late third trimester (34 to 40 weeks) for our local population but also magnitude of change in AFI values at weekly interval by quantitative analysis using effect size statistics. Strength of present study is that it is based on longitudinal data of normal healthy pregnant women and percentile curves obtained can be used to define what constitutes normal range of AFI for low risk antenatal patients. Though our results are based on required number of patients by sample size determination, larger number of subjects if studied may yield robust reference curves for AFI and identify extreme values to define what constitutes oligo- or polyhydramnios. The same study can be extended to high risk pregnancies such as preeclampsia, chronic hypertension, multiple gestation, and intrauterine growth restriction, in order to determine the frequency of liquor testing for these cohorts.

## Conflict of Interests

The authors have no conflict of interests to declare.

## [References](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204\#)

- 1Yeo L.,
Ross M. G., and
Vintzileos A. M., Antepartum and intra-partum surveillance of the fetus and the amniotic fluid, Clinical Obstetrics: The Fetus & Mother, 2008, 3rd edition, John Wiley & Sons, 586–606.





[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26publication_year%3D2008%26pages%3D586-606%26author%3DL.%2BYeo%26author%3DM.%2BG.%2BRoss%26author%3DA.%2BM.%2BVintzileos%26title%3DClinical%2BObstetrics%253A%2BThe%2BFetus%2B%2526%2BMother&doi=10.1155%2F2015%2F319204&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 2Liston R.,
Sawchuck D., and
Young D., Fetal health surveillance: antepartum and intrapartum consensus guideline, _Journal of Obstetrics and Gynaecology Canada_. (2007) 29, no. 9 supplement 4, S3–S56, 2-s2.0-38449114992.

10.1016/S1701-2163(16)32615-9



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=17845745&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2FS1701-2163%2816%2932615-9&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D29%26publication_year%3D2007%26pages%3DS3-S56%26journal%3DJournal%2Bof%2BObstetrics%2Band%2BGynaecology%2BCanada%26author%3DR.%2BListon%26author%3DD.%2BSawchuck%26author%3DD.%2BYoung%26title%3DFetal%2Bhealth%2Bsurveillance%253A%2Bantepartum%2Band%2Bintrapartum%2Bconsensus%2Bguideline&doi=10.1155%2F2015%2F319204&doiOfLink=10.1016%2FS1701-2163%2816%2932615-9&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 3Baschat A. A.,
Viscardi R. M.,
Hussey-Gardner B.,
Hashmi N., and
Harman C., Infant neurodevelopment following fetal growth restriction: Relationship with antepartum surveillance parameters, _Ultrasound in Obstetrics & Gynecology_. (2009) 33, no. 1, 44–50, [https://doi.org/10.1002/uog.6286](https://doi.org/10.1002/uog.6286), 2-s2.0-58149508225.

10.1002/uog.6286



[CAS](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=32&doi=10.1155%2F2015%2F319204&key=1%3ASTN%3A280%3ADC%252BD1M%252FkvFartw%253D%253D&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1002%2Fuog.6286&linkType=COI&linkSource=FULL_TEXT&linkLocation=Reference)[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=19072744&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1002%2Fuog.6286&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000263702400008&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1002%2Fuog.6286&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D33%26publication_year%3D2009%26pages%3D44-50%26journal%3DUltrasound%2Bin%2BObstetrics%2B%2526%2BGynecology%26author%3DA.%2BA.%2BBaschat%26author%3DR.%2BM.%2BViscardi%26author%3DB.%2BHussey-Gardner%26author%3DN.%2BHashmi%26author%3DC.%2BHarman%26title%3DInfant%2Bneurodevelopment%2Bfollowing%2Bfetal%2Bgrowth%2Brestriction%253A%2BRelationship%2Bwith%2Bantepartum%2Bsurveillance%2Bparameters&doi=10.1155%2F2015%2F319204&doiOfLink=10.1002%2Fuog.6286&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 4Heller G.,
Misselwitz B., and
Schmidt S., Early neonatal mortality, asphyxia related deaths, and timing of low risk births in Hesse, Germany, 1990–8: observational study, _British Medical Journal_. (2000) 321, no. 7256, 274–275, [https://doi.org/10.1136/bmj.321.7256.274](https://doi.org/10.1136/bmj.321.7256.274), 2-s2.0-0034730010.

10.1136/bmj.321.7256.274



[CAS](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=32&doi=10.1155%2F2015%2F319204&key=1%3ASTN%3A280%3ADC%252BD3cvhvVSguw%253D%253D&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1136%2Fbmj.321.7256.274&linkType=COI&linkSource=FULL_TEXT&linkLocation=Reference)[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=10915130&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1136%2Fbmj.321.7256.274&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000088619800026&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1136%2Fbmj.321.7256.274&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D321%26publication_year%3D2000%26pages%3D274-275%26journal%3DBritish%2BMedical%2BJournal%26author%3DG.%2BHeller%26author%3DB.%2BMisselwitz%26author%3DS.%2BSchmidt%26title%3DEarly%2Bneonatal%2Bmortality%252C%2Basphyxia%2Brelated%2Bdeaths%252C%2Band%2Btiming%2Bof%2Blow%2Brisk%2Bbirths%2Bin%2BHesse%252C%2BGermany%252C%2B1990%25E2%2580%25938%253A%2Bobservational%2Bstudy&doi=10.1155%2F2015%2F319204&doiOfLink=10.1136%2Fbmj.321.7256.274&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 5Manning F. A., Antepartum fetal testing: a critical appraisal, _Current Opinion in Obstetrics and Gynecology_. (2009) 21, no. 4, 348–352, [https://doi.org/10.1097/gco.0b013e32832ae0b3](https://doi.org/10.1097/gco.0b013e32832ae0b3), 2-s2.0-68949172201.

10.1097/GCO.0b013e32832ae0b3



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=19424063&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1097%2FGCO.0b013e32832ae0b3&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000268521500011&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1097%2FGCO.0b013e32832ae0b3&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D21%26publication_year%3D2009%26pages%3D348-352%26journal%3DCurrent%2BOpinion%2Bin%2BObstetrics%2Band%2BGynecology%26author%3DF.%2BA.%2BManning%26title%3DAntepartum%2Bfetal%2Btesting%253A%2Ba%2Bcritical%2Bappraisal&doi=10.1155%2F2015%2F319204&doiOfLink=10.1097%2FGCO.0b013e32832ae0b3&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 6Nash P., Amniotic fluid index, _Neonatal Network_. (2013) 32, no. 1, 46–49, [https://doi.org/10.1891/0730-0832.32.1.46](https://doi.org/10.1891/0730-0832.32.1.46), 2-s2.0-84891594107.

10.1891/0730-0832.32.1.46



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=23318207&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1891%2F0730-0832.32.1.46&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D32%26publication_year%3D2013%26pages%3D46-49%26journal%3DNeonatal%2BNetwork%26author%3DP.%2BNash%26title%3DAmniotic%2Bfluid%2Bindex&doi=10.1155%2F2015%2F319204&doiOfLink=10.1891%2F0730-0832.32.1.46&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 7Dubil E. A., Amniotic fluid as a vital sign for fetal wellbeing, _AJUM_. (2013) 16, no. 2, 62–70.





[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D16%26publication_year%3D2013%26pages%3D62-70%26journal%3DAJUM%26author%3DE.%2BA.%2BDubil%26title%3DAmniotic%2Bfluid%2Bas%2Ba%2Bvital%2Bsign%2Bfor%2Bfetal%2Bwellbeing&doi=10.1155%2F2015%2F319204&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 8Nabhan A. F. and
Abdelmoula Y. A., Amniotic fluid index versus single deepest vertical pocket as a screening test for preventing adverse pregnancy outcome, _The Cochrane Database of Systematic Reviews_. (2008) no. 3, CD006593, [https://doi.org/10.1002/14651858.CD006593.pub2](https://doi.org/10.1002/14651858.CD006593.pub2).

10.1002/14651858.CD006593.pub2



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=18646160&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1002%2F14651858.CD006593.pub2&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000257810900069&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1002%2F14651858.CD006593.pub2&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26publication_year%3D2008%26journal%3DThe%2BCochrane%2BDatabase%2Bof%2BSystematic%2BReviews%26author%3DA.%2BF.%2BNabhan%26author%3DY.%2BA.%2BAbdelmoula%26title%3DAmniotic%2Bfluid%2Bindex%2Bversus%2Bsingle%2Bdeepest%2Bvertical%2Bpocket%2Bas%2Ba%2Bscreening%2Btest%2Bfor%2Bpreventing%2Badverse%2Bpregnancy%2Boutcome&doi=10.1155%2F2015%2F319204&doiOfLink=10.1002%2F14651858.CD006593.pub2&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 9Phelan J. P.,
Ahn M. O.,
Smith C. V.,
Rutherford S. E., and
Anderson E., Amniotic fluid index measurements during pregnancy, _Journal of Reproductive Medicine for the Obstetrician and Gynecologist_. (1987) 32, no. 8, 601–604, 2-s2.0-0023270591.





[CAS](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=32&doi=10.1155%2F2015%2F319204&key=1%3ASTN%3A280%3ADyaL1c%252FhtV2qug%253D%253D&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=e_1_2_9_9_2%3ACOI&linkType=COI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D32%26publication_year%3D1987%26pages%3D601-604%26journal%3DJournal%2Bof%2BReproductive%2BMedicine%2Bfor%2Bthe%2BObstetrician%2Band%2BGynecologist%26author%3DJ.%2BP.%2BPhelan%26author%3DM.%2BO.%2BAhn%26author%3DC.%2BV.%2BSmith%26author%3DS.%2BE.%2BRutherford%26author%3DE.%2BAnderson%26title%3DAmniotic%2Bfluid%2Bindex%2Bmeasurements%2Bduring%2Bpregnancy&doi=10.1155%2F2015%2F319204&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 10Beall M. H.,
van den Wijngaard J. P. H. M.,
van Gemert M. J. C., and
Ross M. G., Amniotic fluid water dynamics, _Placenta_. (2007) 28, no. 8-9, 816–823, [https://doi.org/10.1016/j.placenta.2006.11.009](https://doi.org/10.1016/j.placenta.2006.11.009), 2-s2.0-34447506707.

10.1016/j.placenta.2006.11.009



[CAS](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=32&doi=10.1155%2F2015%2F319204&key=1%3ACAS%3A528%3ADC%252BD2sXotVGqt7w%253D&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2Fj.placenta.2006.11.009&linkType=COI&linkSource=FULL_TEXT&linkLocation=Reference)[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=17254633&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2Fj.placenta.2006.11.009&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000248720500008&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2Fj.placenta.2006.11.009&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D28%26publication_year%3D2007%26pages%3D816-823%26journal%3DPlacenta%26author%3DM.%2BH.%2BBeall%26author%3DJ.%2BP.%2BH.%2BM.%2Bvan%2Bden%2BWijngaard%26author%3DM.%2BJ.%2BC.%2Bvan%2BGemert%26author%3DM.%2BG.%2BRoss%26title%3DAmniotic%2Bfluid%2Bwater%2Bdynamics&doi=10.1155%2F2015%2F319204&doiOfLink=10.1016%2Fj.placenta.2006.11.009&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 11Phelan J. P.,
Smith C. V.,
Broussard P., and
Small M., Amniotic fluid volume assessment with the four-quadrant technique at 36–42 weeks′ gestation, _Journal of Reproductive Medicine_. (1987) 32, no. 7, 540–542, 2-s2.0-0023226864.





[CAS](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=32&doi=10.1155%2F2015%2F319204&key=1%3ASTN%3A280%3ADyaL2szhtFCmtw%253D%253D&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=e_1_2_9_11_2%3ACOI&linkType=COI&linkSource=FULL_TEXT&linkLocation=Reference)[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=3305930&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=e_1_2_9_11_2%3APMID&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=A1987J301200011&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=e_1_2_9_11_2%3AISI&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D32%26publication_year%3D1987%26pages%3D540-542%26journal%3DJournal%2Bof%2BReproductive%2BMedicine%26author%3DJ.%2BP.%2BPhelan%26author%3DC.%2BV.%2BSmith%26author%3DP.%2BBroussard%26author%3DM.%2BSmall%26title%3DAmniotic%2Bfluid%2Bvolume%2Bassessment%2Bwith%2Bthe%2Bfour-quadrant%2Btechnique%2Bat%2B36%25E2%2580%259342%2Bweeks%25E2%2580%25B2%2Bgestation&doi=10.1155%2F2015%2F319204&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 12Iqbal S. and
Noreen A., Low amniotic fluid index as a predictor of perinatal outcome in low risk pregnancies at term, _Pakistan Journal of Medical and Health Sciences_. (2010) 4, no. 3, 270–271, 2-s2.0-84866414816.





[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D4%26publication_year%3D2010%26pages%3D270-271%26journal%3DPakistan%2BJournal%2Bof%2BMedical%2Band%2BHealth%2BSciences%26author%3DS.%2BIqbal%26author%3DA.%2BNoreen%26title%3DLow%2Bamniotic%2Bfluid%2Bindex%2Bas%2Ba%2Bpredictor%2Bof%2Bperinatal%2Boutcome%2Bin%2Blow%2Brisk%2Bpregnancies%2Bat%2Bterm&doi=10.1155%2F2015%2F319204&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 13Voxman E. G.,
Tran S., and
Wing D. A., Low amniotic fluid index as a predictor of adverse perinatal outcome, _Journal of Perinatology_. (2002) 22, no. 4, 282–285, [https://doi.org/10.1038/sj/jp/7210697](https://doi.org/10.1038/sj/jp/7210697), 2-s2.0-0036276580.

10.1038/sj.jp.7210697



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=12032790&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1038%2Fsj.jp.7210697&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D22%26publication_year%3D2002%26pages%3D282-285%26journal%3DJournal%2Bof%2BPerinatology%26author%3DE.%2BG.%2BVoxman%26author%3DS.%2BTran%26author%3DD.%2BA.%2BWing%26title%3DLow%2Bamniotic%2Bfluid%2Bindex%2Bas%2Ba%2Bpredictor%2Bof%2Badverse%2Bperinatal%2Boutcome&doi=10.1155%2F2015%2F319204&doiOfLink=10.1038%2Fsj.jp.7210697&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 14Lalor J. G.,
Fawole B.,
Alfirevic Z., and
Devane D., Biophysical profile for fetal assessment in high risk pregnancies, _The Cochrane Database of Systematic Reviews_. (2008) no. 1, CD000038, 2-s2.0-41949117207, [https://doi.org/10.1002/14651858.CD000038.pub2](https://doi.org/10.1002/14651858.CD000038.pub2).

10.1002/14651858.CD000038.pub2



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=18253968&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1002%2F14651858.CD000038.pub2&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000252926800098&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1002%2F14651858.CD000038.pub2&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26publication_year%3D2008%26journal%3DThe%2BCochrane%2BDatabase%2Bof%2BSystematic%2BReviews%26author%3DJ.%2BG.%2BLalor%26author%3DB.%2BFawole%26author%3DZ.%2BAlfirevic%26author%3DD.%2BDevane%26title%3DBiophysical%2Bprofile%2Bfor%2Bfetal%2Bassessment%2Bin%2Bhigh%2Brisk%2Bpregnancies&doi=10.1155%2F2015%2F319204&doiOfLink=10.1002%2F14651858.CD000038.pub2&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 15Signore C.,
Freeman R. K., and
Spong C. Y., Antenatal testing-a reevaluation: executive summary of a Eunice Kennedy Shriver National Institute of Child Health and Human Development wrkshop, _Obstetrics and Gynecology_. (2009) 113, no. 3, 687–701, [https://doi.org/10.1097/aog.0b013e318197bd8a](https://doi.org/10.1097/aog.0b013e318197bd8a), 2-s2.0-64249083701.

10.1097/AOG.0b013e318197bd8a



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=19300336&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1097%2FAOG.0b013e318197bd8a&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000263750000018&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1097%2FAOG.0b013e318197bd8a&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D113%26publication_year%3D2009%26pages%3D687-701%26journal%3DObstetrics%2Band%2BGynecology%26author%3DC.%2BSignore%26author%3DR.%2BK.%2BFreeman%26author%3DC.%2BY.%2BSpong%26title%3DAntenatal%2Btesting-a%2Breevaluation%253A%2Bexecutive%2Bsummary%2Bof%2Ba%2BEunice%2BKennedy%2BShriver%2BNational%2BInstitute%2Bof%2BChild%2BHealth%2Band%2BHuman%2BDevelopment%2Bwrkshop&doi=10.1155%2F2015%2F319204&doiOfLink=10.1097%2FAOG.0b013e318197bd8a&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 16Khadilkar S. S.,
Desai S. S.,
Tayade S. M., and
Purandare C. N., Amniotic fluid index in normal pregnancy: an assessment of gestation specific reference values among Indian women, _Journal of Obstetrics and Gynaecology Research_. (2003) 29, no. 3, 136–141, [https://doi.org/10.1046/j.1341-8076.2003.00089.x](https://doi.org/10.1046/j.1341-8076.2003.00089.x), 2-s2.0-0038305327.

10.1046/j.1341-8076.2003.00089.x



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=12841695&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1046%2Fj.1341-8076.2003.00089.x&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000182797700003&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1046%2Fj.1341-8076.2003.00089.x&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D29%26publication_year%3D2003%26pages%3D136-141%26journal%3DJournal%2Bof%2BObstetrics%2Band%2BGynaecology%2BResearch%26author%3DS.%2BS.%2BKhadilkar%26author%3DS.%2BS.%2BDesai%26author%3DS.%2BM.%2BTayade%26author%3DC.%2BN.%2BPurandare%26title%3DAmniotic%2Bfluid%2Bindex%2Bin%2Bnormal%2Bpregnancy%253A%2Ban%2Bassessment%2Bof%2Bgestation%2Bspecific%2Breference%2Bvalues%2Bamong%2BIndian%2Bwomen&doi=10.1155%2F2015%2F319204&doiOfLink=10.1046%2Fj.1341-8076.2003.00089.x&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 17Cohen J., Statistical Power Analysis for the Behavioral Sciences, 1988, 2nd edition, Lawrence Earlbaum Associates, Hillsdale, NJ, USA.

10.1046/j.1526-4610.2001.111006343.x



[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26publication_year%3D1988%26author%3DJ.%2BCohen%26title%3DStatistical%2BPower%2BAnalysis%2Bfor%2Bthe%2BBehavioral%2BSciences&doi=10.1155%2F2015%2F319204&doiOfLink=10.1046%2Fj.1526-4610.2001.111006343.x&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 18Brace R. A. and
Wolf E. J., Normal amniotic fluid volume changes throughout pregnancy, _The American Journal of Obstetrics and Gynecology_. (1989) 161, no. 2, 382– 388, [https://doi.org/10.1016/0002-9378(89)90527-9](https://doi.org/10.1016/0002-9378(89)90527-9), 2-s2.0-0024323628.

10.1016/0002-9378(89)90527-9



[CAS](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=32&doi=10.1155%2F2015%2F319204&key=1%3ASTN%3A280%3ADyaL1MzkvFaltQ%253D%253D&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2F0002-9378%2889%2990527-9&linkType=COI&linkSource=FULL_TEXT&linkLocation=Reference)[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=2764058&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2F0002-9378%2889%2990527-9&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=A1989AL05600034&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2F0002-9378%2889%2990527-9&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D161%26publication_year%3D1989%26pages%3D382-%2B388%26journal%3DThe%2BAmerican%2BJournal%2Bof%2BObstetrics%2Band%2BGynecology%26author%3DR.%2BA.%2BBrace%26author%3DE.%2BJ.%2BWolf%26title%3DNormal%2Bamniotic%2Bfluid%2Bvolume%2Bchanges%2Bthroughout%2Bpregnancy&doi=10.1155%2F2015%2F319204&doiOfLink=10.1016%2F0002-9378%2889%2990527-9&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 19Moore T. R. and
Cayle J. E., The amniotic fluid index in normal human pregnancy, _American Journal of Obstetrics & Gynecology_. (1990) 162, no. 5, 1168–1173, [https://doi.org/10.1016/0002-9378(90)90009-v](https://doi.org/10.1016/0002-9378(90)90009-v), 2-s2.0-0025341260.

10.1016/0002-9378(90)90009-V



[CAS](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=32&doi=10.1155%2F2015%2F319204&key=1%3ASTN%3A280%3ADyaK3c3lt1ygtA%253D%253D&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2F0002-9378%2890%2990009-V&linkType=COI&linkSource=FULL_TEXT&linkLocation=Reference)[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=2187347&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2F0002-9378%2890%2990009-V&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=A1990DD89300009&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2F0002-9378%2890%2990009-V&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D162%26publication_year%3D1990%26pages%3D1168-1173%26journal%3DAmerican%2BJournal%2Bof%2BObstetrics%2B%2526%2BGynecology%26author%3DT.%2BR.%2BMoore%26author%3DJ.%2BE.%2BCayle%26title%3DThe%2Bamniotic%2Bfluid%2Bindex%2Bin%2Bnormal%2Bhuman%2Bpregnancy&doi=10.1155%2F2015%2F319204&doiOfLink=10.1016%2F0002-9378%2890%2990009-V&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 20Magann E. F.,
Sandlin A. T., and
Ounpraseuth S. T., Amniotic fluid and the clinical relevance of the sonographically estimated amniotic fluid volume: oligohydramnios, _Journal of Ultrasound in Medicine_. (2011) 30, no. 11, 1573–1585, 2-s2.0-80655139769.

10.7863/jum.2011.30.11.1573



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=22039031&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.7863%2Fjum.2011.30.11.1573&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000296936600015&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.7863%2Fjum.2011.30.11.1573&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D30%26publication_year%3D2011%26pages%3D1573-1585%26journal%3DJournal%2Bof%2BUltrasound%2Bin%2BMedicine%26author%3DE.%2BF.%2BMagann%26author%3DA.%2BT.%2BSandlin%26author%3DS.%2BT.%2BOunpraseuth%26title%3DAmniotic%2Bfluid%2Band%2Bthe%2Bclinical%2Brelevance%2Bof%2Bthe%2Bsonographically%2Bestimated%2Bamniotic%2Bfluid%2Bvolume%253A%2Boligohydramnios&doi=10.1155%2F2015%2F319204&doiOfLink=10.7863%2Fjum.2011.30.11.1573&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 21Lee S. M.,
Park S. K.,
Shim S. S.,
Jun J. K.,
Park J. S., and
Syn H. C., Measurement of fetal urine production by three-dimensional ultrasonography in normal pregnancy, _Ultrasound in Obstetrics and Gynecology_. (2007) 30, no. 3, 281–286, [https://doi.org/10.1002/uog.4038](https://doi.org/10.1002/uog.4038), 2-s2.0-34748825631.

10.1002/uog.4038



[CAS](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=32&doi=10.1155%2F2015%2F319204&key=1%3ASTN%3A280%3ADC%252BD2srgslCjug%253D%253D&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1002%2Fuog.4038&linkType=COI&linkSource=FULL_TEXT&linkLocation=Reference)[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=17628483&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1002%2Fuog.4038&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000249962300009&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1002%2Fuog.4038&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D30%26publication_year%3D2007%26pages%3D281-286%26journal%3DUltrasound%2Bin%2BObstetrics%2Band%2BGynecology%26author%3DS.%2BM.%2BLee%26author%3DS.%2BK.%2BPark%26author%3DS.%2BS.%2BShim%26author%3DJ.%2BK.%2BJun%26author%3DJ.%2BS.%2BPark%26author%3DH.%2BC.%2BSyn%26title%3DMeasurement%2Bof%2Bfetal%2Burine%2Bproduction%2Bby%2Bthree-dimensional%2Bultrasonography%2Bin%2Bnormal%2Bpregnancy&doi=10.1155%2F2015%2F319204&doiOfLink=10.1002%2Fuog.4038&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 22Hinh N. D. and
Ladinsky J. L., Amniotic fluid index measurements in normal pregnancy after 28 gestational weeks, _International Journal of Gynecology & Obstetrics_. (2005) 91, no. 2, 132–136, [https://doi.org/10.1016/j.ijgo.2005.07.007](https://doi.org/10.1016/j.ijgo.2005.07.007), 2-s2.0-26844452828.

10.1016/j.ijgo.2005.07.007



[CAS](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=32&doi=10.1155%2F2015%2F319204&key=1%3ASTN%3A280%3ADC%252BD2Mrmt1Gmtg%253D%253D&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2Fj.ijgo.2005.07.007&linkType=COI&linkSource=FULL_TEXT&linkLocation=Reference)[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=16126206&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2Fj.ijgo.2005.07.007&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000233659800003&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2Fj.ijgo.2005.07.007&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D91%26publication_year%3D2005%26pages%3D132-136%26journal%3DInternational%2BJournal%2Bof%2BGynecology%2B%2526%2BObstetrics%26author%3DN.%2BD.%2BHinh%26author%3DJ.%2BL.%2BLadinsky%26title%3DAmniotic%2Bfluid%2Bindex%2Bmeasurements%2Bin%2Bnormal%2Bpregnancy%2Bafter%2B28%2Bgestational%2Bweeks&doi=10.1155%2F2015%2F319204&doiOfLink=10.1016%2Fj.ijgo.2005.07.007&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 23MacHado M. R.,
Cecatti J. G.,
Krupa F., and
Faundes A., Curve of amniotic fluid index measurements in low-risk pregnancy, _Acta Obstetricia et Gynecologica Scandinavica_. (2007) 86, no. 1, 37–41, 2-s2.0-33845806367, [https://doi.org/10.1080/00016340600994976](https://doi.org/10.1080/00016340600994976).

10.1080/00016340600994976



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=17230287&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1080%2F00016340600994976&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000246475900007&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1080%2F00016340600994976&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D86%26publication_year%3D2007%26pages%3D37-41%26journal%3DActa%2BObstetricia%2Bet%2BGynecologica%2BScandinavica%26author%3DM.%2BR.%2BMacHado%26author%3DJ.%2BG.%2BCecatti%26author%3DF.%2BKrupa%26author%3DA.%2BFaundes%26title%3DCurve%2Bof%2Bamniotic%2Bfluid%2Bindex%2Bmeasurements%2Bin%2Blow-risk%2Bpregnancy&doi=10.1155%2F2015%2F319204&doiOfLink=10.1080%2F00016340600994976&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 24Birang S., Ultrasonographic assessment of normal amniotic fluid index in a group of Iranian women, _Iranian Journal of Radiology_. (2008) 5, no. 1, 31–34, 2-s2.0-77953462697.





[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000267245300006&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=e_1_2_9_24_2%3AISI&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D5%26publication_year%3D2008%26pages%3D31-34%26journal%3DIranian%2BJournal%2Bof%2BRadiology%26author%3DS.%2BBirang%26title%3DUltrasonographic%2Bassessment%2Bof%2Bnormal%2Bamniotic%2Bfluid%2Bindex%2Bin%2Ba%2Bgroup%2Bof%2BIranian%2Bwomen&doi=10.1155%2F2015%2F319204&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 25Singh C.,
Tayal T.,
Gupta R.,
Sharma A. P.,
Khurana D., and
Kaul A., Amniotic fluid index in healthy pregnancy in an Indian population, _International Journal of Gynecology and Obstetrics_. (2013) 121, no. 2, 176–177, [https://doi.org/10.1016/j.ijgo.2013.01.003](https://doi.org/10.1016/j.ijgo.2013.01.003), 2-s2.0-84876051753.

10.1016/j.ijgo.2013.01.003



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=23394873&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2Fj.ijgo.2013.01.003&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=000318137400019&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2Fj.ijgo.2013.01.003&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D121%26publication_year%3D2013%26pages%3D176-177%26journal%3DInternational%2BJournal%2Bof%2BGynecology%2Band%2BObstetrics%26author%3DC.%2BSingh%26author%3DT.%2BTayal%26author%3DR.%2BGupta%26author%3DA.%2BP.%2BSharma%26author%3DD.%2BKhurana%26author%3DA.%2BKaul%26title%3DAmniotic%2Bfluid%2Bindex%2Bin%2Bhealthy%2Bpregnancy%2Bin%2Ban%2BIndian%2Bpopulation&doi=10.1155%2F2015%2F319204&doiOfLink=10.1016%2Fj.ijgo.2013.01.003&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 26Rosenthal R. and
Rosnow R. L., Essentials of Behavioral Research: Methods and Data Analysis, 1991, 2nd edition, McGraw Hill, New York, NY, USA.





[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=A1991GP73700015&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=e_1_2_9_26_2%3AISI&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26publication_year%3D1991%26author%3DR.%2BRosenthal%26author%3DR.%2BL.%2BRosnow%26title%3DEssentials%2Bof%2BBehavioral%2BResearch%253A%2BMethods%2Band%2BData%2BAnalysis&doi=10.1155%2F2015%2F319204&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)

- 27Richardson J. T. E., Eta squared and partial eta squared as measures of effect size in educational research, _Educational Research Review_. (2011) 6, no. 2, 135–147, [https://doi.org/10.1016/j.edurev.2010.12.001](https://doi.org/10.1016/j.edurev.2010.12.001), 2-s2.0-79957645252.

10.1016/j.edurev.2010.12.001



[PubMed](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=8&doi=10.1155%2F2015%2F319204&key=7696869&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2Fj.edurev.2010.12.001&linkType=PMID&linkSource=FULL_TEXT&linkLocation=Reference)[Web of Science®](https://onlinelibrary.wiley.com/servlet/linkout?suffix=null&dbid=128&doi=10.1155%2F2015%2F319204&key=WOS%3A000293051700004&getFTLinkType=true&doiForPubOfPage=10.1155%2F2015%2F319204&refDoi=10.1016%2Fj.edurev.2010.12.001&linkType=ISI&linkSource=FULL_TEXT&linkLocation=Reference)[Google Scholar](https://onlinelibrary.wiley.com/action/getFTRLinkout?url=http%3A%2F%2Fscholar.google.com%2Fscholar_lookup%3Fhl%3Den%26volume%3D6%26publication_year%3D2011%26pages%3D135-147%26journal%3DEducational%2BResearch%2BReview%26author%3DJ.%2BT.%2BE.%2BRichardson%26title%3DEta%2Bsquared%2Band%2Bpartial%2Beta%2Bsquared%2Bas%2Bmeasures%2Bof%2Beffect%2Bsize%2Bin%2Beducational%2Bresearch&doi=10.1155%2F2015%2F319204&doiOfLink=10.1016%2Fj.edurev.2010.12.001&linkType=gs&linkLocation=Reference&linkSource=FULL_TEXT)


## Citing Literature

- [![All articles](https://onlinelibrary.wiley.com/cms/asset/22e785a1-a1a3-4380-bee9-4aa8f888db0a/default_cover.jpg)](https://onlinelibrary.wiley.com/index/7097 "All articles")

[All articles  >](https://onlinelibrary.wiley.com/index/7097 "All articles")


[![](https://static.adzerk.net/Advertisers/6ed6ea5dcd2141709902f6122905a70b.png)](https://ssai.onlinelibrary.wiley.com/r?e=eyJ2IjoiMS4xMyIsImF2IjoyNjI5MzQ4LCJhdCI6NSwiYnQiOjAsImNtIjozODY3MTc1NzgsImNoIjo2MTE0NywiY2siOnt9LCJjciI6NTQ5OTk1OTc0LCJkaSI6IjRjM2M5NzY5ODhjMzQ3MDE4YTFjYzQ2YmRiZjEyOGFiIiwiZGoiOjAsImlpIjoiYTllZjgyZWI2YWJjNDY0NzlkODE1M2M4N2M1OGNkOTQiLCJkbSI6MywiZmMiOjgzNDYyOTIxMSwiZmwiOjc5Nzk5MzY3NiwiaXAiOiI1LjE4My45MS4xNTUiLCJrdyI6InBvcy1yYWlsMSxwbGYtd29sLGFzc2lkLTEwLjExNTUvMjAxNS8zMTkyMDQsdm9sLTIwMTUsaXNzLTEsYXhzLW9wZW4iLCJtayI6InBvcy1yYWlsMSIsIm53IjoxMTQ5MiwicGMiOjAsIm9wIjowLCJtcCI6MCwiZWMiOjAsImdtIjowLCJlcCI6bnVsbCwicHIiOjI0MDAzNywicnQiOjEsInJzIjo1MDAsInNhIjoiOTciLCJzYiI6ImktMDU3MmQ5OTY4OGFkZDE3MGMiLCJzcCI6MjgyMTk1OCwic3QiOjEzMDI4NjAsInVrIjoidWUxLTk4NDM4MWJlMDFhMzQwOTViOTI2MzM2YzkyNGYyZWJkIiwiem4iOjMwNzM3MCwiem0iOlszMDczNzBdLCJ0cyI6MTc1MTE5NzA2Mzc1OSwiYmYiOnRydWUsInBuIjoiMTMxOWMxMWYtODcyOC00ZDFiLWE4NDQtZTI3ZGY5NzdlNWM1IiwiZ3IiOnRydWUsImdjIjp0cnVlLCJnQyI6dHJ1ZSwiZ3MiOiJub25lIiwidHoiOiJVVEMiLCJ1ciI6Imh0dHBzOi8vY29ycG9yYXRlc29sdXRpb25zLndpbGV5LmNvbS9yZXN1bHRzLz91dG1fc291cmNlPVdpbGV5JnV0bV9tZWRpdW09V09MJnV0bV9jYW1wYWlnbj1NZWRpYUtpdHMifQ&s=nNwsz_dbF7JYTpF-8amljDaCTLc "")

- [**Figures**](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#pane-pcw-figures)
- [**References**](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#pane-pcw-references)
- [**Related**](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#pane-pcw-related)
- [**Information**](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#pane-pcw-details)

### Recommended

- [Sonographic measurement of amniotic fluid volume in the first trimester of pregnancy.](https://onlinelibrary.wiley.com/doi/full/10.7863/jum.1996.15.11.771)



[A Weissman](https://onlinelibrary.wiley.com/authored-by/Weissman/A), [J Itskovitz-Eldor](https://onlinelibrary.wiley.com/authored-by/Itskovitz-Eldor/J), [P Jakobi](https://onlinelibrary.wiley.com/authored-by/Jakobi/P),



[Journal of Ultrasound in Medicine](https://onlinelibrary.wiley.com/journal/15509613)

- [Biochemical composition of amniotic fluid and extraembryonic coelomic fluid in the first trimester of pregnancy](https://obgyn.onlinelibrary.wiley.com/doi/full/10.1111/j.1471-0528.1992.tb13821.x)



[JAMES CAMPBELL](https://onlinelibrary.wiley.com/authored-by/CAMPBELL/JAMES), [NEVILLE WATHEN](https://onlinelibrary.wiley.com/authored-by/WATHEN/NEVILLE), [MARY MACINTOSH](https://onlinelibrary.wiley.com/authored-by/MACINTOSH/MARY), [PETER CASS](https://onlinelibrary.wiley.com/authored-by/CASS/PETER), [TIM CHARD](https://onlinelibrary.wiley.com/authored-by/CHARD/TIM), [RICHARD MAINWARING-BURTON](https://onlinelibrary.wiley.com/authored-by/MAINWARING%E2%80%90BURTON/RICHARD),



[BJOG: An International Journal of Obstetrics & Gynaecology](https://obgyn.onlinelibrary.wiley.com/journal/14710528)

- [Accuracy of the Ultrasound Estimate of the Amniotic Fluid Volume (Amniotic Fluid Index and Single Deepest Pocket) to Identify Actual Low, Normal, and High Amniotic Fluid Volumes as Determined by Quantile Regression](https://onlinelibrary.wiley.com/doi/full/10.1002/jum.15116)



[Dawn S. Hughes MD](https://onlinelibrary.wiley.com/authored-by/Hughes/Dawn+S.), [Everett F. Magann MD](https://onlinelibrary.wiley.com/authored-by/Magann/Everett+F.), [Julie R. Whittington MD](https://onlinelibrary.wiley.com/authored-by/Whittington/Julie+R.), [Michael P. Wendel MD](https://onlinelibrary.wiley.com/authored-by/Wendel/Michael+P.), [Adam T. Sandlin MD](https://onlinelibrary.wiley.com/authored-by/Sandlin/Adam+T.), [Songthip T. Ounpraseuth PhD](https://onlinelibrary.wiley.com/authored-by/Ounpraseuth/Songthip+T.),



[Journal of Ultrasound in Medicine](https://onlinelibrary.wiley.com/journal/15509613)

- [Single deepest vertical pocket or amniotic fluid index as evaluation test for predicting adverse pregnancy outcome (SAFE trial): a multicenter, open‐label, randomized controlled trial](https://obgyn.onlinelibrary.wiley.com/doi/full/10.1002/uog.14924)



[S. Kehl](https://onlinelibrary.wiley.com/authored-by/Kehl/S.), [A. Schelkle](https://onlinelibrary.wiley.com/authored-by/Schelkle/A.), [A. Thomas](https://onlinelibrary.wiley.com/authored-by/Thomas/A.), [A. Puhl](https://onlinelibrary.wiley.com/authored-by/Puhl/A.), [K. Meqdad](https://onlinelibrary.wiley.com/authored-by/Meqdad/K.), [B. Tuschy](https://onlinelibrary.wiley.com/authored-by/Tuschy/B.), [S. Berlit](https://onlinelibrary.wiley.com/authored-by/Berlit/S.), [C. Weiss](https://onlinelibrary.wiley.com/authored-by/Weiss/C.), [C. Bayer](https://onlinelibrary.wiley.com/authored-by/Bayer/C.), [J. Heimrich](https://onlinelibrary.wiley.com/authored-by/Heimrich/J.), [U. Dammer](https://onlinelibrary.wiley.com/authored-by/Dammer/U.), [E. Raabe](https://onlinelibrary.wiley.com/authored-by/Raabe/E.), [M. Winkler](https://onlinelibrary.wiley.com/authored-by/Winkler/M.), [F. Faschingbauer](https://onlinelibrary.wiley.com/authored-by/Faschingbauer/F.), [M. W. Beckmann](https://onlinelibrary.wiley.com/authored-by/Beckmann/M.+W.), [M. Sütterlin](https://onlinelibrary.wiley.com/authored-by/S%C3%BCtterlin/M.),



[Ultrasound in Obstetrics & Gynecology](https://obgyn.onlinelibrary.wiley.com/journal/14690705)


### Metrics

Citations: 8

![Article has an altmetric score of 1](https://d1uo4w7k31k5mn.cloudfront.net/v1/1.png)

### Details

Copyright © 2015 Shripad Hebbar et al.

This is an open access article distributed under the [Creative Commons Attribution License](http://creativecommons.org/licenses/by/3.0/ "Link to external resource"), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.

- Check for updates

### Publication History

- Issue Online: 15 January 2015
- Version of Record online: 15 January 2015
- Manuscript accepted: 20 November 2014
- Manuscript revised: 18 November 2014
- Manuscript received: 31 July 2014

![](https://onlinelibrary.wiley.com/specs/products/acropolis/pericles/releasedAssets/images/spinner-1ffd60b3aabe5b09bc98c48345208fd9.gif)

[![](https://s.zkcdn.net/Advertisers/fa79325b25f5493999ae0837dad01240.png)](https://ssai.onlinelibrary.wiley.com/r?e=eyJ2IjoiMS4xMyIsImF2IjoyNjI5MzQ4LCJhdCI6NSwiYnQiOjAsImNtIjozODY3MTc1NzgsImNoIjo2MTE0NywiY2siOnt9LCJjciI6NjMwNTg5NTkyLCJkaSI6IjYyODA0YjIzZjZjNTRkYzBhNGFlZjMyZTkyYTg4OWMwIiwiZGoiOjAsImlpIjoiNzFhZjcwNTUwMzg5NDNiNDg0MDcyYWVmN2MyNzhjZjgiLCJkbSI6MywiZmMiOjgzNDYyOTIwNCwiZmwiOjc5Nzk5MzY3NiwiaXAiOiI1LjE4My45MS4xNTUiLCJrdyI6InBvcy1yYWlsMixwbGYtd29sLGFzc2lkLTEwLjExNTUvMjAxNS8zMTkyMDQsdm9sLTIwMTUsaXNzLTEsYXhzLW9wZW4iLCJtayI6InBvcy1yYWlsMiIsIm53IjoxMTQ5MiwicGMiOjAsIm9wIjowLCJtcCI6MCwiZWMiOjAsImdtIjowLCJlcCI6bnVsbCwicHIiOjI0MDAzNywicnQiOjEsInJzIjo1MDAsInNhIjoiOTciLCJzYiI6ImktMDgxYmQzMDc5MzhjZWJlMzAiLCJzcCI6MjgyODMyOSwic3QiOjEzMDI4NjAsInVrIjoidWUxLTM3NDllNzg2ODJhODQ0YWVhZGRhNzJlMGU0YWE2YzEzIiwiem4iOjMwNzM3MCwiem0iOlszMDczNzBdLCJ0cyI6MTc1MTE5NzA2Mzc1NCwiYmYiOnRydWUsInBuIjoiYjNiNWQyMTgtNTIzZC00NWQ5LTg2ODAtMzBjMmY2YzIwMmJjIiwiZ3IiOnRydWUsImdjIjp0cnVlLCJnQyI6dHJ1ZSwiZ3MiOiJub25lIiwidHoiOiJVVEMiLCJ1ciI6Imh0dHBzOi8vd3d3LndpbGV5LmNvbS9lbi1nYi9idXNpbmVzcy9yZXNlYXJjaC9jb3Jwb3JhdGUtc29sdXRpb25zP3V0bV9zb3VyY2U9V2lsZXkmdXRtX21lZGl1bT1XT0xiYW5uZXJzJnV0bV9jYW1wYWlnbj04NjgwMzkifQ&s=wALDHSu1nk4jATGBXoQY2-kWp4k "")

[Close Figure Viewer](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204# "close")

[Previous Figure](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204# "previous figure") [Next Figure](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204# "next figure")

[Caption](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204# "Open/Close Caption")

[Download PDF](https://onlinelibrary.wiley.com/doi/pdf/10.1155/2015/319204)

back

The full text of this article hosted at iucr.org is unavailable due to technical difficulties.

Teaser Component

Copy link

✓

Thanks for sharing!

Find any service

[AddToAny](https://www.addtoany.com/ "Share Buttons")

[More…](https://onlinelibrary.wiley.com/doi/10.1155/2015/319204#addtoany "Show all")

A2A

Close crossmark popup

[Posted by **1** X users](https://www.altmetric.com/details.php?domain=onlinelibrary.wiley.com&citation_id=3707085&tab=twitter)

**107** readers on Mendeley


[See more details](https://www.altmetric.com/details.php?domain=onlinelibrary.wiley.com&citation_id=3707085)

---

## Source 3: www.mdpi.com {#source-3}

**URL:** https://www.mdpi.com/1424-8220/22/12/4570
**Content Type:** Web Content
**Content Length:** 1,22,894 characters
**Scraped At:** 2025-06-29T11:38:04.392Z

**Detected Structure:** Tables

### Content:

[iframe](about:blank)

Next Article in Journal

[Assessment of the Effect of Soil Sample Preparation, Water Content and Excitation Time on Proximal X-ray Fluorescence Sensing](https://www.mdpi.com/1424-8220/22/12/4572)

Next Article in Special Issue

[ROSEBUD: A Deep Fluvial Segmentation Dataset for Monocular Vision-Based River Navigation and Obstacle Avoidance](https://www.mdpi.com/1424-8220/22/13/4681)

Previous Article in Journal

[Toward a Structural Health Monitoring Methodology for Concrete Structures under Dynamic Loads Using Embedded FBG Sensors and Strain Mapping Techniques](https://www.mdpi.com/1424-8220/22/12/4569)

Previous Article in Special Issue

[A3C-TL-GTO: Alzheimer Automatic Accurate Classification Using Transfer Learning and Artificial Gorilla Troops Optimizer](https://www.mdpi.com/1424-8220/22/11/4250)

## Journals

[Active Journals](https://www.mdpi.com/about/journals) [Find a Journal](https://www.mdpi.com/about/journalfinder) [Journal Proposal](https://www.mdpi.com/about/journals/proposal) [Proceedings Series](https://www.mdpi.com/about/proceedings)

[**Topics**](https://www.mdpi.com/topics)

## Information

[For Authors](https://www.mdpi.com/authors) [For Reviewers](https://www.mdpi.com/reviewers) [For Editors](https://www.mdpi.com/editors) [For Librarians](https://www.mdpi.com/librarians) [For Publishers](https://www.mdpi.com/publishing_services) [For Societies](https://www.mdpi.com/societies) [For Conference Organizers](https://www.mdpi.com/conference_organizers)

[Open Access Policy](https://www.mdpi.com/openaccess) [Institutional Open Access Program](https://www.mdpi.com/ioap) [Special Issues Guidelines](https://www.mdpi.com/special_issues_guidelines) [Editorial Process](https://www.mdpi.com/editorial_process) [Research and Publication Ethics](https://www.mdpi.com/ethics) [Article Processing Charges](https://www.mdpi.com/apc) [Awards](https://www.mdpi.com/awards) [Testimonials](https://www.mdpi.com/testimonials)

[**Author Services**](https://www.mdpi.com/authors/english)

## Initiatives

[Sciforum](https://sciforum.net/) [MDPI Books](https://www.mdpi.com/books) [Preprints.org](https://www.preprints.org/) [Scilit](https://www.scilit.com/) [SciProfiles](https://sciprofiles.com/) [Encyclopedia](https://encyclopedia.pub/) [JAMS](https://jams.pub/) [Proceedings Series](https://www.mdpi.com/about/proceedings)

## About

[Overview](https://www.mdpi.com/about) [Contact](https://www.mdpi.com/about/contact) [Careers](https://careers.mdpi.com/) [News](https://www.mdpi.com/about/announcements) [Press](https://www.mdpi.com/about/press) [Blog](http://blog.mdpi.com/)

[Sign In / Sign Up](https://www.mdpi.com/user/login)

## Notice

You can make submissions to other journals
[here](https://susy.mdpi.com/user/manuscripts/upload).


_clear_

## Notice

You are accessing a machine-readable page. In order to be human-readable, please install an RSS reader.


ContinueCancel

_clear_

All articles published by MDPI are made immediately available worldwide under an open access license. No special
permission is required to reuse all or part of the article published by MDPI, including figures and tables. For
articles published under an open access Creative Common CC BY license, any part of the article may be reused without
permission provided that the original article is clearly cited. For more information, please refer to
[https://www.mdpi.com/openaccess](https://www.mdpi.com/openaccess).


Feature papers represent the most advanced research with significant potential for high impact in the field. A Feature
Paper should be a substantial original Article that involves several techniques or approaches, provides an outlook for
future research directions and describes possible research applications.


Feature papers are submitted upon individual invitation or recommendation by the scientific editors and must receive
positive feedback from the reviewers.


Editor’s Choice articles are based on recommendations by the scientific editors of MDPI journals from around the world.
Editors select a small number of articles recently published in the journal that they believe will be particularly
interesting to readers, or important in the respective research area. The aim is to provide a snapshot of some of the
most exciting work published in the various research areas of the journal.



Original Submission Date Received: .


[![sensors-logo](https://pub.mdpi-res.com/img/journals/sensors-logo.png?8600e93ff98dbf14)](https://www.mdpi.com/journal/sensors)

[Submit to this Journal](https://susy.mdpi.com/user/manuscripts/upload?form%5Bjournal_id%5D%3D3) [Review for this Journal](https://susy.mdpi.com/volunteer/journals/review) [Propose a Special Issue](https://www.mdpi.com/journalproposal/sendproposalspecialissue/sensors)

[►▼\\
Article Menu](https://www.mdpi.com/1424-8220/22/12/4570#)

## Article Menu

- [Academic Editors](https://www.mdpi.com/1424-8220/22/12/4570#academic_editors)






![](https://pub.mdpi-res.com/bundles/mdpisciprofileslink/img/unknown-user.png?1750928612)Biswajeet Pradhan











![](https://pub.mdpi-res.com/bundles/mdpisciprofileslink/img/unknown-user.png?1750928612)Subrata Chakraborty

- [Subscribe SciFeed](https://www.mdpi.com/1424-8220/22/12/4570/scifeed_display)
- [Recommended Articles](https://www.mdpi.com/1424-8220/22/12/4570#)
- [Related Info Links](https://www.mdpi.com/1424-8220/22/12/4570#related)


- [PubMed/Medline](http://www.ncbi.nlm.nih.gov/sites/entrez/35746352)
- [Google Scholar](http://scholar.google.com/scholar?q=Amniotic%20Fluid%20Classification%20and%20Artificial%20Intelligence%3A%20Challenges%20and%20Opportunities)

- [More by Authors Links](https://www.mdpi.com/1424-8220/22/12/4570#authors)


- on DOAJ

- [Khan, I. Ullah](http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Irfan%20Ullah%20Khan%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D)
- [Aslam, N.](http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Nida%20Aslam%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D)
- [Anis, F. M.](http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Fatima%20M.%20Anis%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D)
- [Mirza, S.](http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Samiha%20Mirza%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D)
- [AlOwayed, A.](http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Alanoud%20AlOwayed%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D)
- [Aljuaid, R. M.](http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Reef%20M.%20Aljuaid%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D)
- [Bakr, R. M.](http://doaj.org/search/articles?source=%7B%22query%22%3A%7B%22query_string%22%3A%7B%22query%22%3A%22%5C%22Razan%20M.%20Bakr%5C%22%22%2C%22default_operator%22%3A%22AND%22%2C%22default_field%22%3A%22bibjson.author.name%22%7D%7D%7D)

- on Google Scholar

- [Khan, I. Ullah](http://scholar.google.com/scholar?q=Irfan%20Ullah%20Khan)
- [Aslam, N.](http://scholar.google.com/scholar?q=Nida%20Aslam)
- [Anis, F. M.](http://scholar.google.com/scholar?q=Fatima%20M.%20Anis)
- [Mirza, S.](http://scholar.google.com/scholar?q=Samiha%20Mirza)
- [AlOwayed, A.](http://scholar.google.com/scholar?q=Alanoud%20AlOwayed)
- [Aljuaid, R. M.](http://scholar.google.com/scholar?q=Reef%20M.%20Aljuaid)
- [Bakr, R. M.](http://scholar.google.com/scholar?q=Razan%20M.%20Bakr)

- on PubMed

- [Khan, I. Ullah](http://www.pubmed.gov/?cmd=Search&term=Irfan%20Ullah%20Khan)
- [Aslam, N.](http://www.pubmed.gov/?cmd=Search&term=Nida%20Aslam)
- [Anis, F. M.](http://www.pubmed.gov/?cmd=Search&term=Fatima%20M.%20Anis)
- [Mirza, S.](http://www.pubmed.gov/?cmd=Search&term=Samiha%20Mirza)
- [AlOwayed, A.](http://www.pubmed.gov/?cmd=Search&term=Alanoud%20AlOwayed)
- [Aljuaid, R. M.](http://www.pubmed.gov/?cmd=Search&term=Reef%20M.%20Aljuaid)
- [Bakr, R. M.](http://www.pubmed.gov/?cmd=Search&term=Razan%20M.%20Bakr)

/ajax/scifeed/subscribe

[Article Views](https://www.mdpi.com/1424-8220/22/12/4570#metrics)

[Citations-](https://www.mdpi.com/1424-8220/22/12/4570#metrics)

- [Table of Contents](https://www.mdpi.com/1424-8220/22/12/4570#table_of_contents)


Altmetric[_share_ Share](https://www.mdpi.com/1424-8220/22/12/4570# "Share") [_announcement_ Help](https://www.mdpi.com/1424-8220/22/12/4570# "Help") [_format\_quote_ Cite](javascript:void(0);) [_question\_answer_ Discuss in SciProfiles](https://sciprofiles.com/discussion-groups/public/10.3390/s22124570?utm_source=mpdi.com&utm_medium=publication&utm_campaign=discuss_in_sciprofiles "Discuss in Sciprofiles")

## Need Help?

### Support

Find support for a specific problem in the support section of our website.


[Get Support](https://www.mdpi.com/about/contactform)

### Feedback

Please let us know what you think of our products and services.


[Give Feedback](https://www.mdpi.com/feedback/send)

### Information

Visit our dedicated information section to learn more about MDPI.


[Get Information](https://www.mdpi.com/authors)

_clear_

## JSmol Viewer

_clear_

_first\_page_

[Download PDF](https://www.mdpi.com/1424-8220/22/12/4570/pdf?version=1655447306)

_settings_

[Order Article Reprints](https://www.mdpi.com/1424-8220/22/12/4570/reprints)

Font Type:


_Arial__Georgia__Verdana_

Font Size:

AaAaAa

Line Spacing:

______

Column Width:

______

Background:

Open AccessReview

# Amniotic Fluid Classification and Artificial Intelligence: Challenges and Opportunities

by


Irfan Ullah Khan

![](https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png)Irfan Ullah Khan

[SciProfiles](https://sciprofiles.com/profile/1261881?utm_source=mdpi.com&utm_medium=website&utm_campaign=avatar_name) [Scilit](https://scilit.com/scholars?q=Irfan%20Ullah%20Khan) [Preprints.org](https://www.preprints.org/search?search1=Irfan%20Ullah%20Khan&field1=authors) [Google Scholar](https://scholar.google.com/scholar?q=Irfan+Ullah+Khan)

[![](https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1750928612)](https://orcid.org/0000-0003-1002-6178),

Nida Aslam

![](https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png)Nida Aslam

[SciProfiles](https://sciprofiles.com/profile/1199402?utm_source=mdpi.com&utm_medium=website&utm_campaign=avatar_name) [Scilit](https://scilit.com/scholars?q=Nida%20Aslam) [Preprints.org](https://www.preprints.org/search?search1=Nida%20Aslam&field1=authors) [Google Scholar](https://scholar.google.com/scholar?q=Nida+Aslam)

\* [![](https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1750928612)](https://orcid.org/0000-0002-1619-5733),

Fatima M. Anis

![](https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png)Fatima M. Anis

[SciProfiles](https://sciprofiles.com/profile/1828970?utm_source=mdpi.com&utm_medium=website&utm_campaign=avatar_name) [Scilit](https://scilit.com/scholars?q=Fatima%20M.%20Anis) [Preprints.org](https://www.preprints.org/search?search1=Fatima%20M.%20Anis&field1=authors) [Google Scholar](https://scholar.google.com/scholar?q=Fatima+M.+Anis)

[![](https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1750928612)](https://orcid.org/0000-0002-4916-8977),

Samiha Mirza

![](https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png)Samiha Mirza

[SciProfiles](https://sciprofiles.com/profile/1875333?utm_source=mdpi.com&utm_medium=website&utm_campaign=avatar_name) [Scilit](https://scilit.com/scholars?q=Samiha%20Mirza) [Preprints.org](https://www.preprints.org/search?search1=Samiha%20Mirza&field1=authors) [Google Scholar](https://scholar.google.com/scholar?q=Samiha+Mirza)

[![](https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1750928612)](https://orcid.org/0000-0003-3754-6894),

Alanoud AlOwayed

![](https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png)Alanoud AlOwayed

[SciProfiles](https://sciprofiles.com/profile/2270038?utm_source=mdpi.com&utm_medium=website&utm_campaign=avatar_name) [Scilit](https://scilit.com/scholars?q=Alanoud%20AlOwayed) [Preprints.org](https://www.preprints.org/search?search1=Alanoud%20AlOwayed&field1=authors) [Google Scholar](https://scholar.google.com/scholar?q=Alanoud+AlOwayed)

[![](https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1750928612)](https://orcid.org/0000-0002-3599-5090),

Reef M. Aljuaid

![](https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png)Reef M. Aljuaid

[SciProfiles](https://sciprofiles.com/profile/2267684?utm_source=mdpi.com&utm_medium=website&utm_campaign=avatar_name) [Scilit](https://scilit.com/scholars?q=Reef%20M.%20Aljuaid) [Preprints.org](https://www.preprints.org/search?search1=Reef%20M.%20Aljuaid&field1=authors) [Google Scholar](https://scholar.google.com/scholar?q=Reef+M.+Aljuaid)

[![](https://pub.mdpi-res.com/img/design/orcid.png?0465bc3812adeb52?1750928612)](https://orcid.org/0000-0001-7221-8998) and

Razan M. Bakr

![](https://www.mdpi.com/bundles/mdpisciprofileslink/img/unknown-user.png)Razan M. Bakr

[SciProfiles](https://sciprofiles.com/profile/2172497?utm_source=mdpi.com&utm_medium=website&utm_campaign=avatar_name) [Scilit](https://scilit.com/scholars?q=Razan%20M.%20Bakr) [Preprints.org](https://www.preprints.org/search?search1=Razan%20M.%20Bakr&field1=authors) [Google Scholar](https://scholar.google.com/scholar?q=Razan+M.+Bakr)

Department of Computer Science, College of Computer Science and Information Technology, Imam Abdulrahman Bin Faisal University, P.O. Box 1982, Dammam 31441, Saudi Arabia

\*

Author to whom correspondence should be addressed.

_Sensors_ **2022**, _22_(12), 4570; [https://doi.org/10.3390/s22124570](https://doi.org/10.3390/s22124570)

Submission received: 5 April 2022
/
Revised: 13 June 2022
/
Accepted: 14 June 2022
/
Published: 17 June 2022



(This article belongs to the Special Issue [Machine Learning in Computer Vision and Image Sensing: Theory and Applications](https://www.mdpi.com/journal/sensors/special_issues/Computer_VisionIS))

Download _keyboard\_arrow\_down_

[Download PDF](https://www.mdpi.com/1424-8220/22/12/4570/pdf?version=1655447306)

[Download PDF with Cover](https://www.mdpi.com/1424-8220/22/12/4570#)

[Download XML](https://www.mdpi.com/1424-8220/22/12/4570#)

[Download Epub](https://www.mdpi.com/1424-8220/22/12/4570/epub)

[Browse Figures](https://www.mdpi.com/1424-8220/22/12/4570#)

[\
                        <strong>Figure 1</strong><br/>\
                                                    <p>Taxonomy of AF detection using AI techniques.</p>\
                                                ](https://pub.mdpi-res.com/sensors/sensors-22-04570/article_deploy/html/images/sensors-22-04570-g001.png?1655447386 "                         <strong>Figure 1</strong><br/>                                                     <p>Taxonomy of AF detection using AI techniques.</p>                                                 ")[\
                        <strong>Figure 2</strong><br/>\
                                                    <p>Methodology adopted for the systematic review.</p>\
                                                ](https://pub.mdpi-res.com/sensors/sensors-22-04570/article_deploy/html/images/sensors-22-04570-g002.png?1655447392 "                         <strong>Figure 2</strong><br/>                                                     <p>Methodology adopted for the systematic review.</p>                                                 ")[\
                        <strong>Figure 3</strong><br/>\
                                                    <p>Distribution of the studies based on the AI method type.</p>\
                                                ](https://pub.mdpi-res.com/sensors/sensors-22-04570/article_deploy/html/images/sensors-22-04570-g003.png?1655447396 "                         <strong>Figure 3</strong><br/>                                                     <p>Distribution of the studies based on the AI method type.</p>                                                 ")[\
                        <strong>Figure 4</strong><br/>\
                                                    <p>AI techniques used.</p>\
                                                ](https://pub.mdpi-res.com/sensors/sensors-22-04570/article_deploy/html/images/sensors-22-04570-g004.png?1655447389 "                         <strong>Figure 4</strong><br/>                                                     <p>AI techniques used.</p>                                                 ")[\
                        <strong>Figure 5</strong><br/>\
                                                    <p>Data types used by various studies.</p>\
                                                ](https://pub.mdpi-res.com/sensors/sensors-22-04570/article_deploy/html/images/sensors-22-04570-g005.png?1655447387 "                         <strong>Figure 5</strong><br/>                                                     <p>Data types used by various studies.</p>                                                 ")[\
                        <strong>Figure 6</strong><br/>\
                                                    <p>Dataset type and size of various studies.</p>\
                                                ](https://pub.mdpi-res.com/sensors/sensors-22-04570/article_deploy/html/images/sensors-22-04570-g006.png?1655447394 "                         <strong>Figure 6</strong><br/>                                                     <p>Dataset type and size of various studies.</p>                                                 ")

[Versions Notes](https://www.mdpi.com/1424-8220/22/12/4570/notes)

## Abstract

**:**

A fetal ultrasound (US) is a technique to examine a baby’s maturity and development. US examinations have varying purposes throughout pregnancy. Consequently, in the second and third trimester, US tests are performed for the assessment of Amniotic Fluid Volume (AFV), a key indicator of fetal health. Disorders resulting from abnormal AFV levels, commonly referred to as oligohydramnios or polyhydramnios, may pose a serious threat to a mother’s or child’s health. This paper attempts to accumulate and compare the most recent advancements in Artificial Intelligence (AI)-based techniques for the diagnosis and classification of AFV levels. Additionally, we provide a thorough and highly inclusive breakdown of other relevant factors that may cause abnormal AFV levels, including, but not limited to, abnormalities in the placenta, kidneys, or central nervous system, as well as other contributors, such as preterm birth or twin-to-twin transfusion syndrome. Furthermore, we bring forth a concise overview of all the Machine Learning (ML) and Deep Learning (DL) techniques, along with the datasets supplied by various researchers. This study also provides a brief rundown of the challenges and opportunities encountered in this field, along with prospective research directions and promising angles to further explore.

Keywords:

[amniotic fluid (AF)](https://www.mdpi.com/search?q=amniotic+fluid+%28AF%29); [artificial intelligence](https://www.mdpi.com/search?q=artificial+intelligence); [deep learning](https://www.mdpi.com/search?q=deep+learning); [machine learning](https://www.mdpi.com/search?q=machine+learning); [oligohydramnios](https://www.mdpi.com/search?q=oligohydramnios); [polyhydramnios](https://www.mdpi.com/search?q=polyhydramnios); [ultrasound](https://www.mdpi.com/search?q=ultrasound)

## 1\. Introduction

Amniotic fluid (AF) refers to a protective liquid surrounding the fetus inside the amniotic sac that plays essential roles in fetal development. Some of these roles entail shielding the baby from external pressure or sudden motion, ensuring optimal temperature, providing antibodies, and allowing the baby to begin exercising the muscles of various organ systems by floating inside the sac and swallowing the AF \[ [1](https://www.mdpi.com/1424-8220/22/12/4570#B1-sensors-22-04570)\]. Normal volumes of AF, which typically lie in the range of 500–2000 mL, can cater to all the aforementioned functions \[ [2](https://www.mdpi.com/1424-8220/22/12/4570#B2-sensors-22-04570)\]. However, abnormal volumes, typically lying outside the range of 500–2000 mL \[ [2](https://www.mdpi.com/1424-8220/22/12/4570#B2-sensors-22-04570)\], can cause serious conditions, such as oligohydramnios, which refers to an insufficient amount of AF, and polyhydramnios, which is characterized by an excessive amount of AF. The occurrence of oligohydramnios leads to an increased risk of stillbirth or miscarriage \[ [3](https://www.mdpi.com/1424-8220/22/12/4570#B3-sensors-22-04570)\]. Furthermore, it can sometimes lead to abnormalities, such as underdeveloped lungs, since the AF plays an essential role in lung development during the middle of the second trimester \[ [3](https://www.mdpi.com/1424-8220/22/12/4570#B3-sensors-22-04570)\]; it can also lead to umbilical cord compression, contractures, etc. Similarly, the occurrence of polyhydramnios can also increase complications during pregnancy and delivery. In this condition, excessive amounts of AF can cause premature contractions, leading to early delivery, difficulty breathing, limited oxygen supply to the fetus due to the umbilical cord becoming trapped beneath the fetus, etc. \[ [3](https://www.mdpi.com/1424-8220/22/12/4570#B3-sensors-22-04570)\]. Therefore, AF volume estimation is a fundamental measurement required to monitor fetal development.

A fetal ultrasound (US), or sonogram, is a technique used to examine the baby’s maturity and development, and is widely used to estimate AF volume by physicians. AF volume is usually measured by evaluating the four-quadrant AF Index (AFI) or the Single Deep Vertical Pocket (SDP) \[ [4](https://www.mdpi.com/1424-8220/22/12/4570#B4-sensors-22-04570)\] technique. In order to determine AF levels, sonographers find a suitable AF pocket, and then trace the depth of the AF by locating an appropriate point. Despite the fact that AFI and SDP are known to be repeatable and semi-quantitative, manual AFI estimation is highly reliant on the sonographer’s skills and expertise \[ [5](https://www.mdpi.com/1424-8220/22/12/4570#B5-sensors-22-04570)\]. Sometimes, despite having years of experience, sonographers find it difficult to accurately determine the AF volume in the fetus. Thus, complete assessment is a lengthy process, sometimes leading to inaccurate results. However, considering how technological advancements in the medical field have made a tremendous impact in treating many disorders that were once considered irreversible, we recognize that introducing a certain degree of automation in AF volume estimation could reduce errors and provide more reliable measurements. The automation process is where Artificial Intelligence (AI) comes into the picture.

AI techniques, namely Machine Learning (ML) and Deep Learning (DL), can be used to efficiently automate the process of AF volume estimation. ML and DL excel in visual pattern identification, making them particularly useful for sonographers \[ [6](https://www.mdpi.com/1424-8220/22/12/4570#B6-sensors-22-04570)\]. Even though obstetric and gynecological ultrasonography are two of the most popular imaging procedures, ML and DL have made a limited impact in this field. However, they have a great deal of potential in aiding repetitive US operations, such as automatically selecting optimum images and providing instantaneous anatomical measurements. One of the most significant advantages to using these methods is that they aid the sonographer in analyzing the US images for AF volume estimation, and standardize the US technique to improve patient safety.

To the best of our knowledge, no paper in the literature so far has conducted a comprehensive review of the existing studies in this area of utilizing AI for AF detection and classification. We noticed that there was a need to conduct a comprehensive review of the existing studies so as to provide a starting point for researchers to identify the findings and gaps in this area and conduct more extensive research. Motivated by this need, in this paper we explore the existing literature to examine what is presently known about the numerous concepts and theories related to utilizing AI for AF identification from US images. This review paper makes the following key contributions:

- Summarizes the use of ML- and DL-based classification and segmentation methods in measuring and classifying AF volume.

- Discusses the factors leading to abnormal AF levels and summarizes the studies focusing on using AI to detect these factors.

- Summarizes the previous studies’ performances in terms of their detection approaches, including their accuracy, dice similarity, etc.

- Presents a comprehensive discussion on the techniques used by the previous studies and the dataset types and sizes.

- Highlights the challenges and future directions in this field of AF detection using AI techniques.


[Figure 1](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-f001) presents the overall structure of the review paper, which includes discussing AF detection using ML and DL techniques, investigating the causes or factors leading to abnormal AF, and the ML and DL techniques adopted to detect these factors.

The paper is structured as follows: [Section 2](https://www.mdpi.com/1424-8220/22/12/4570#sec2-sensors-22-04570) presents the methodology of the paper. [Section 3](https://www.mdpi.com/1424-8220/22/12/4570#sec3-sensors-22-04570) investigates the AI-based techniques for diagnosis and classification of AF. [Section 4](https://www.mdpi.com/1424-8220/22/12/4570#sec4-sensors-22-04570) outlines the factors leading to abnormal AF levels, and reviews the studies conducted to investigate these factors using AI. [Section 5](https://www.mdpi.com/1424-8220/22/12/4570#sec5-sensors-22-04570) provides a discussion on the most widely used AI algorithms in the most-related papers, as well as the type and size of datasets analyzed in the literature. [Section 6](https://www.mdpi.com/1424-8220/22/12/4570#sec6-sensors-22-04570) presents the challenges and opportunities in this field. Finally, [Section 7](https://www.mdpi.com/1424-8220/22/12/4570#sec7-sensors-22-04570) provides a conclusion to summarize the results of our study.

## 2\. Correlation between AF Levels and Gestational Age

During the first half of pregnancy, AF is derived from fetal and maternal compartments. With time, active secretion of fluids from amniotic tissues (epithelium) leads to the early formation of AF. By the second trimester, the fetus contributes to AF volume through urination. However, as the fetus ages, several factors, such as fetal swallowing, rigorous activity in the respiratory tract, continuous fluid exchange by hydrostatic or oncotic forces, etc., may contribute to AF elimination \[ [7](https://www.mdpi.com/1424-8220/22/12/4570#B7-sensors-22-04570)\]. It is often argued that the meaning of the reduced fluid is different depending on gestational age. The amount of AF varies with gestational age, e.g., 50 mL at 12 weeks, 150 mL at 16 weeks, and then increases per week by 50 mL until 34 weeks \[ [8](https://www.mdpi.com/1424-8220/22/12/4570#B8-sensors-22-04570)\]. Low AF levels are most prevalent during the final trimester. Overdue births are at higher risk of reduced AF levels as the AF level drops by 50% after 42 weeks.

A decrease in AF levels is usually observed at around a gestational age of 34 weeks \[ [9](https://www.mdpi.com/1424-8220/22/12/4570#B9-sensors-22-04570)\]. A patient diagnosed with oligohydramnios may be at risk of many disorders and birth defects. In some cases, oligohydramnios could potentially cause child death. Patients showing signs of oligohydramnios in the first trimester are at an increased risk of abortion. In the second trimester, the degree of oligohydramnios is of prime significance during diagnosis; severe oligohydramnios could lead to fetal death, whereas borderline oligohydramnios is of lesser concern. In the third trimester, oligohydramnios is typically known to restrict fetal movement, therefore inducing umbilical cord compression and placing the fetus in a dangerous state.

## 3\. Methodology

The purpose of this review is to study the existing research in the domain of AF detection and classification using AI techniques. In order to formulate this review, the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) method was adopted to search for and include the most-related studies, as illustrated in [Figure 2](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-f002).

As a first step, we searched for AF-related papers on various popular databases, namely Google Scholar, PubMed, and Semantic Scholar. To search for the papers, we used relevant keywords related to our scope, such as AF, twin-to-twin transfusion, fetal kidney/abdomen, placenta, DL, ML, AI, sonography, Image Analysis, etc., to name a few. Based on this step, 61 papers in total were found from the aforementioned databases. As a next step, we screened the collected papers, whereby we removed the duplicates. At the end of this step, we obtained 57 unique papers. Next, we checked the eligibility and the relevance of these papers to the scope of our review, and found that some did not fall within the scope. Finally, the number of most-relevant papers found was 39. All 39 papers were included in the review and discussed. The results and findings of the articles, and the future scope, are discussed in the present paper.

## 4\. Artificial Intelligence-Based Techniques for Diagnosis and Classification of Amniotic Fluid

A number of studies have been published addressing the use of AI techniques in AF detection. This section reviews the existing literature on the topic by discussing various concepts and theories, including previous studies and their findings. The related works are organized based on the most relevant AF assessments with two main approaches: classification and segmentation.

#### 4.1. Classification

Some studies concentrated on classifying AF from the fetal US images or videos for assessing fetal health. Following this ideology, Bahado-Singh et al. \[ [10](https://www.mdpi.com/1424-8220/22/12/4570#B10-sensors-22-04570)\] compared the DL and ML models, namely Random Forest (RF) and the Support Vector Machine (SVM), and neural networks for AF detection by utilizing sonographic, clinical, and demographic factors to predict perinatal outcomes in pregnant women with a short Cervical Length (CL). The researchers used a combination of omics, demographic, and clinical data to study 26 samples. DL yielded a significant performance, with an Area Under the Curve (AUC) (0.85 Curie (CI)) of 0.890 (0.810–0.970) for delivery < 34 weeks of gestation, 0.890 (0.790–0.990) for delivery < 28 days post-amniocentesis, and 0.792 (0.689–0.894) for Neonatal Intensive Care Unit (NICU) admission. Additionally, R. Ramya and K. Srinivasan \[ [11](https://www.mdpi.com/1424-8220/22/12/4570#B11-sensors-22-04570)\] introduced a hybridized strategy to create the Hybrid Bidirectional Unidirectional—Long Short-Term Memory (HBU-LSTM) algorithm by merging the unidirectional and bidirectional models. In US fetal images, different image preprocessing methods were used for distance prediction, i.e., Convolutional Neural Network (CNN) and bidirectional LSTM; the suggested model achieved the best results, with a Mean Squared Error (MSE) of 0.5244 and a Mean Squared Deviation (MSD) of 0.4554.

Following the same principles, Ayu et al. \[ [12](https://www.mdpi.com/1424-8220/22/12/4570#B12-sensors-22-04570)\] used ML algorithms to classify AF into six categories: Oligohydramnion Clear, Oligodramnion Echogenic; Polygohydramnion Clear, Polygohydramnion Echogenic; Normal Clear and Normal Echogenic. The US images dataset was acquired from a local hospital, and it contained 95 US images. During preprocessing, cropping, and conversion of images from RGB to greyscale was applied to facilitate image segmentation. Additionally, the SDP feature was extracted. After the preprocessing steps, the images were classified based on rule-based SDP and the RF algorithm. The results obtained by the model had a good accuracy of 0.9052, outperforming many studies. In another study, Ayu and Hartati \[ [13](https://www.mdpi.com/1424-8220/22/12/4570#B13-sensors-22-04570)\] investigated a pixel classification algorithm to differentiate AF regions on US pictures with noise, hazy edges, distortions, and poor contrast. The method involved local first-order statistical methods and data as gray-level to produce each pixel’s traits. Classification of each pixel was performed using RF and Decision Tree (DT) techniques to create four classes: AF, fetal body, placenta, and uterus. They found 5 × 7 window sizes for the RF method depicted the best performance, with 0.995 accuracy; these were obtained from a mode with 50 US testing images for the AF area’s segmentation.

Additionally, Amuthadevi and Subarnan \[ [14](https://www.mdpi.com/1424-8220/22/12/4570#B14-sensors-22-04570)\] focused on measuring the AFI, as well as the geometry and shadowed properties of AF at various phases of gestation, and developed a fuzzy technique to help with forecasting anomalies in infant weight, head circumference (HC), and the requirement for critical care following delivery. The assessment of these factors would prove useful for delivery decisions, and ultimately aid in avoiding premature birth. US scans were used for this, and the condition of the patient was determined depending on the features obtained. Oligohydramnios, borderline, normal, or polyhydramnios were the classifications in the AFI. This classification helped practitioners gain insight into the pregnancy’s effect on both the child and the mother. The implemented fuzzy logic system was tested by comparing the results obtained algorithmically against a physician’s opinion on the AFI level, which was a 0.94 match, and the geometry of the AF images at various weeks of gestation; classifying them into one of the cases led to an accuracy of 0.925. [Table 1](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-t001) below presents a summary and comparison of the AF classification studies utilizing different AI techniques, which are subdivided into ML and DL.

#### 4.2. Segmentation

Some studies focused on segmenting AF from US images by utilizing DL methods. For example, Cho et al. \[ [5](https://www.mdpi.com/1424-8220/22/12/4570#B5-sensors-22-04570)\] established a DL-based model that detects AF pockets. The segmentation of an AF pocket with their proposed DL model, AF-net, is the most important phase. AF-net can be described as a version of U-net, along with a combination of three concepts: atrous convolution, multi-scale side-input layer, and side-output layer. The dataset used was comprised of 435 US images. Preprocessing methods included cropping, resizing images, and random contrast or brightness settings to lessen the influence of overfitting. To ensure effectiveness, five-fold cross-validation was applied. The proposed model accomplished a Dice Similarity Coefficient (DSC) of 0.877 ± 0.086 for AF segmentation, and a precision value of 0.898 ± 0.111. They found that a stable and consistent method is required to control varying transducer conditions. Moreover, there is a limitation in assessing AFIs in obese women due to the inflammation of adipose tissue.

Similarly, Sun et al. \[ [15](https://www.mdpi.com/1424-8220/22/12/4570#B15-sensors-22-04570)\] aimed at estimating AF volume from US images. In order to segment the AF, they used DL models using a dual-path network. The dual net included the primary path that comprised of AF-net (similar to the previous study), and the secondary path that entailed an auxiliary network. The dataset includes 2380 US images acquired manually from a medical center. The dataset underwent preprocessing techniques, mainly cropping, resizing, normalization, and augmentation, as well as five-fold cross validation. The proposed network successfully achieved a DSC of 0.8599 ± 0.1074. Similarly, Li et al. \[ [16](https://www.mdpi.com/1424-8220/22/12/4570#B16-sensors-22-04570)\] applied DL for the segmentation of the AF and tissue sections of fetal US images obtained from clinical examinations. The DL model was initiated by encoding the input image into down-scaled feature maps utilizing convolution and pooling stages. This was followed by decoding, achieved via the un-pooling layers in accordance with the 1 × 1 convolution kernels for acquiring the image of the input size. The dataset consisted of videos, 20 s in length, of four patients, from which the still images were sampled every two frames. By random separation, 900 training images and 400 testing images were attained. Different network settings were tested, confirming the three inner layers of the kernel achieved the best performance, with an accuracy of 0.93. However, more data and segmentation at the object border is required for the enhancement of the technique.

Additionally, Ayu et al. \[ [17](https://www.mdpi.com/1424-8220/22/12/4570#B17-sensors-22-04570)\] proposed an AF segmentation model with 50 fetal B-Mode US images. The segmentation model applied pixel classification based on the RF method. For comparison, the images were taken at two window sizes (3 × 3 and 5 × 5), then a Radiologist Expert labeled multiple points according to 3 classes (AF, fetal body, uterus). As a result, images with a window size of 5 × 5 had an accuracy of 0.8586 and 0.8145 for images with window size 3 × 3 In another study, Ayu et al. \[ [18](https://www.mdpi.com/1424-8220/22/12/4570#B18-sensors-22-04570)\] focused on AF segmentation using a pixel classification model which applied various classifiers namely RF, DT, Naive Bayes (NB), SVM, and K-Nearest Neighbor (KNN) to classify the AF from other objects in the images. The dataset was acquired from a local hospital and consisted of 55 US images. The sampling window technique was used to construct training sets, producing pixel information specific to certain regions. The results of the proposed model were best achieved using the RF classifier, which obtained a DSC of 0.876 and pixel accuracy of 0.857.

Furthermore, Looney et al. \[ [19](https://www.mdpi.com/1424-8220/22/12/4570#B19-sensors-22-04570)\] proposed a multiclass CNN model to segment the placenta, AF, and fetus. The dataset consisted of 2093 labeled placental volumes augmented by 300 volumes with placenta, AF, and fetus annotated for multi-class segmentation. For the Placenta Segmentation (PS) model, out of 2093 images were used and the model used was Fully CNN (FCNN). For multiclass segmentation, a two-pathway Hybrid Model (HB) was built using the remaining 300 cases from the original dataset. For the PS model, the highest obtained results were obtained with a DSC of 0.85 after 17,000 training steps. In the case of the HB model, it improved the placental segmentation due to the dual pathway and exhibited a DSC of 0.84. Correspondingly, Anquez et al. \[ [20](https://www.mdpi.com/1424-8220/22/12/4570#B20-sensors-22-04570)\] studied the Utero-Fetal Unit (UFU) segmentation of 19 3D US images in the first trimester of the fetal. The main goal was to extract fetal tissues and AF automatically. The study used exponential and normal distributions for saturated images, whereas Rayleigh and normal distributions were used for non-saturated images. In addition, the Gamma distribution was used as a generic formulation. The study has achieved an accuracy average of 0.89. [Table 2](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-t002) below presents summary and comparisons of the AF segmentation studies utilizing different AI techniques subdivided into ML and DL.

## 5\. Factors/Causes of Abnormal Amniotic Fluid Levels

Oligohydramnios is an AF abnormality that causes a reduction in AF volume for the early stage of pregnancy. Inadequate AF levels can be caused by a variety of obstetric, fetal, or placental problems, all of which result in negative fetal consequences \[ [21](https://www.mdpi.com/1424-8220/22/12/4570#B21-sensors-22-04570)\]. Polyhydramnios is a condition in which the AF level rises during gestation, a condition that is linked to higher maternal and neonatal mortality rates \[ [21](https://www.mdpi.com/1424-8220/22/12/4570#B21-sensors-22-04570)\]. In this section, we review the studies that focus on using ML/DL to detect the factors or elements in the fetus that possibly contribute to causing abnormal AF levels. The breakdown of this section is already presented in [Figure 1](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-f001).

#### 5.1. Oligohydramnios

Through extensive research, it appears that oligohydramnios is mostly caused by placental abnormalities, followed by congenital anomalies. The following section summarizes the most prevalent studies regarding the factors affecting oligohydramnios.

#### 5.1.1. Placenta

Considering the idea that the placenta is essential in determining the fetal heath, as well as useful in determining its contribution to high AF levels, some studies focused on segmenting or detecting placenta in fetal images. Following this idea, Han et al. \[ [22](https://www.mdpi.com/1424-8220/22/12/4570#B22-sensors-22-04570)\] proposed an automatic segmentation method using U-net, a CNN for biomedical image data. The dataset, acquired from a local hospital, contained 1110 Magnetic Resonance Imaging (MRI) images, which underwent a preprocessing technique mainly featuring normalization. The overall accuracy achieved by the model was 0.98. In another study, Yang et al. \[ [23](https://www.mdpi.com/1424-8220/22/12/4570#B23-sensors-22-04570)\] utilized 3D US images for automatic semantic segmentation of the placenta, as well as gestational sac and fetus. Based on 3D FCNN, they proposed a Recurrent Neural Network (RNN) to flexibly explore 3D semantic knowledge from a sequential perspective. The dataset used contained volumetric US images from 104 pregnant women, and it underwent augmentation. The FCNN achieved a good DSC of 0.882. Furthermore, Hu et al. \[ [24](https://www.mdpi.com/1424-8220/22/12/4570#B24-sensors-22-04570)\] utilized a CNN to segment placenta from US images using a dataset that contained 1364 fetal images. In order to identify artifacts specific to US, the CNN contained a novel layer weighted by automated acoustic shadow detection. The CNN built with the additional layer achieved a DSC of 0.92. Similarly, Zimmer et al. \[ [25](https://www.mdpi.com/1424-8220/22/12/4570#B25-sensors-22-04570)\] followed a multi-task approach, and used transfer learning to identify placenta position in U-net architecture. The dataset used contained real-time 1054 3D US images, and it underwent augmentation. The achieved segmentation accuracy was improved, with the highest DSC of the anterior and posterior being 0.87 and 0.81, respectively.

However, sometimes placental-mediated diseases are not recognized until later stages. Hence, Hu et al. \[ [26](https://www.mdpi.com/1424-8220/22/12/4570#B26-sensors-22-04570)\] proposed a CNN pipeline to detect the presence of placental diseases. The model consists of segmentation of the placenta followed by classification utilizing a dataset containing US images of 321 patients (13,384 frames). The model successfully achieved a high classification accuracy of 0.81. In another study, Schilpzand et al. \[ [27](https://www.mdpi.com/1424-8220/22/12/4570#B27-sensors-22-04570)\] focused on detecting low-lying placenta or placenta previa in resource-limited settings using US images. The authors segmented the placenta using U-net, achieving a DSC of 0.84, utilizing 6576 US images. Then, classification was applied to differentiate it as normal or placenta previa, which achieved a specificity of 0.82 in 148 cases. Additionally, Zimmer et al. \[ [28](https://www.mdpi.com/1424-8220/22/12/4570#B28-sensors-22-04570)\] proposed a method using 3D US images to segment the placenta at late gestation using 3D CNN. The dataset contained about 127 3D US images, and the model successfully performed multi-view PS, achieving a DSC of 0.8. Additionally, Looney et al. \[ [29](https://www.mdpi.com/1424-8220/22/12/4570#B29-sensors-22-04570)\] examined a Deep CNN (DCNN), known as DeepMdic, constituting of a ground truth based on a semi-automated random walker method output. For segmentation of the 3D US data, the input volume was converted into a subjective, undirected graph, and a segmentation protocol was then applied. The dataset consisted of placenta from 3064 cases during the first trimester. The 300 test cases produced a DSC of 0.73. In another study, Looney et al. \[ [30](https://www.mdpi.com/1424-8220/22/12/4570#B30-sensors-22-04570)\] proposed a unique technique to atomize placental segmentation from 3D US volumes controlled by a complete CNN, OxNNet, for ground truth. Adverse pregnancy outcome, namely Small for Gestational Age (SGA) prediction was evaluated using a CNN containing data for 3104 cases. The results obtained showed the DSC to vary from 0.73 to 0.81.

Furthermore, Saavedra et al. \[ [31](https://www.mdpi.com/1424-8220/22/12/4570#B31-sensors-22-04570)\] utilized portable technology to propose a model for the automated evaluation of placenta previa throughout the last trimester in remote regions. The method includes PS by U-net DL algorithm applied to 11,014 US images from 10 patients, and identifies the placenta position. The approach was found to have a sensitivity of 0.75 and a specificity of 0.92. Similarly, Oguz et al. \[ [32](https://www.mdpi.com/1424-8220/22/12/4570#B32-sensors-22-04570)\] presented a new technique for automatic PS in 3D US images that combines Joint Label Fusion (JLF)-based multi-atlas segmentation and DL approaches. The procedure was tested on a sample of 47 patients during the first trimester by merging the JLF and CNN models. With 86.3 ± 5.3 as the mean dice coefficient, the model indicates a significant improvement. Moreover, for recognizing uteroplacental interface in US images, Qi et al. \[ [33](https://www.mdpi.com/1424-8220/22/12/4570#B33-sensors-22-04570)\] introduced Knowledge-guided Pretext Learning (KPL), which trains anatomical structures without employing external data, much like ImageNet. The dataset consisted of 101 placental 3D US volumes. KPL had the greatest performance of Optimal Dataset Scale (ODS), achieving 0.605 with VGG-19, while ImageNet had good results as well. Correspondingly, Romeo et al. \[ [34](https://www.mdpi.com/1424-8220/22/12/4570#B34-sensors-22-04570)\] suggested that ML assessment utilizing MRI-based texture features would be a useful method for detecting placental tissue anomalies that underpin the placenta accreta spectrum in women with placenta previa. MRI tests of 64 individuals were used to test the various algorithms, with KNN achieving the greatest accuracy of 0.981. Likewise, to address the challenges of automated placental structural classification, Chen et al. \[ [35](https://www.mdpi.com/1424-8220/22/12/4570#B35-sensors-22-04570)\] introduced a new transfer learning model, PlacentaNet, comprised of multiple encoder–decoder CNNs. With a dataset covering photographic images of 1003 placentas, the proposed model achieved a total classification accuracy of 0.9751.

#### 5.1.2. Kidneys

The occurrence of oligohydramnios during pregnancy has been identified as a significant risk factor for renal damage. Thus, Sridar et al. \[ [36](https://www.mdpi.com/1424-8220/22/12/4570#B36-sensors-22-04570)\] began with prenatal US images and identified 14 angles using the AlexNet neural network, which had been trained with a genuine visual dataset. They devised a method for training two adjacent networks at the same time. One network’s feed was the full US image, which was utilized to understand the image’s content overall. The second network’s feed consisted of random confined segments of US images, which was necessary to identify the image’s specific and distinct characteristics. They had a 0.97 mean accuracy, 0.7647 precision, and 0.7541 mean recall rate.

#### 5.2. Polyhydramnios

Although polyhydramnios may be classified as a rare disorder \[ [21](https://www.mdpi.com/1424-8220/22/12/4570#B21-sensors-22-04570)\], it most definitely can lead to dire consequences, such as child mortality. This section summarizes the literature on some of the factors resulting from this disorder.

#### Central Nervous System

The most prevalent anomalies linked to polyhydramnios are those of the central nervous system. Therefore, Zhou et al. \[ [37](https://www.mdpi.com/1424-8220/22/12/4570#B37-sensors-22-04570)\] applied DL neural network algorithm to diagnose fetal central nervous system malformation. The proposed algorithm aims to optimize analysis and identify malformation from a set of 63 US images from pregnant women. The proposed model utilizes the CNN method and was able to improve the accuracy of the results; nevertheless, due to the small size of the dataset, the results could still be improved.

Similarly, Attallah et al. \[ [38](https://www.mdpi.com/1424-8220/22/12/4570#B38-sensors-22-04570)\] developed a new approach for detecting fetal neurological abnormalities using DL methods. Transfer learning, deep feature extraction, feature reduction, and classification are the phases of the methodology. There are 227 embryonic MRI scans in the collection (113 are normal and 114 have neurological abnormalities), with gestational age spanning from 16 to 39 weeks. Using quadratic SVM classifiers trained with deep features taken from AlexNet and ResNet50 combined, the accuracy was 0.886. The findings demonstrate that the presented approach may successfully detect fetal neurological abnormalities from prenatal MRI data at diverse stages of pregnancy.

#### 5.3. Common Factors of Oligohydramnios and Polyhydramnios

The following subsections demonstrate common factors that may contribute to both oligohydramnios and polyhydramnios.

#### 5.3.1. TTTS (Twin-to-Twin Transfusion Syndrome)

TTTS occurs when one of a set of monochorionic diamniotic twins suffers severe polyhydramnios during the middle of gestation, which results in the co-twin developing oligohydramnios. For this reason, Bano et al. \[ [39](https://www.mdpi.com/1424-8220/22/12/4570#B39-sensors-22-04570)\] proposed a combined CNN and LSTM model to study fetoscopic videos captured from different human TTTS cases; the dataset consists of 138,780 frames. The proposed model achieved a precision value of 0.96, and the results show that the proposed model handled the challenges in the fetoscopic environment better than other methods and resulted in improved prediction for multi-label frames. Moreover, Bano et al. \[ [40](https://www.mdpi.com/1424-8220/22/12/4570#B40-sensors-22-04570)\] also presented a DL-based mosaicking framework for fetoscopic videos captured from different environments. In total, 2400 frames were extracted to capture different environments, including simulation, phantom, ex vivo, and in vivo environments. A comparison was performed with existing feature-based and deep image homography methods, and the proposed model demonstrated its robustness and outperformed the existing methods.

Correspondingly, Ahmad et al. \[ [41](https://www.mdpi.com/1424-8220/22/12/4570#B41-sensors-22-04570)\] introduced a new shared control approach for fetoscopic applications. The model trained 30,000 images using CNN to predict the relative orientation of the placental surface made by a single monocular fetoscope camera photo, and achieved an accuracy of 0.87 for the simulated dataset. Finally, Casella et al. \[ [42](https://www.mdpi.com/1424-8220/22/12/4570#B42-sensors-22-04570)\] aimed to use DL in providing automatic and fast membrane segmentation in fetal images. They used an adversarial network consisting of two CNNs. The dataset included 900 images acquired and labeled from six surgical videos (150 frames per video). After training and validating, the adversarial network obtained a DSC of 0.9191.

#### 5.3.2. Preterm

One of the pregnancy complications that motivates researchers to explore ML solutions is Prelabor Rupture of Membranes (PROM). Sufriyana et al. \[ [43](https://www.mdpi.com/1424-8220/22/12/4570#B43-sensors-22-04570)\] aimed to predict the likelihood of PROM and delivery time. There were five ML and statistical techniques compared: Ridge Regression (RR), Elastic Net Regression (ENR), RF, Gradient Boosting (GB) models, and the Deep-Insight Visible Neural Network (DI-VNN). The study showed that RF has the capability to estimate delivery time, unlike the other models. However, the DI-VNN classifier showed outstanding performance, with a sensitivity of 0.494 and specificity of 0.816. Hence, it was chosen to be integrated as a web application. Extreme Preterm Birth (EPB) is another condition that causes early delivery before the 28th week. Gao et al. \[ [44](https://www.mdpi.com/1424-8220/22/12/4570#B44-sensors-22-04570)\] focused on developing a DL model for EPB using RNN, comparing the performance with Linear Regression (LR), SVM, and GB models. The number of patients who participated was 25,689, containing approximately 0.0 EPB cases. The model resulted in an AUC of 0.827 and a sensitivity of 0.965.

#### 5.3.3. Fetal Health

Along with gestational age, fetal biometry and weight estimation are indicators of babies’ and their mothers’ short- and long-term health. Several studies have been published to automate the identification of any potential risks. Lee et al. \[ [45](https://www.mdpi.com/1424-8220/22/12/4570#B45-sensors-22-04570)\] have experimented with multiple ML approaches to predict a newborn’s Body Mass Index (BMI) using US images. The study contained 3159 patients across several countries, with a range of gestational age from week 21–36 and later. The dataset has been tested using LR, RF, and an Artificial Neural Network (ANN) with one, two, and three hidden layers, resulting in RF having the highest average of MSE of 2.1610. In addition, they found that Abdominal Circumference (AC) and Estimated Fetal Weight (EFW) in week 36 or later are primary predictors of the newborn’s BMI. Similarly, Feng et al. \[ [46](https://www.mdpi.com/1424-8220/22/12/4570#B46-sensors-22-04570)\] presented a model for EFW based on SVM and Deep Belief Network (DBN) models. The number of pregnant women who have participated in the study is 7875, including High Birth Weight (HBW) and Low Birth Weight (LBW) fetuses. The results show Mean Absolute Percent Error (MAPE) ranges of 0.0609 ± 0.0506 and a Mean Absolute Error (MAE) of 98.55 ± 158.63 g. Correspondingly, Oghli et al. \[ [47](https://www.mdpi.com/1424-8220/22/12/4570#B47-sensors-22-04570)\] present CNN architecture based on Multi-Feature Pyramid U-net (MFP-U-net) to measure fetal biometry, including Biparietal Diameter (BPD), HC, AC, and Femur Length (FL) using 1334 US images. The model achieved 0.98 on DSC, 1.14 mm on Hausdorff Distance (HD), 0.95 on conformity, and 0.2 mm on Average Perpendicular Distance (APD). [Table 3](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-t003) summarizes AI studies focusing on investigating the causes of factors of abnormal AF Levels.

## 6\. Discussion

A number of studies have been published addressing the use of DL techniques for fetal health assessment that utilized segmentation and classification. Almost all the researchers assessed utilizing US images as inputs for their models. Since some studies suffered from small dataset sizes, they used the augmentation technique. [Figure 3](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-f003) shows the type of method used for Amniotic Fluid. While [Figure 4](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-f004) illustrates the type of techniques used like list of ML, DL techniques used by the previous studies, and [Figure 5](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-f005) illustrates the datatype used for diagnosis adopted by the studies. As shown in [Figure 3](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-f003), the most widely used method among the various studies was segmentation, and the least was regression Furthermore, as seen in [Figure 5](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-f005), RF and CNN were widely used methods by a plethora of authors and they tend to exhibit a good performance among the literature investigated in this report. U-net is also a form of CNN architecture for biomedical imaging that provides fast and accurate segmentation of images.

Most of the reviewed papers have used fetal 2D and 3D US images and videos, MRI images, fetoscopic images and videos, and clinical data as their datasets. The primary focus was AF detection; nevertheless, fetal health factors were considered to understand the relation in-depth, including placenta, kidneys, abdomen, central nervous system, TTTS, preterm. Additionally, the datasets varied from 19 to 219,272 instances, with an average of approximately 12,392. Some datasets have used 3 × 3 to 5 × 5 pixels with 1 × 1 convolution in terms of the image window size. [Figure 4](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-f004) and [Figure 6](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-f006) summarize the reviewed dataset sizes and the types.

## 7\. Challenges and Opportunities

Implementing AI techniques in fetal health has been proven to exhibit significant results for diagnosis. However, some aspects of this implementation are quite complex, and require further intervention to be applied safely and effectively in clinical applications. In this section, we highlight the general challenges and opportunities associated with the current research, and [Table 4](https://www.mdpi.com/1424-8220/22/12/4570#sensors-22-04570-t004) provides a summarized view of the limitations and solutions in the reviewed literature.

#### 7.1. Limited Dataset Size

Open-source datasets in the field of fetal medical imaging are scarce and, therefore, in most cases, researchers must obtain their own datasets through the assistance of a cooperating hospital or medical facility. The privately acquired dataset is often relatively small and, therefore, may contribute to lower accuracy in detecting fetal structures or characteristics. Consequently, datasets may be imbalanced, resulting in great differences between the distribution of classes. Training an algorithm on an unbalanced dataset often leads to a biased result.

Transfer learning is one of the most often-employed strategies used by researchers nowadays to overcome the issue of limited-sample datasets \[ [48](https://www.mdpi.com/1424-8220/22/12/4570#B48-sensors-22-04570)\]. In addition, the availability of an open-source US image dataset would allow researchers to compare the performance of their proposed classification algorithms in a more efficient manner.

#### 7.2. Sonographer Dependency

A sonographer’s subjectivity contributes to inconsistency in the collection of US images. This may worsen the restricted generalization ability of present DL-based algorithms. The practitioner’s method of obtaining US images affects the actual results \[ [49](https://www.mdpi.com/1424-8220/22/12/4570#B49-sensors-22-04570)\]. As a result, AI algorithmic outcomes are determined by how the practitioner identifies the target object in the image, as well as whether the target object is successfully characterized and recorded. Hence, even for highly intelligent AI systems to perform effectively, the medical practitioner must have some level of expertise, at the very least sufficient to examine the patient appropriately.

To reduce the impact an individual sonographer has, sonographers may be further categorized according to their expertise and skill level. This ensures that novice sonographers may not capture an US image without the guidance of an expert sonographer to correctly identify target fetal planes.

#### 7.3. Overfitting

The low universal applicability of AI algorithms for medical diagnosis and prediction (i.e., large variations in AI accuracy between patients) is a notorious problem, which is sometimes referred to as “overfitting” \[ [49](https://www.mdpi.com/1424-8220/22/12/4570#B49-sensors-22-04570)\]. As US examinations are frequently performed in a variety of medical settings and on a wide range of patients, and are conducted by a broad set of clinical personnel with varying skill levels, overfitting may pose a severe danger to the accuracy of AI algorithms. In addition, ultrasonography equipment is highly varied compared to Computerized Tomography (CT) scans or MRI systems, with more suppliers and versions.

Solving the problem of overfitting emphasizes the significance of a thorough external validation of an AI system in the many clinical situations where it is expected to be applied \[ [49](https://www.mdpi.com/1424-8220/22/12/4570#B49-sensors-22-04570)\]. Sonographers or medical professionals are encouraged to compare AI system findings with their own findings to ensure the accuracy of the AI algorithm, and thus to guarantee that it can be applied safely and in an effective manner.

#### 7.4. Black Box Nature

Obstetrics and gynecology is a field that highly depends on the data generated from radiology, ultrasound, and CTG scans. The radiologically generated data is image-based and usually requires a highly sophisticated algorithm for automated diagnosis. In ML, there is usually a tradeoff among the predictive performance and the interpretability of the algorithm. Highly interpretable models, such as DT, LR, and NB, do not have the capability to understand the complex problems. On the other hand, the ensemble and DL models produce significant results in terms of prediction, but have a black box nature.

Due to the black box nature, clinicians are usually reluctant to adopt AI-based solutions in real life \[ [50](https://www.mdpi.com/1424-8220/22/12/4570#B50-sensors-22-04570)\]. Therefore, clinicians tend to trust their perception more than outcomes generated by black box algorithms. Explainable AI has introduced transparency into the decision-making process and incorporates trust; clinicians can determine how the decision has been made.

#### 7.5. Bias

AI-based models highly rely on the dataset that was used to train the model. This leads to the risk of bias. For example, if the model was trained using the dataset from one health center, then it will incorporate the bias from the data generated in that center. Thus, the model will not be generalized. Most of the previously defined studies used datasets from a single center. For the AI-based prediction model to be more generalized and robust, the model must be trained using multi-center and heterogenous data.

#### 7.6. Distributed Data

One of the challenges AI systems have faced is decentralized data. Sometimes the diagnosis has been made to consider the data from different sources, such as radiology, pathology, and through physical examinations. Furthermore, the patients generally visit more than one hospital or health center, which leads to the division of data among multiple health centers. Similarly different health centers save the data in different formats. The decentralization of data raises the chance of errors, and data inconsistency and incompleteness.

#### 7.7. Privacy and Cyber Security Concerns

AI-based diagnosis and prognosis systems require large amounts of data to better train the models. One of the major concerns is the patient’s privacy. Some patients refuse to provide data due to fear of privacy. Furthermore, the rise in automated diagnosis and health monitoring using the internet of things (IOT) increases the risk of cyber security threats.

## 8\. Future Research

With respect to all the reviewed literature in this broad field, we propose that further research should bridge many of the gaps that are currently encountered:

#### 8.1. Image Quality

One of the weakest links in the deployment of AI in fetal health assessment is the poor image quality resulting from either inexperienced medical practitioners or an unsuitable fetal position within the placenta. There are areas of great potential improvement when enhancing the quality of captured US images.

#### 8.2. Imaging Techniques

AI can be utilized to aid various advanced US methods, such as color Doppler imaging \[ [7](https://www.mdpi.com/1424-8220/22/12/4570#B7-sensors-22-04570)\]. Gaining more views or angles to analyze an image would be promising in terms of reaching an accurate interpretation of the image.

#### 8.3. Awareness and Training

Acquainting and educating sonographers with the AI tools and/or methods used to automatically estimate fetal health indicators, such as AFV, ultimately escalates the performance of these AI-based solutions because sonographers will gain a better understanding of the consequences that a poorly captured US image can cause, especially in terms of patient misdiagnosis. In turn, sonographers will properly consider the aspects of each image taken, and whether the image meets the criteria of the algorithm for accurate assessment.

## 9\. Conclusions

This paper attempted to provide a comprehensive review of the existing studies in the area of utilizing AI for AF detection and classification to provide a starting point for researchers to identify the knowledge gaps in this area and conduct more extensive research. Furthermore, it summarizes the use of DL- and ML-based classification and segmentation methods in measuring AF volume and highlights the challenges and opportunities in this field. Additionally, it discusses the various factors and causes leading to abnormal AF levels and reviews the studies focusing on using AI techniques to investigate these factors. Several ML and DL methods were analyzed for AF detection, including CNN, AF-net, RF, DT, NB, SVM, KNN, LSTM, etc. We created visual aids to analyze the reviewed papers based on the nature of their datasets as well as the performance of applied algorithms. From the analysis, we discovered that the most frequently used techniques in AF detection are the RF and CNN, which exhibited the highest performance among the literature investigated in this article. Furthermore, we discussed and listed some of the challenges, as well as recommended solutions to be utilized by interested parties for developing and funding the medical technology sector. Finally, we also discussed the future directions to undertake in order to advance this field of using AI techniques in the medical analysis of fetal health.

## Author Contributions

Conceptualization, I.U.K., N.A., F.M.A., S.M., A.A., R.M.A. and R.M.B.; methodology, I.U.K., N.A., F.M.A., S.M., A.A., R.M.A. and R.M.B.; formal analysis, F.M.A., S.M., A.A., R.M.A. and R.M.B.; investigation, F.M.A., S.M., A.A., R.M.A. and R.M.B.; resources, I.U.K., N.A., F.M.A., S.M., A.A., R.M.A. and R.M.B.; data curation, I.U.K., N.A., F.M.A., S.M., A.A., R.M.A. and R.M.B.; writing—original draft preparation, F.M.A., S.M., A.A., R.M.A. and R.M.B.; writing—review and editing, I.U.K. and N.A.; visualization, F.M.A., S.M., A.A., R.M.A. and R.M.B.; supervision, I.U.K. and N.A.; project administration, I.U.K. and N.A.; funding acquisition, I.U.K., N.A., F.M.A., S.M., A.A., R.M.A. and R.M.B. All authors have read and agreed to the published version of the manuscript.

## Funding

This research received no external funding.

## Informed Consent Statement

Not applicable.

## Data Availability Statement

Not applicable.

## Conflicts of Interest

The authors declare no conflict of interest.

## References

01. Beall, M.H.; van den Wijngaard, J.P.H.M.; van Gemert, M.J.C.; Ross, M.G. Amniotic Fluid Water Dynamics. Placenta **2007**, 28, 816–823. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Amniotic+Fluid+Water+Dynamics&author=Beall,+M.H.&author=van+den+Wijngaard,+J.P.H.M.&author=van+Gemert,+M.J.C.&author=Ross,+M.G.&publication_year=2007&journal=Placenta&volume=28&pages=816%E2%80%93823&doi=10.1016/j.placenta.2006.11.009&pmid=17254633)\] \[ [CrossRef](http://doi.org/10.1016/j.placenta.2006.11.009)\] \[ [PubMed](http://www.ncbi.nlm.nih.gov/pubmed/17254633)\]
02. Phelan, J.P.; Ahn, M.O.; Smith, C.V.; Rutherford, S.E.; Anderson, E. Amniotic fluid index measurements during pregnancy. J. Reprod. Med. Obstet. Gynecol. **1987**, 32, 601–604. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Amniotic+fluid+index+measurements+during+pregnancy&author=Phelan,+J.P.&author=Ahn,+M.O.&author=Smith,+C.V.&author=Rutherford,+S.E.&author=Anderson,+E.&publication_year=1987&journal=J.+Reprod.+Med.+Obstet.+Gynecol.&volume=32&pages=601%E2%80%93604)\]
03. Magann, E.F.; Chauhan, S.P.; Doherty, D.A.; Lutgendorf, M.A.; Magann, M.I.; Morrison, J.C. A review of idiopathic hydramnios and pregnancy outcomes. Obstet. Gynecol. Surv. **2007**, 62, 795–802. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=A+review+of+idiopathic+hydramnios+and+pregnancy+outcomes&author=Magann,+E.F.&author=Chauhan,+S.P.&author=Doherty,+D.A.&author=Lutgendorf,+M.A.&author=Magann,+M.I.&author=Morrison,+J.C.&publication_year=2007&journal=Obstet.+Gynecol.+Surv.&volume=62&pages=795%E2%80%93802&doi=10.1097/01.ogx.0000290349.58707.e0&pmid=18005456)\] \[ [CrossRef](http://doi.org/10.1097/01.ogx.0000290349.58707.e0)\] \[ [PubMed](http://www.ncbi.nlm.nih.gov/pubmed/18005456)\]
04. Kehl, S.; Schelkle, A.; Thomas, A.; Puhl, A.; Meqdad, K.; Tuschy, B.; Berlit, S.; Weiss, C.; Bayer, C.; Heimrich, J.; et al. Single deepest vertical pocket or amniotic fluid index as evaluation test for predicting adverse pregnancy outcome (SAFE trial): A multicenter, open-label, randomized controlled trial. Ultrasound Obstet. Gynecol. **2016**, 47, 674–679. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Single+deepest+vertical+pocket+or+amniotic+fluid+index+as+evaluation+test+for+predicting+adverse+pregnancy+outcome+(SAFE+trial):+A+multicenter,+open-label,+randomized+controlled+trial&author=Kehl,+S.&author=Schelkle,+A.&author=Thomas,+A.&author=Puhl,+A.&author=Meqdad,+K.&author=Tuschy,+B.&author=Berlit,+S.&author=Weiss,+C.&author=Bayer,+C.&author=Heimrich,+J.&publication_year=2016&journal=Ultrasound+Obstet.+Gynecol.&volume=47&pages=674%E2%80%93679&doi=10.1002/uog.14924)\] \[ [CrossRef](http://doi.org/10.1002/uog.14924)\]
05. Cho, H.C.; Sun, S.; Hyun, C.M.; Kwon, J.Y.; Kim, B.; Park, Y.; Seo, J.K. Automated ultrasound assessment of amniotic fluid index using deep learning. Med. Image Anal. **2021**, 69, 101951\. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Automated+ultrasound+assessment+of+amniotic+fluid+index+using+deep+learning&author=Cho,+H.C.&author=Sun,+S.&author=Hyun,+C.M.&author=Kwon,+J.Y.&author=Kim,+B.&author=Park,+Y.&author=Seo,+J.K.&publication_year=2021&journal=Med.+Image+Anal.&volume=69&pages=101951&doi=10.1016/j.media.2020.101951)\] \[ [CrossRef](http://doi.org/10.1016/j.media.2020.101951)\]
06. Drukker, L.; Noble, J.A.; Papageorghiou, A.T.P. Introduction to artificial intelligence in ultrasound imaging in obstetrics and gynecology. Ultrasound Obstet. Gynecol. **2020**, 56, 498–505. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Introduction+to+artificial+intelligence+in+ultrasound+imaging+in+obstetrics+and+gynecology&author=Drukker,+L.&author=Noble,+J.A.&author=Papageorghiou,+A.T.P.&publication_year=2020&journal=Ultrasound+Obstet.+Gynecol.&volume=56&pages=498%E2%80%93505&doi=10.1002/uog.22122)\] \[ [CrossRef](http://doi.org/10.1002/uog.22122)\]
07. Fischer, R.L. Amniotic fluid: Physiology and assessment. Gynecol. Obstet. **1995**, 8, 1–9. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Amniotic+fluid:+Physiology+and+assessment&author=Fischer,+R.L.&publication_year=1995&journal=Gynecol.+Obstet.&volume=8&pages=1%E2%80%939&doi=10.3843/GLOWM.10208)\] \[ [CrossRef](http://doi.org/10.3843/GLOWM.10208)\]
08. Papageorghiou, A. Fetal physiology. In MRCOG Part One: Your Essential Revision Guide; Fiander, A., Thilaganathan, B., Eds.; Cambridge University Press: Cambridge, UK, 2016. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Fetal+physiology&author=Papageorghiou,+A.&publication_year=2016)\]
09. Bakhsh, H.; Alenizy, H.; Alenazi, S.; Alnasser, S.; Alanazi, N.; Alsowinea, M.; Alharbi, L.; Alfaifi, B. Amniotic fluid disorders and the effects on prenatal outcome: A retrospective cohort study. BMC Pregnancy Childbirth **2021**, 21, 75\. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Amniotic+fluid+disorders+and+the+effects+on+prenatal+outcome:+A+retrospective+cohort+study&author=Bakhsh,+H.&author=Alenizy,+H.&author=Alenazi,+S.&author=Alnasser,+S.&author=Alanazi,+N.&author=Alsowinea,+M.&author=Alharbi,+L.&author=Alfaifi,+B.&publication_year=2021&journal=BMC+Pregnancy+Childbirth&volume=21&pages=75&doi=10.1186/s12884-021-03549-3)\] \[ [CrossRef](http://doi.org/10.1186/s12884-021-03549-3)\]
10. Bahado-Singh, R.O.; Sonek, J.; McKenna, D.; Cool, D.; Aydas, B.; Turkoglu, O.; Bjorndahl, T.; Mandal, R.; Wishart, D.; Friedman, P.; et al. Artificial intelligence and amniotic fluid multiomics: Prediction of perinatal outcome in asymptomatic women with short cervix. Ultrasound Obstet. Gynecol. **2019**, 54, 110–118. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Artificial+intelligence+and+amniotic+fluid+multiomics:+Prediction+of+perinatal+outcome+in+asymptomatic+women+with+short+cervix&author=Bahado-Singh,+R.O.&author=Sonek,+J.&author=McKenna,+D.&author=Cool,+D.&author=Aydas,+B.&author=Turkoglu,+O.&author=Bjorndahl,+T.&author=Mandal,+R.&author=Wishart,+D.&author=Friedman,+P.&publication_year=2019&journal=Ultrasound+Obstet.+Gynecol.&volume=54&pages=110%E2%80%93118&doi=10.1002/uog.20168)\] \[ [CrossRef](http://doi.org/10.1002/uog.20168)\]
11. Ramya, R.; Srinivasan, K. Classification of Amniotic Fluid Level Using Bi-LSTM with Homomorphic filter and Contrast Enhancement Techniques. Wirel. Pers. Commun. **2021**, 124, 1123–1150. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Classification+of+Amniotic+Fluid+Level+Using+Bi-LSTM+with+Homomorphic+filter+and+Contrast+Enhancement+Techniques&author=Ramya,+R.&author=Srinivasan,+K.&publication_year=2021&journal=Wirel.+Pers.+Commun.&volume=124&pages=1123%E2%80%931150&doi=10.1007/s11277-021-09397-w)\] \[ [CrossRef](http://doi.org/10.1007/s11277-021-09397-w)\]
12. Ayu, P.D.W.; Hartati, S.; Musdholifah, A.; Nurdiati, D.S. Amniotic Fluids Classification Using Combination of Rules-Based and Random Forest Algorithm. In Communications in Computer and Information Science; Springer: Berlin/Heidelberg, Germany, 2021; Volume 1489, pp. 267–285. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Amniotic+Fluids+Classification+Using+Combination+of+Rules-Based+and+Random+Forest+Algorithm&author=Ayu,+P.D.W.&author=Hartati,+S.&author=Musdholifah,+A.&author=Nurdiati,+D.S.&publication_year=2021&pages=267%E2%80%93285)\] \[ [CrossRef](http://doi.org/10.1007/978-981-16-7334-4_20)\]
13. Ayu, P.D.W.; Hartati, S. Pixel Classification Based on Local Gray Level Rectangle Window Sampling for Amniotic Fluid Segmentation. Int. J. Intell. Eng. Syst. **2021**, 14, 420–432. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Pixel+Classification+Based+on+Local+Gray+Level+Rectangle+Window+Sampling+for+Amniotic+Fluid+Segmentation&author=Ayu,+P.D.W.&author=Hartati,+S.&publication_year=2021&journal=Int.+J.+Intell.+Eng.+Syst.&volume=14&pages=420%E2%80%93432&doi=10.22266/IJIES2021.0228.39)\] \[ [CrossRef](http://doi.org/10.22266/IJIES2021.0228.39)\]
14. Amuthadevi, C.; Subarnan, G.M. Development of fuzzy approach to predict the fetus safety and growth using AFI. J. Supercomput. **2020**, 76, 5981–5995. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Development+of+fuzzy+approach+to+predict+the+fetus+safety+and+growth+using+AFI&author=Amuthadevi,+C.&author=Subarnan,+G.M.&publication_year=2020&journal=J.+Supercomput.&volume=76&pages=5981%E2%80%935995&doi=10.1007/s11227-019-03099-8)\] \[ [CrossRef](http://doi.org/10.1007/s11227-019-03099-8)\]
15. Sun, S.; Kwon, J.Y.; Park, Y.; Cho, H.C.; Hyun, C.M.; Seo, J.K. Complementary Network for Accurate Amniotic Fluid Segmentation from Ultrasound Images. IEEE Access **2021**, 9, 108223–108235. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Complementary+Network+for+Accurate+Amniotic+Fluid+Segmentation+from+Ultrasound+Images&author=Sun,+S.&author=Kwon,+J.Y.&author=Park,+Y.&author=Cho,+H.C.&author=Hyun,+C.M.&author=Seo,+J.K.&publication_year=2021&journal=IEEE+Access&volume=9&pages=108223%E2%80%93108235&doi=10.1109/ACCESS.2021.3098844)\] \[ [CrossRef](http://doi.org/10.1109/ACCESS.2021.3098844)\]
16. Li, Y.; Xu, R.; Ohya, J.; Iwata, H. Automatic fetal body and amniotic fluid segmentation from fetal ultrasound images by encoder-decoder network with inner layers. In Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBS), Jeju, Korea, 11–15 July 2017. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Automatic+fetal+body+and+amniotic+fluid+segmentation+from+fetal+ultrasound+images+by+encoder-decoder+network+with+inner+layers&conference=Proceedings+of+the+Annual+International+Conference+of+the+IEEE+Engineering+in+Medicine+and+Biology+Society+(EMBS)&author=Li,+Y.&author=Xu,+R.&author=Ohya,+J.&author=Iwata,+H.&publication_year=2017&doi=10.1109/EMBC.2017.8037116)\] \[ [CrossRef](http://doi.org/10.1109/EMBC.2017.8037116)\]
17. Ayu, D.W.; Hartati, S.; Musdholifah, A. Amniotic Fluid Segmentation by Pixel Classification in B-Mode Ultrasound Image for Computer Assisted Diagnosis. In Communications in Computer and Information Science; Springer: Berlin/Heidelberg, Germany, 2019; Volume 1100. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Amniotic+Fluid+Segmentation+by+Pixel+Classification+in+B-Mode+Ultrasound+Image+for+Computer+Assisted+Diagnosis&author=Ayu,+D.W.&author=Hartati,+S.&author=Musdholifah,+A.&publication_year=2019)\] \[ [CrossRef](http://doi.org/10.1007/978-981-15-0399-3_5)\]
18. Ayu, P.D.W.; Hartati, S.; Musdholifah, A.; Nurdiati, D.S. Amniotic fluid segmentation based on pixel classification using local window information and distance angle pixel. Appl. Soft Comput. **2021**, 107, 107196\. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Amniotic+fluid+segmentation+based+on+pixel+classification+using+local+window+information+and+distance+angle+pixel&author=Ayu,+P.D.W.&author=Hartati,+S.&author=Musdholifah,+A.&author=Nurdiati,+D.S.&publication_year=2021&journal=Appl.+Soft+Comput.&volume=107&pages=107196&doi=10.1016/j.asoc.2021.107196)\] \[ [CrossRef](http://doi.org/10.1016/j.asoc.2021.107196)\]
19. Looney, P.; Yin, Y.; Collins, S.L.; Nicolaides, K.H.; Plasencia, W.; Molloholli, M.; Natsis, S.; Stevenson, G.N. Fully Automated 3-D Ultrasound Segmentation of the Placenta, Amniotic Fluid, and Fetus for Early Pregnancy Assessment. IEEE Trans. Ultrason. Ferroelectr. Freq. Control **2021**, 68, 2038–2047. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Fully+Automated+3-D+Ultrasound+Segmentation+of+the+Placenta,+Amniotic+Fluid,+and+Fetus+for+Early+Pregnancy+Assessment&author=Looney,+P.&author=Yin,+Y.&author=Collins,+S.L.&author=Nicolaides,+K.H.&author=Plasencia,+W.&author=Molloholli,+M.&author=Natsis,+S.&author=Stevenson,+G.N.&publication_year=2021&journal=IEEE+Trans.+Ultrason.+Ferroelectr.+Freq.+Control&volume=68&pages=2038%E2%80%932047&doi=10.1109/TUFFC.2021.3052143)\] \[ [CrossRef](http://doi.org/10.1109/TUFFC.2021.3052143)\]
20. Anquez, J.; Angelini, E.D.; Grange, G.; Bloch, I. Automatic segmentation of antenatal 3-D ultrasound images. IEEE Trans. Biomed. Eng. **2013**, 60, 1388–1400. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Automatic+segmentation+of+antenatal+3-D+ultrasound+images&author=Anquez,+J.&author=Angelini,+E.D.&author=Grange,+G.&author=Bloch,+I.&publication_year=2013&journal=IEEE+Trans.+Biomed.+Eng.&volume=60&pages=1388%E2%80%931400&doi=10.1109/TBME.2012.2237400)\] \[ [CrossRef](http://doi.org/10.1109/TBME.2012.2237400)\] \[ [Green Version](http://perso.telecom-paristech.fr/~angelini/shared_files/papers_links/anquez:TBME-13.pdf)\]
21. Friedman, P.; Ogunyemi, D. Oligohydramnios. In Obstetric Imaging: Fetal Diagnosis and Care, 2nd ed.; Elsevier: Amsterdam, The Netherlands, 2021. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Oligohydramnios&author=Friedman,+P.&author=Ogunyemi,+D.&publication_year=2021)\]
22. Han, M.; Bao, Y.; Sun, Z.; Wen, S.; Xia, L.; Zhao, J.; Du, J.; Yan, Z. Automatic Segmentation of Human Placenta Images with U-Net. IEEE Access **2019**, 7, 180083–180092. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Automatic+Segmentation+of+Human+Placenta+Images+with+U-Net&author=Han,+M.&author=Bao,+Y.&author=Sun,+Z.&author=Wen,+S.&author=Xia,+L.&author=Zhao,+J.&author=Du,+J.&author=Yan,+Z.&publication_year=2019&journal=IEEE+Access&volume=7&pages=180083%E2%80%93180092&doi=10.1109/ACCESS.2019.2958133)\] \[ [CrossRef](http://doi.org/10.1109/ACCESS.2019.2958133)\]
23. Yang, X.; Yu, L.; Li, S.; Wang, X.; Wang, N.; Qin, J.; Ni, D.; Heng, P.-A. Towards Automatic Semantic Segmentation in Volumetric Ultrasound. In Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2017, Quebec City, QC, Canada, 11–13 September 2017; pp. 711–719. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Towards+Automatic+Semantic+Segmentation+in+Volumetric+Ultrasound&conference=Proceedings+of+the+Medical+Image+Computing+and+Computer+Assisted+Intervention%E2%80%94MICCAI+2017&author=Yang,+X.&author=Yu,+L.&author=Li,+S.&author=Wang,+X.&author=Wang,+N.&author=Qin,+J.&author=Ni,+D.&author=Heng,+P.-A.&publication_year=2017&pages=711%E2%80%93719)\]
24. Hu, R.; Singla, R.; Yan, R.; Mayer, C.; Rohling, R.N. Automated Placenta Segmentation with a Convolutional Neural Network Weighted by Acoustic Shadow Detection. In Proceedings of the 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Berlin, Germany, 23–27 July 2019; pp. 6718–6723. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Automated+Placenta+Segmentation+with+a+Convolutional+Neural+Network+Weighted+by+Acoustic+Shadow+Detection&conference=Proceedings+of+the+2019+41st+Annual+International+Conference+of+the+IEEE+Engineering+in+Medicine+and+Biology+Society+(EMBC)&author=Hu,+R.&author=Singla,+R.&author=Yan,+R.&author=Mayer,+C.&author=Rohling,+R.N.&publication_year=2019&pages=6718%E2%80%936723&doi=10.1109/EMBC.2019.8857448)\] \[ [CrossRef](http://doi.org/10.1109/EMBC.2019.8857448)\]
25. Zimmer, V.A.; Gomez, A.; Skelton, E.; Ghavami, N.; Wright, R.; Li, L.; Matthew, J.; Hajnal, J.V.; Schnabel, J.A. A Multi-task Approach Using Positional Information for Ultrasound Placenta Segmentation. In Proceedings of the Medical Ultrasound, and Preterm, Perinatal and Paediatric Image Analysis, Lima, Peru, 4–8 October 2020; pp. 264–273. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=A+Multi-task+Approach+Using+Positional+Information+for+Ultrasound+Placenta+Segmentation&conference=Proceedings+of+the+Medical+Ultrasound,+and+Preterm,+Perinatal+and+Paediatric+Image+Analysis&author=Zimmer,+V.A.&author=Gomez,+A.&author=Skelton,+E.&author=Ghavami,+N.&author=Wright,+R.&author=Li,+L.&author=Matthew,+J.&author=Hajnal,+J.V.&author=Schnabel,+J.A.&publication_year=2020&pages=264%E2%80%93273)\]
26. Hu, Z.; Hu, R.; Yan, R.; Mayer, C.; Rohling, R.N.; Singla, R. Automatic Placenta Abnormality Detection Using Convolutional Neural Networks on Ultrasound Texture. In Proceedings of the Uncertainty for Safe Utilization of Machine Learning in Medical Imaging, and Perinatal Imaging, Placental and Preterm Image Analysis, Strasbourg, France, 1 October 2021; pp. 147–156. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Automatic+Placenta+Abnormality+Detection+Using+Convolutional+Neural+Networks+on+Ultrasound+Texture&conference=Proceedings+of+the+Uncertainty+for+Safe+Utilization+of+Machine+Learning+in+Medical+Imaging,+and+Perinatal+Imaging,+Placental+and+Preterm+Image+Analysis&author=Hu,+Z.&author=Hu,+R.&author=Yan,+R.&author=Mayer,+C.&author=Rohling,+R.N.&author=Singla,+R.&publication_year=2021&pages=147%E2%80%93156)\]
27. Schilpzand, M.; Neff, C.; van Dillen, J.; van Ginneken, B.; Heskes, T.; de Korte, C.; van den Heuvel, T. Automatic Placenta Localization From Ultrasound Imaging in a Resource-Limited Setting Using a Predefined Ultrasound Acquisition Protocol and Deep Learning. Ultrasound Med. Biol. **2022**, 48, 663–674. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Automatic+Placenta+Localization+From+Ultrasound+Imaging+in+a+Resource-Limited+Setting+Using+a+Predefined+Ultrasound+Acquisition+Protocol+and+Deep+Learning&author=Schilpzand,+M.&author=Neff,+C.&author=van+Dillen,+J.&author=van+Ginneken,+B.&author=Heskes,+T.&author=de+Korte,+C.&author=van+den+Heuvel,+T.&publication_year=2022&journal=Ultrasound+Med.+Biol.&volume=48&pages=663%E2%80%93674&doi=10.1016/j.ultrasmedbio.2021.12.006)\] \[ [CrossRef](http://doi.org/10.1016/j.ultrasmedbio.2021.12.006)\]
28. Zimmer, V.A.; Gomez, A.; Skelton, E.; Toussaint, N.; Zhang, T.; Khanal, B.; Wright, R.; Noh, Y.; Ho, A.; Matthew, J.; et al. Towards Whole Placenta Segmentation at Late Gestation Using Multi-view Ultrasound Images. In Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2019, Shenzhen, China, 13–17 October 2019; pp. 628–636. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Towards+Whole+Placenta+Segmentation+at+Late+Gestation+Using+Multi-view+Ultrasound+Images&conference=Proceedings+of+the+Medical+Image+Computing+and+Computer+Assisted+Intervention%E2%80%94MICCAI+2019&author=Zimmer,+V.A.&author=Gomez,+A.&author=Skelton,+E.&author=Toussaint,+N.&author=Zhang,+T.&author=Khanal,+B.&author=Wright,+R.&author=Noh,+Y.&author=Ho,+A.&author=Matthew,+J.&publication_year=2019&pages=628%E2%80%93636)\]
29. Looney, P.; Stevenson, G.N.; Nicolaides, K.H.; Plasencia, W.; Molloholli, M.; Natsis, S.; Collins, S.L. Automatic 3D ultrasound segmentation of the first trimester placenta using deep learning. In Proceedings of the International Symposium on Biomedical Imaging, Melbourne, VIC, Australia, 18–21 April 2017. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Automatic+3D+ultrasound+segmentation+of+the+first+trimester+placenta+using+deep+learning&conference=Proceedings+of+the+International+Symposium+on+Biomedical+Imaging&author=Looney,+P.&author=Stevenson,+G.N.&author=Nicolaides,+K.H.&author=Plasencia,+W.&author=Molloholli,+M.&author=Natsis,+S.&author=Collins,+S.L.&publication_year=2017&doi=10.1109/ISBI.2017.7950519)\] \[ [CrossRef](http://doi.org/10.1109/ISBI.2017.7950519)\]
30. Looney, P.; Stevenson, G.N.; Nicolaides, K.H.; Plasencia, W.; Molloholli, M.; Natsis, S.; Collins, S.L. Fully automated, real-time 3D ultrasound segmentation to estimate first trimester placental volume using deep learning. JCI Insight **2018**, 3, e120178. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Fully+automated,+real-time+3D+ultrasound+segmentation+to+estimate+first+trimester+placental+volume+using+deep+learning&author=Looney,+P.&author=Stevenson,+G.N.&author=Nicolaides,+K.H.&author=Plasencia,+W.&author=Molloholli,+M.&author=Natsis,+S.&author=Collins,+S.L.&publication_year=2018&journal=JCI+Insight&volume=3&pages=e120178&doi=10.1172/jci.insight.120178)\] \[ [CrossRef](http://doi.org/10.1172/jci.insight.120178)\]
31. Saavedra, A.C.; Arroyo, J.; Tamayo, L.; Egoavil, M.; Ramos, B.; Castaneda, B. Automatic ultrasound assessment of placenta previa during the third trimester for rural areas. In Proceedings of the 2020 IEEE International Ultrasonics Symposium (IUS), Las Vegas, NV, USA, 7–11 September 2020; pp. 1–4. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Automatic+ultrasound+assessment+of+placenta+previa+during+the+third+trimester+for+rural+areas&conference=Proceedings+of+the+2020+IEEE+International+Ultrasonics+Symposium+(IUS)&author=Saavedra,+A.C.&author=Arroyo,+J.&author=Tamayo,+L.&author=Egoavil,+M.&author=Ramos,+B.&author=Castaneda,+B.&publication_year=2020&pages=1%E2%80%934&doi=10.1109/IUS46767.2020.9251764)\] \[ [CrossRef](http://doi.org/10.1109/IUS46767.2020.9251764)\]
32. Oguz, B.U.; Wang, J.; Yushkevich, N.; Pouch, A.; Gee, J.; Yushkevich, P.A.; Schwartz, N.; Oguz, I. Combining Deep Learning and Multi-atlas Label Fusion for Automated Placenta Segmentation from 3DUS. In Proceedings of the Data Driven Treatment Response Assessment and Preterm, Perinatal, and Paediatric Image Analysis, Granada, Spain, 16 September 2018; pp. 138–148. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Combining+Deep+Learning+and+Multi-atlas+Label+Fusion+for+Automated+Placenta+Segmentation+from+3DUS&conference=Proceedings+of+the+Data+Driven+Treatment+Response+Assessment+and+Preterm,+Perinatal,+and+Paediatric+Image+Analysis&author=Oguz,+B.U.&author=Wang,+J.&author=Yushkevich,+N.&author=Pouch,+A.&author=Gee,+J.&author=Yushkevich,+P.A.&author=Schwartz,+N.&author=Oguz,+I.&publication_year=2018&pages=138%E2%80%93148)\]
33. Qi, H.; Collins, S.; Noble, J.A. Knowledge-guided Pretext Learning for Utero-placental Interface Detection. Med. Image Comput. Comput. Interv. MICCAI **2020**, 12261, 582–593. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Knowledge-guided+Pretext+Learning+for+Utero-placental+Interface+Detection&author=Qi,+H.&author=Collins,+S.&author=Noble,+J.A.&publication_year=2020&journal=Med.+Image+Comput.+Comput.+Interv.+MICCAI&volume=12261&pages=582%E2%80%93593&doi=10.1007/978-3-030-59710-8_57)\] \[ [CrossRef](http://doi.org/10.1007/978-3-030-59710-8_57)\]
34. Romeo, V.; Ricciardi, C.; Cuocolo, R.; Stanzione, A.; Verde, F.; Sarno, L.; Improta, G.; Mainenti, P.P.; D’Armiento, M.; Brunetti, A.; et al. Machine learning analysis of MRI-derived texture features to predict placenta accreta spectrum in patients with placenta previa. Magn. Reson. Imaging **2019**, 64, 71–76. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Machine+learning+analysis+of+MRI-derived+texture+features+to+predict+placenta+accreta+spectrum+in+patients+with+placenta+previa&author=Romeo,+V.&author=Ricciardi,+C.&author=Cuocolo,+R.&author=Stanzione,+A.&author=Verde,+F.&author=Sarno,+L.&author=Improta,+G.&author=Mainenti,+P.P.&author=D%E2%80%99Armiento,+M.&author=Brunetti,+A.&publication_year=2019&journal=Magn.+Reson.+Imaging&volume=64&pages=71%E2%80%9376&doi=10.1016/j.mri.2019.05.017&pmid=31102613)\] \[ [CrossRef](http://doi.org/10.1016/j.mri.2019.05.017)\] \[ [PubMed](http://www.ncbi.nlm.nih.gov/pubmed/31102613)\]
35. Chen, Y.; Wu, C.; Zhang, Z.; Goldstein, J.A.; Gernand, A.D.; Wang, J.Z. PlacentaNet: Automatic Morphological Characterization of Placenta Photos with Deep Learning. In Proceedings of the Medical Image Computing and Computer Assisted Intervention—MICCAI 2019: 22nd International Conference, Shenzhen, China, 13–17 October 2019; pp. 487–495. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=PlacentaNet:+Automatic+Morphological+Characterization+of+Placenta+Photos+with+Deep+Learning&conference=Proceedings+of+the+Medical+Image+Computing+and+Computer+Assisted+Intervention%E2%80%94MICCAI+2019:+22nd+International+Conference&author=Chen,+Y.&author=Wu,+C.&author=Zhang,+Z.&author=Goldstein,+J.A.&author=Gernand,+A.D.&author=Wang,+J.Z.&publication_year=2019&pages=487%E2%80%93495&doi=10.1007/978-3-030-32239-7_54)\] \[ [CrossRef](http://doi.org/10.1007/978-3-030-32239-7_54)\]
36. Sridar, P.; Kumar, A.; Quinton, A.; Nanan, R.; Kim, J.; Krishnakumar, R. Decision Fusion-Based Fetal Ultrasound Image Plane Classification Using Convolutional Neural Networks. Ultrasound Med. Biol. **2019**, 45, 1259–1273. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Decision+Fusion-Based+Fetal+Ultrasound+Image+Plane+Classification+Using+Convolutional+Neural+Networks&author=Sridar,+P.&author=Kumar,+A.&author=Quinton,+A.&author=Nanan,+R.&author=Kim,+J.&author=Krishnakumar,+R.&publication_year=2019&journal=Ultrasound+Med.+Biol.&volume=45&pages=1259%E2%80%931273&doi=10.1016/j.ultrasmedbio.2018.11.016&pmid=30826153)\] \[ [CrossRef](http://doi.org/10.1016/j.ultrasmedbio.2018.11.016)\] \[ [PubMed](http://www.ncbi.nlm.nih.gov/pubmed/30826153)\]
37. Zhou, Y. Prediction and Value of Ultrasound Image in Diagnosis of Fetal Central Nervous System Malformation under Deep Learning Algorithm. Adv. Sci. Program. Methods Health Inform. **2021**, 2021, 6246274\. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Prediction+and+Value+of+Ultrasound+Image+in+Diagnosis+of+Fetal+Central+Nervous+System+Malformation+under+Deep+Learning+Algorithm&author=Zhou,+Y.&publication_year=2021&journal=Adv.+Sci.+Program.+Methods+Health+Inform.&volume=2021&pages=6246274&doi=10.1155/2021/6246274)\] \[ [CrossRef](http://doi.org/10.1155/2021/6246274)\]
38. Attallah, O.; Sharkas, M.A.; Gadelkarim, H. Deep Learning Techniques for Automatic Detection of Embryonic Neurodevelopmental Disorders. Diagnostics **2020**, 10, 27\. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Deep+Learning+Techniques+for+Automatic+Detection+of+Embryonic+Neurodevelopmental+Disorders&author=Attallah,+O.&author=Sharkas,+M.A.&author=Gadelkarim,+H.&publication_year=2020&journal=Diagnostics&volume=10&pages=27&doi=10.3390/diagnostics10010027&pmid=31936008)\] \[ [CrossRef](http://doi.org/10.3390/diagnostics10010027)\] \[ [PubMed](http://www.ncbi.nlm.nih.gov/pubmed/31936008)\] \[ [Green Version](https://www.mdpi.com/2075-4418/10/1/27/pdf)\]
39. Bano, S.; Vasconcelos, F.; Vander Poorten, E.; Vercauteren, T.; Ourselin, S.; Deprest, J.; Stoyanov, D. FetNet: A recurrent convolutional network for occlusion identification in fetoscopic videos. Int. J. Comput. Assist. Radiol. Surg. **2020**, 15, 791–801. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=FetNet:+A+recurrent+convolutional+network+for+occlusion+identification+in+fetoscopic+videos&author=Bano,+S.&author=Vasconcelos,+F.&author=Vander+Poorten,+E.&author=Vercauteren,+T.&author=Ourselin,+S.&author=Deprest,+J.&author=Stoyanov,+D.&publication_year=2020&journal=Int.+J.+Comput.+Assist.+Radiol.+Surg.&volume=15&pages=791%E2%80%93801&doi=10.1007/s11548-020-02169-0&pmid=32350787)\] \[ [CrossRef](http://doi.org/10.1007/s11548-020-02169-0)\] \[ [PubMed](http://www.ncbi.nlm.nih.gov/pubmed/32350787)\]
40. Bano, S.; Vasconcelos, F.; Tella-Amo, M.; Dwyer, G.; Gruijthuijsen, C.; Vander Poorten, E.; Vercauteren, T.; Ourselin, S.; Deprest, J.; Stoyanov, D. Deep learning-based fetoscopic mosaicking for field-of-view expansion. Int. J. Comput. Assist. Radiol. Surg. **2020**, 15, 1807–1816. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Deep+learning-based+fetoscopic+mosaicking+for+field-of-view+expansion&author=Bano,+S.&author=Vasconcelos,+F.&author=Tella-Amo,+M.&author=Dwyer,+G.&author=Gruijthuijsen,+C.&author=Vander+Poorten,+E.&author=Vercauteren,+T.&author=Ourselin,+S.&author=Deprest,+J.&author=Stoyanov,+D.&publication_year=2020&journal=Int.+J.+Comput.+Assist.+Radiol.+Surg.&volume=15&pages=1807%E2%80%931816&doi=10.1007/s11548-020-02242-8&pmid=32808148)\] \[ [CrossRef](http://doi.org/10.1007/s11548-020-02242-8)\] \[ [PubMed](http://www.ncbi.nlm.nih.gov/pubmed/32808148)\]
41. Ahmad, M.A.; Ourak, M.; Gruijthuijsen, C.; Deprest, J.; Vercauteren, T.; Vander Poorten, E. Deep learning-based monocular placental pose estimation: Towards collaborative robotics in fetoscopy. Int. J. Comput. Assist. Radiol. Surg. **2020**, 15, 1561–1571. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Deep+learning-based+monocular+placental+pose+estimation:+Towards+collaborative+robotics+in+fetoscopy&author=Ahmad,+M.A.&author=Ourak,+M.&author=Gruijthuijsen,+C.&author=Deprest,+J.&author=Vercauteren,+T.&author=Vander+Poorten,+E.&publication_year=2020&journal=Int.+J.+Comput.+Assist.+Radiol.+Surg.&volume=15&pages=1561%E2%80%931571&doi=10.1007/s11548-020-02166-3)\] \[ [CrossRef](http://doi.org/10.1007/s11548-020-02166-3)\]
42. Casella, A.; Moccia, S.; Frontoni, E.; Paladini, D.; De Momi, E.; Mattos, L.S. Inter-foetus Membrane Segmentation for TTTS Using Adversarial Networks. Ann. Biomed. Eng. **2020**, 48, 848–859. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Inter-foetus+Membrane+Segmentation+for+TTTS+Using+Adversarial+Networks&author=Casella,+A.&author=Moccia,+S.&author=Frontoni,+E.&author=Paladini,+D.&author=De+Momi,+E.&author=Mattos,+L.S.&publication_year=2020&journal=Ann.+Biomed.+Eng.&volume=48&pages=848%E2%80%93859&doi=10.1007/s10439-019-02424-9)\] \[ [CrossRef](http://doi.org/10.1007/s10439-019-02424-9)\] \[ [Green Version](https://re.public.polimi.it/bitstream/11311/1121585/1/Casella___ABME___2019__Copy_-2.pdf)\]
43. Sufriyana, H.; Wu, Y.-W.; Su, E.C.-Y. Prognostication for prelabor rupture of membranes and the time of delivery in nationwide insured women: Development, validation, and deployment. medRxiv **2021**. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Prognostication+for+prelabor+rupture+of+membranes+and+the+time+of+delivery+in+nationwide+insured+women:+Development,+validation,+and+deployment&author=Sufriyana,+H.&author=Wu,+Y.-W.&author=Su,+E.C.-Y.&publication_year=2021&journal=medRxiv&doi=10.1101/2021.06.16.21258884)\] \[ [CrossRef](http://doi.org/10.1101/2021.06.16.21258884)\]
44. Gao, C.; Osmundson, S.; Velez Edwards, D.R.; Jackson, G.P.; Malin, B.A.; Chen, Y. Deep learning predicts extreme preterm birth from electronic health records. J. Biomed. Inform. **2019**, 100, 103334\. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Deep+learning+predicts+extreme+preterm+birth+from+electronic+health+records&author=Gao,+C.&author=Osmundson,+S.&author=Velez+Edwards,+D.R.&author=Jackson,+G.P.&author=Malin,+B.A.&author=Chen,+Y.&publication_year=2019&journal=J.+Biomed.+Inform.&volume=100&pages=103334&doi=10.1016/j.jbi.2019.103334)\] \[ [CrossRef](http://doi.org/10.1016/j.jbi.2019.103334)\]
45. Lee, K.-S.; Kim, H.Y.; Lee, S.J.; Kwon, S.O.; Na, S.; Hwang, H.S.; Park, M.H.; Ahn, K.H.; Korean Society of Ultrasound in Obstetrics and Gynecology Research Group. Prediction of newborn’s body mass index using nationwide multicenter ultrasound data: A machine-learning study. BMC Pregnancy Childbirth **2021**, 21, 172\. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Prediction+of+newborn%E2%80%99s+body+mass+index+using+nationwide+multicenter+ultrasound+data:+A+machine-learning+study&author=Lee,+K.-S.&author=Kim,+H.Y.&author=Lee,+S.J.&author=Kwon,+S.O.&author=Na,+S.&author=Hwang,+H.S.&author=Park,+M.H.&author=Ahn,+K.H.&author=Korean+Society+of+Ultrasound+in+Obstetrics+and+Gynecology+Research+Group&publication_year=2021&journal=BMC+Pregnancy+Childbirth&volume=21&pages=172&doi=10.1186/s12884-021-03660-5&pmid=33653299)\] \[ [CrossRef](http://doi.org/10.1186/s12884-021-03660-5)\] \[ [PubMed](http://www.ncbi.nlm.nih.gov/pubmed/33653299)\]
46. Feng, M.; Wan, L.; Li, Z.; Qing, L.; Qi, X. Fetal Weight Estimation via Ultrasound Using Machine Learning. IEEE Access **2019**, 7, 87783–87791. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Fetal+Weight+Estimation+via+Ultrasound+Using+Machine+Learning&author=Feng,+M.&author=Wan,+L.&author=Li,+Z.&author=Qing,+L.&author=Qi,+X.&publication_year=2019&journal=IEEE+Access&volume=7&pages=87783%E2%80%9387791&doi=10.1109/ACCESS.2019.2925803)\] \[ [CrossRef](http://doi.org/10.1109/ACCESS.2019.2925803)\]
47. Ghelich Oghli, M.; Shabanzadeh, A.; Moradi, S.; Sirjani, N.; Gerami, R.; Ghaderi, P.; Sanei Taheri, M.; Shiri, I.; Arabi, H.; Zaidi, H. Automatic fetal biometry prediction using a novel deep convolutional network architecture. Phys. Med. **2021**, 88, 127–137. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Automatic+fetal+biometry+prediction+using+a+novel+deep+convolutional+network+architecture&author=Ghelich+Oghli,+M.&author=Shabanzadeh,+A.&author=Moradi,+S.&author=Sirjani,+N.&author=Gerami,+R.&author=Ghaderi,+P.&author=Sanei+Taheri,+M.&author=Shiri,+I.&author=Arabi,+H.&author=Zaidi,+H.&publication_year=2021&journal=Phys.+Med.&volume=88&pages=127%E2%80%93137&doi=10.1016/j.ejmp.2021.06.020&pmid=34242884)\] \[ [CrossRef](http://doi.org/10.1016/j.ejmp.2021.06.020)\] \[ [PubMed](http://www.ncbi.nlm.nih.gov/pubmed/34242884)\]
48. Liu, S.; Wang, Y.; Yang, X.; Lei, B.; Liu, L.; Li, S.X.; Ni, D.; Wang, T. Deep Learning in Medical Ultrasound Analysis: A Review. Engineering **2019**, 5, 261–275. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Deep+Learning+in+Medical+Ultrasound+Analysis:+A+Review&author=Liu,+S.&author=Wang,+Y.&author=Yang,+X.&author=Lei,+B.&author=Liu,+L.&author=Li,+S.X.&author=Ni,+D.&author=Wang,+T.&publication_year=2019&journal=Engineering&volume=5&pages=261%E2%80%93275&doi=10.1016/j.eng.2018.11.020)\] \[ [CrossRef](http://doi.org/10.1016/j.eng.2018.11.020)\]
49. Park, S.H. Artificial intelligence for ultrasonography: Unique opportunities and challenges. Ultrasonography **2021**, 40, 3–6. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Artificial+intelligence+for+ultrasonography:+Unique+opportunities+and+challenges&author=Park,+S.H.&publication_year=2021&journal=Ultrasonography&volume=40&pages=3%E2%80%936&doi=10.14366/usg.20078)\] \[ [CrossRef](http://doi.org/10.14366/usg.20078)\]
50. Wadden, J.J. Defining the undefinable: The black box problem in healthcare artificial intelligence. J. Med. Ethics **2021**. Online First. \[ [Google Scholar](http://scholar.google.com/scholar_lookup?title=Defining+the+undefinable:+The+black+box+problem+in+healthcare+artificial+intelligence&author=Wadden,+J.J.&publication_year=2021&journal=J.+Med.+Ethics&doi=10.1136/medethics-2021-107529)\] \[ [CrossRef](http://doi.org/10.1136/medethics-2021-107529)\]

**Figure 1.**
Taxonomy of AF detection using AI techniques.

**Figure 1.**
Taxonomy of AF detection using AI techniques.

**Figure 2.**
Methodology adopted for the systematic review.

**Figure 2.**
Methodology adopted for the systematic review.

**Figure 3.**
Distribution of the studies based on the AI method type.

**Figure 3.**
Distribution of the studies based on the AI method type.

**Figure 4.**
AI techniques used.

**Figure 4.**
AI techniques used.

**Figure 5.**
Data types used by various studies.

**Figure 5.**
Data types used by various studies.

**Figure 6.**
Dataset type and size of various studies.

**Figure 6.**
Dataset type and size of various studies.

**Table 1.**
Summary of amniotic fluid classification studies using AI techniques.


**Table 1.**
Summary of amniotic fluid classification studies using AI techniques.

| Domain | Ref. | Year | Data Type | Dataset Size | Binary/<br>Multi-Class | Augmentation | Methods | MSE | Accuracy |
| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |
| ML | \[ [12](https://www.mdpi.com/1424-8220/22/12/4570#B12-sensors-22-04570)\] | 2021 | US Images | 95 | Multi | No | RF |  | 0.9052 |
| \[ [13](https://www.mdpi.com/1424-8220/22/12/4570#B13-sensors-22-04570)\] | 2021 | US Images | 50 | Multi | No | RF, DT |  | 0.995 |
| DL | \[ [11](https://www.mdpi.com/1424-8220/22/12/4570#B11-sensors-22-04570)\] | 2021 | US Images | 4000 | Multi | No | HBU-LSTM | 0.5244 |  |
| \[ [10](https://www.mdpi.com/1424-8220/22/12/4570#B10-sensors-22-04570)\] | 2018 | US Images | 26 | Binary | Yes | CNN |  | 0.95 |
| \[ [14](https://www.mdpi.com/1424-8220/22/12/4570#B14-sensors-22-04570)\] | 2020 | US Images | 50 | Multi | No | Fuzzy Technique |  | 0.925 |

**Table 2.**
Summary of AF segmentation studies using AI techniques.


**Table 2.**
Summary of AF segmentation studies using AI techniques.

| Domain | Ref. | Year | Data Type | Dataset Size | Binary/<br>Multi-Class | Augmentation | Methods | DSC | Accuracy |
| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |
| DL | \[ [5](https://www.mdpi.com/1424-8220/22/12/4570#B5-sensors-22-04570)\] | 2021 | US Images | 435 | Binary | Yes | U-net (CNN) | 0.877 |  |
| \[ [15](https://www.mdpi.com/1424-8220/22/12/4570#B15-sensors-22-04570)\] | 2021 | US Images | 2380 | Multi | Yes | AF-net + Auxiliary Network | 0.8599 |  |
| \[ [19](https://www.mdpi.com/1424-8220/22/12/4570#B19-sensors-22-04570)\] | 2021 | US Images | 2393 | Binary, Multi | No | FCNN | 0.84 |  |
| \[ [16](https://www.mdpi.com/1424-8220/22/12/4570#B16-sensors-22-04570)\] | 2017 | US Videos | 601 | Multi | Yes | CNN, Encoder–Decoder Network |  | 0.93 |
| ML | \[ [18](https://www.mdpi.com/1424-8220/22/12/4570#B18-sensors-22-04570)\] | 2021 | US Images | 55 | Binary | No | RF, DT, NB, SVM, and KNN | RF—0.876 |  |
| \[ [17](https://www.mdpi.com/1424-8220/22/12/4570#B17-sensors-22-04570)\] | 2019 | US Images | 50 | Multi | Yes | RF | 0.5553 | 0.8586 |
| \[ [20](https://www.mdpi.com/1424-8220/22/12/4570#B20-sensors-22-04570)\] | 2013 | US Images | 19 | Binary | No | Bayesian Formulation | Overlap Measure—0.89 |  |

**Table 3.**
Summary of studies investigating abnormal amniotic fluid causes using AI techniques.


**Table 3.**
Summary of studies investigating abnormal amniotic fluid causes using AI techniques.

| Condition | Ref. | Type | Year | Data Type | Dataset Size | Domain | Methods | Performance Measure |
| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |
| Oligo | \[ [29](https://www.mdpi.com/1424-8220/22/12/4570#B29-sensors-22-04570)\] | Placenta | 2017 | US Images | 2893 | DL | CNN, Random Walker | DSC-0.73 |
| \[ [22](https://www.mdpi.com/1424-8220/22/12/4570#B22-sensors-22-04570)\] | Placenta | 2019 | MRI Images | 1110 | DL | CNN (U-net) | Acc-0.98 |
| \[ [30](https://www.mdpi.com/1424-8220/22/12/4570#B30-sensors-22-04570)\] | Placenta | 2018 | US Images | 1200 | DL | CNN | DSC-0.81 |
| \[ [25](https://www.mdpi.com/1424-8220/22/12/4570#B25-sensors-22-04570)\] | Placenta | 2020 | US Images (3D) | 1054 | DL | U-net | DSC-0.87 |
| \[ [24](https://www.mdpi.com/1424-8220/22/12/4570#B24-sensors-22-04570)\] | Placenta | 2019 | US Images | 1364 | DL | CNN | DSC-0.92 |
| \[ [26](https://www.mdpi.com/1424-8220/22/12/4570#B26-sensors-22-04570)\] | Placenta | 2021 | US Images | 321 (patients) | DL | CNN | Acc-0.81 |
| \[ [27](https://www.mdpi.com/1424-8220/22/12/4570#B27-sensors-22-04570)\] | Placenta | 2021 | US Images | 6576 | DL | U-net | Acc-0.84 |
| \[ [31](https://www.mdpi.com/1424-8220/22/12/4570#B31-sensors-22-04570)\] | Placenta | 2020 | US Images | 11,014 | DL | U-net | Sen-0.75<br>Spe-0.92 |
| \[ [32](https://www.mdpi.com/1424-8220/22/12/4570#B32-sensors-22-04570)\] | Placenta | 2018 | US Images | 47 (patients) | DL | JLF + CNN | DSC-0.863 |
| \[ [33](https://www.mdpi.com/1424-8220/22/12/4570#B33-sensors-22-04570)\] | Placenta | 2020 | US Volumes | 101 | DL | KPL, ImageNet | ODS-0.605 |
| \[ [34](https://www.mdpi.com/1424-8220/22/12/4570#B34-sensors-22-04570)\] | Placenta | 2019 | MRI Images | 64 (patients) | ML | KNN | Acc-0.981 |
| \[ [35](https://www.mdpi.com/1424-8220/22/12/4570#B35-sensors-22-04570)\] | Placenta | 2019 | Photographic Images | 1003 | DL | CNN (PlacentaNet) | Acc-0.9751 |
| \[ [23](https://www.mdpi.com/1424-8220/22/12/4570#B23-sensors-22-04570)\] | Placenta | 2017 | US Images (3D) | 104 (patients) | DL | FCNN, RNN | DSC-0.882 |
| \[ [28](https://www.mdpi.com/1424-8220/22/12/4570#B28-sensors-22-04570)\] | Placenta | 2019 | US Images (3D) | 127 | DL | CNN | DSC-0.8 |
| \[ [36](https://www.mdpi.com/1424-8220/22/12/4570#B36-sensors-22-04570)\] | Kidney | 2019 | US Images | 4074 | DL | CNN (AlexNet) | Acc-0.9705 |
| Poly | \[ [38](https://www.mdpi.com/1424-8220/22/12/4570#B38-sensors-22-04570)\] | Neuro | 2020 | MRI Images | 227 | DL | SVM + CNN (AlexNet, ResNet50) | Acc-0.886 |
| \[ [37](https://www.mdpi.com/1424-8220/22/12/4570#B37-sensors-22-04570)\] | Neuro | 2021 | US Images | 63 | DL | CNN | p < 0.05 |
| Both | \[ [42](https://www.mdpi.com/1424-8220/22/12/4570#B42-sensors-22-04570)\] | TTTS | 2019 | US Videos | 900 | DL | CNN | DSC-0.9191 |
| \[ [39](https://www.mdpi.com/1424-8220/22/12/4570#B39-sensors-22-04570)\] | TTTS | 2020 | Fetoscopic Videos | 138,780 | DL | CNN and LSTM | Precision-0.96 |
| \[ [40](https://www.mdpi.com/1424-8220/22/12/4570#B40-sensors-22-04570)\] | TTTS | 2020 | Fetoscopic Videos | 2400 | DL | CNN | - |
| \[ [41](https://www.mdpi.com/1424-8220/22/12/4570#B41-sensors-22-04570)\] | TTTS | 2020 | Fetoscopic Images | 30,000 | DL | CNN | Acc-0.87 |
| \[ [43](https://www.mdpi.com/1424-8220/22/12/4570#B43-sensors-22-04570)\] | Preterm | 2021 | Clinical Data | 219,272 (patients) | DL | DI-VNN | Sen-0.494<br>Spe-0.816 |
| \[ [44](https://www.mdpi.com/1424-8220/22/12/4570#B44-sensors-22-04570)\] | Preterm | 2019 | Clinical Data | 25,689 (patients) | DL | RNN | Sen-0.819<br>AUC-0.777 |
| \[ [45](https://www.mdpi.com/1424-8220/22/12/4570#B45-sensors-22-04570)\] | Health | 2021 | US Images | 3159 (patients) | ML | RF | MSE-0.02161 |
| \[ [46](https://www.mdpi.com/1424-8220/22/12/4570#B46-sensors-22-04570)\] | Health | 2019 | US Images | 7875 (patients) | ML | SVM, DBN | MAPE-0.0609 |
| \[ [47](https://www.mdpi.com/1424-8220/22/12/4570#B47-sensors-22-04570)\] | Health | 2021 | US Images | 1334 | DL | CNN (MFP-U-net) | DSC-0.98 |

**Table 4.**
Limitations and solutions of amniotic fluid studies.


**Table 4.**
Limitations and solutions of amniotic fluid studies.

| Ref. | Limitations | Solutions |
| :-: | :-: | :-: |
| \[ [18](https://www.mdpi.com/1424-8220/22/12/4570#B18-sensors-22-04570)\] | Limited features to differentiate between actual AF and reflected waves.<br>Insufficient uneven window shapes for relevant results. | Considering AF coordinates.<br>Adding data for uneven and rectangular window shapes. |
| \[ [12](https://www.mdpi.com/1424-8220/22/12/4570#B12-sensors-22-04570)\] | As there is no accurate measuring number for echogenicity, only doctor’s insight applied in observing the gray texture in US images. | - |
| \[ [11](https://www.mdpi.com/1424-8220/22/12/4570#B11-sensors-22-04570)\] | Fetal weight ignored for results. | Present findings considering fetal weight. |
| \[ [20](https://www.mdpi.com/1424-8220/22/12/4570#B20-sensors-22-04570)\] | Not entirely automated—Images manually labeled.<br>Advance dataset with all different forms of US images is required. | Automize labelling of US images. |
| \[ [13](https://www.mdpi.com/1424-8220/22/12/4570#B13-sensors-22-04570)\] | Uncertain aspects, such as angle and direction of the transducer, are ignored.<br>Decreased AF appearance in overweight women due to US beam. | Considering maternal position during Amniotic Fluid Volume (AFV) measurement. |
| \[ [5](https://www.mdpi.com/1424-8220/22/12/4570#B5-sensors-22-04570)\] | Errors in final finding due to secondary path in complementation procedure.<br>US Images with noise disturbance. | Distinction between both paths.<br>Unified image settings. |
| \[ [15](https://www.mdpi.com/1424-8220/22/12/4570#B15-sensors-22-04570)\] | Moderate accuracy.<br>Specific situation. | More broad case with additional clinical data and adequate labels. |
| \[ [16](https://www.mdpi.com/1424-8220/22/12/4570#B16-sensors-22-04570)\] | Average accuracy. | - |
| \[ [17](https://www.mdpi.com/1424-8220/22/12/4570#B17-sensors-22-04570)\] | Clinical data and US images exhibit moderate accuracy. | Omics data analysis to provide understanding to patients and help with clinical management. |
| \[ [10](https://www.mdpi.com/1424-8220/22/12/4570#B10-sensors-22-04570)\] | Various measurements scattered. | First trimester screening tool combining different measures and characteristics. |
| \[ [19](https://www.mdpi.com/1424-8220/22/12/4570#B19-sensors-22-04570)\] | Manual refinement of models. | Automate procedure. |

|     |     |
| --- | --- |
|  | **Publisher’s Note:** MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations. |

© 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ( [https://creativecommons.org/licenses/by/4.0/](https://creativecommons.org/licenses/by/4.0/)).

## Share and Cite

[Email](mailto:?&subject=From%20MDPI%3A%20%22Amniotic%20Fluid%20Classification%20and%20Artificial%20Intelligence%3A%20Challenges%20and%20Opportunities%22&body=https://www.mdpi.com/1682092%3A%0A%0AAmniotic%20Fluid%20Classification%20and%20Artificial%20Intelligence%3A%20Challenges%20and%20Opportunities%0A%0AAbstract%3A%20A%20fetal%20ultrasound%20%28US%29%20is%20a%20technique%20to%20examine%20a%20baby%26rsquo%3Bs%20maturity%20and%20development.%20US%20examinations%20have%20varying%20purposes%20throughout%20pregnancy.%20Consequently%2C%20in%20the%20second%20and%20third%20trimester%2C%20US%20tests%20are%20performed%20for%20the%20assessment%20of%20Amniotic%20Fluid%20Volume%20%28AFV%29%2C%20a%20key%20indicator%20of%20fetal%20health.%20Disorders%20resulting%20from%20abnormal%20AFV%20levels%2C%20commonly%20referred%20to%20as%20oligohydramnios%20or%20polyhydramnios%2C%20may%20pose%20a%20serious%20threat%20to%20a%20mother%26rsquo%3Bs%20or%20child%26rsquo%3Bs%20health.%20This%20paper%20attempts%20to%20accumulate%20and%20compare%20the%20most%20recent%20advancements%20in%20Artificial%20Intelligence%20%28AI%29-based%20techniques%20for%20the%20diagnosis%20and%20classification%20of%20AFV%20levels.%20Additionally%2C%20we%20provide%20a%20thorough%20and%20highly%20inclusive%20breakdown%20of%20other%20relevant%20factors%20that%20may%20cause%20abnormal%20AFV%20levels%2C%20including%2C%20but%20not%20limited%20to%2C%20abnormalities%20in%20the%20placenta%2C%20kidneys%2C%20or%20central%20nervous%20system%2C%20as%20well%20as%20other%20contributors%2C%20such%20as%20preterm%20birth%20or%20twin-to-twin%20transfusion%20syndrome.%20Furthermore%2C%20we%20bring%20forth%20a%20concise%20overview%20of%20all%20the%20Machine%20Learning%20%28ML%29%20and%20Deep%20Learning%20%28DL%29%20techniques%2C%20along%20with%20the%20datasets%20supplied%20by%20various%20researchers.%20This%20study%20also%20provides%20a%20brief%20rundown%20of%20the%20challenges%20and[...] "Email")[LinkedIn](http://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.mdpi.com%2F1682092&title=Amniotic%20Fluid%20Classification%20and%20Artificial%20Intelligence%3A%20Challenges%20and%20Opportunities%26source%3Dhttps%3A%2F%2Fwww.mdpi.com%26summary%3DA%20fetal%20ultrasound%20%28US%29%20is%20a%20technique%20to%20examine%20a%20baby%E2%80%99s%20maturity%20and%20development.%20US%20examinations%20have%20varying%20purposes%20throughout%20pregnancy.%20Consequently%2C%20in%20the%20second%20and%20third%20trimester%2C%20US%20tests%20are%20performed%20for%20the%20assessment%20of%20Amniotic%20%5B...%5D "LinkedIn")[facebook](http://www.facebook.com/sharer.php?u=https://www.mdpi.com/1682092 "facebook")[Wechat](javascript:void(0); "Wechat")[Reddit](http://www.reddit.com/submit?url=https://www.mdpi.com/1682092 "Reddit")[Mendeley](http://www.mendeley.com/import/?url=https://www.mdpi.com/1682092 "Mendeley")

**MDPI and ACS Style**

Khan, I.U.; Aslam, N.; Anis, F.M.; Mirza, S.; AlOwayed, A.; Aljuaid, R.M.; Bakr, R.M.
Amniotic Fluid Classification and Artificial Intelligence: Challenges and Opportunities. _Sensors_ **2022**, _22_, 4570.
https://doi.org/10.3390/s22124570

**AMA Style**

Khan IU, Aslam N, Anis FM, Mirza S, AlOwayed A, Aljuaid RM, Bakr RM.
Amniotic Fluid Classification and Artificial Intelligence: Challenges and Opportunities. _Sensors_. 2022; 22(12):4570.
https://doi.org/10.3390/s22124570


**Chicago/Turabian Style**

Khan, Irfan Ullah, Nida Aslam, Fatima M. Anis, Samiha Mirza, Alanoud AlOwayed, Reef M. Aljuaid, and Razan M. Bakr.
2022\. "Amniotic Fluid Classification and Artificial Intelligence: Challenges and Opportunities" _Sensors_ 22, no. 12: 4570.
https://doi.org/10.3390/s22124570


**APA Style**

Khan, I. U., Aslam, N., Anis, F. M., Mirza, S., AlOwayed, A., Aljuaid, R. M., & Bakr, R. M.

(2022). Amniotic Fluid Classification and Artificial Intelligence: Challenges and Opportunities. _Sensors_, _22_(12), 4570.
https://doi.org/10.3390/s22124570


Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details [here](https://www.mdpi.com/about/announcements/784).


## Article Metrics

No

No

### Article Access Statistics

For more information on the journal statistics, click [here](https://www.mdpi.com/journal/sensors/stats).



Multiple requests from the same IP address are counted as one view.


Zoom\| Orient \| As Lines \| As Sticks \| As Cartoon \| As Surface \|Previous Scene\|Next Scene

## Cite

Export citation file:
[BibTeX](javascript:window.document.forms['export-bibtex'].submit()) \|
[EndNote](javascript:window.document.forms['export-endnote'].submit()) \|
[RIS](javascript:window.document.forms['export-ris'].submit())

**MDPI and ACS Style**

Khan, I.U.; Aslam, N.; Anis, F.M.; Mirza, S.; AlOwayed, A.; Aljuaid, R.M.; Bakr, R.M.
Amniotic Fluid Classification and Artificial Intelligence: Challenges and Opportunities. _Sensors_ **2022**, _22_, 4570.
https://doi.org/10.3390/s22124570

**AMA Style**

Khan IU, Aslam N, Anis FM, Mirza S, AlOwayed A, Aljuaid RM, Bakr RM.
Amniotic Fluid Classification and Artificial Intelligence: Challenges and Opportunities. _Sensors_. 2022; 22(12):4570.
https://doi.org/10.3390/s22124570


**Chicago/Turabian Style**

Khan, Irfan Ullah, Nida Aslam, Fatima M. Anis, Samiha Mirza, Alanoud AlOwayed, Reef M. Aljuaid, and Razan M. Bakr.
2022\. "Amniotic Fluid Classification and Artificial Intelligence: Challenges and Opportunities" _Sensors_ 22, no. 12: 4570.
https://doi.org/10.3390/s22124570


**APA Style**

Khan, I. U., Aslam, N., Anis, F. M., Mirza, S., AlOwayed, A., Aljuaid, R. M., & Bakr, R. M.

(2022). Amniotic Fluid Classification and Artificial Intelligence: Challenges and Opportunities. _Sensors_, _22_(12), 4570.
https://doi.org/10.3390/s22124570


Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details [here](https://www.mdpi.com/about/announcements/784).


_clear_

We use cookies on our website to ensure you get the best experience.

Read more about our cookies [here](https://www.mdpi.com/about/privacy).


[Accept](https://www.mdpi.com/accept_cookies)

## Share Link

[Email](mailto:?&subject=From%20MDPI%3A%20%22Amniotic%20Fluid%20Classification%20and%20Artificial%20Intelligence%3A%20Challenges%20and%20Opportunities%22&body=https://www.mdpi.com/1682092%3A%0A%0AAmniotic%20Fluid%20Classification%20and%20Artificial%20Intelligence%3A%20Challenges%20and%20OpportunitiesA%20fetal%20ultrasound%20%28US%29%20is%20a%20technique%20to%20examine%20a%20baby%E2%80%99s%20maturity%20and%20development.%20US%20examinations%20have%20varying%20purposes%20throughout%20pregnancy.%20Consequently%2C%20in%20the%20second%20and%20third%20trimester%2C%20US%20tests%20are%20performed%20for%20the%20assessment%20of%20Amniotic%20Fluid%20Volume%20%28AFV%29%2C%20a%20key%20indicator%20of%20fetal%20health.%20Disorders%20resulting%20from%20abnormal%20AFV%20levels%2C%20commonly%20referred%20to%20as%20oligohydramnios%20or%20polyhydramnios%2C%20may%20pose%20a%20serious%20threat%20to%20a%20mother%E2%80%99s%20or%20child%E2%80%99s%20health.%20This%20paper%20attempts%20to%20accumulate%20and%20compare%20the%20most%20recent%20advancements%20in%20Artificial%20Intelligence%20%28AI%29-based%20techniques%20for%20the%20diagnosis%20and%20classification%20of%20AFV%20levels.%20Additionally%2C%20we%20provide%20a%20thorough%20and%20highly%20inclusive%20breakdown%20of%20other%20relevant%20factors%20that%20may%20cause%20abnormal%20AFV%20levels%2C%20including%2C%20but%20not%20limited%20to%2C%20abnormalities%20in%20the%20placenta%2C%20kidneys%2C%20or%20central%20nervous%20system%2C%20as%20well%20as%20other%20contributors%2C%20such%20as%20preterm%20birth%20or%20twin-to-twin%20transfusion%20syndrome.%20Furthermore%2C%20we%20bring%20forth%20a%20concise%20overview%20of%20all%20the%20Machine%20Learning%20%28ML%29%20and%20Deep%20Learning%20%28DL%29%20techniques%2C%20along%20with%20the%20datasets%20supplied%20by%20various%20researchers.%20This%20study%20also%20provides%20a%20brief%20rundown%20of%20the%20challenges%20and%20opportunities%20encountered[...] "Email")[Twitter](https://x.com/intent/tweet?text=Amniotic+Fluid+Classification+and+Artificial+Intelligence%3A+Challenges+and+Opportunities&hashtags=mdpisensors&url=https%3A%2F%2Fwww.mdpi.com%2F1682092&via=Sensors_MDPI "Twitter")[LinkedIn](http://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.mdpi.com%2F1682092&title=Amniotic%20Fluid%20Classification%20and%20Artificial%20Intelligence%3A%20Challenges%20and%20Opportunities%26source%3Dhttps%3A%2F%2Fwww.mdpi.com%26summary%3DA%20fetal%20ultrasound%20%28US%29%20is%20a%20technique%20to%20examine%20a%20baby%E2%80%99s%20maturity%20and%20development.%20US%20examinations%20have%20varying%20purposes%20throughout%20pregnancy.%20Consequently%2C%20in%20the%20second%20and%20third%20trimester%2C%20US%20tests%20are%20performed%20for%20the%20assessment%20of%20Amniotic%20%5B...%5D "LinkedIn")[facebook](http://www.facebook.com/sharer.php?u=https://www.mdpi.com/1682092 "facebook")[Wechat](javascript:void(0); "Wechat")[Reddit](http://www.reddit.com/submit?url=https://www.mdpi.com/1682092 "Reddit")[Mendeley](http://www.mendeley.com/import/?url=https://www.mdpi.com/1682092 "Mendeley")[CiteULike](http://www.citeulike.org/posturl?url=https://www.mdpi.com/1682092 "CiteULike")

Copy

_clear_

## Share

https://www.mdpi.com/1682092

_clear_

[Back to TopTop](https://www.mdpi.com/1424-8220/22/12/4570#)

---

## Content Analysis Summary

- **Total Sources Processed:** 3
- **Average Content Length:** 1,08,727 characters
- **Content Types Found:** Plain Text, Tables

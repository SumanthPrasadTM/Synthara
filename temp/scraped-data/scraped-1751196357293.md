# Web Scraping Results for: "get the latest dataset for the skin diseases and it cure with different forms"

**Generated on:** 2025-06-29T11:25:57.293Z
**Total Sources:** 4
**Total Content Length:** 1,48,635 characters

## Table of Contents

1. [skinive.com](#source-1)
2. [www.kaggle.com](#source-2)
3. [arxiv.org](#source-3)
4. [pmc.ncbi.nlm.nih.gov](#source-4)

---

## Source 1: skinive.com {#source-1}

**URL:** https://skinive.com/skin-disease-datasets/
**Content Type:** Web Content
**Content Length:** 15,059 characters
**Scraped At:** 2025-06-29T11:25:57.292Z

**Detected Structure:** Plain Text

### Content:

20th February 2025

## Review of 10 Skin Disease Datasets Available for Download

![Review of 10 Skin Disease Datasets Available for Download](https://skinive.com/wp-content/uploads/2025/02/1UHyqHeZJ98w1aUqZBbAL5w-604x339.webp)

- [All](https://skinive.com/home/blog/)
- [AI lab](https://skinive.com/category/tech/)
- [For MD's](https://skinive.com/category/for-doctors/)
- [News](https://skinive.com/category/news/)
- [Skincare tips](https://skinive.com/category/skincare-tips/)

## **Data is the Fuel for AI in Dermatology**

In the age of artificial intelligence, data serves as the crucial foundation for innovation. Just as fuel powers engines, datasets drive AI model training, determining their accuracy, reliability, and effectiveness. When developing AI-powered solutions for skin disease detection—whether **[AI Skin scanner](https://skinive.com/)** mobile apps, cloud-based platforms, or diagnostic software—the first and most essential step is **data collection and preparation**. Without high-quality, diverse, and well-labelled images of skin conditions, even the most advanced neural networks will fail to perform effectively in real-world applications.

This article provides a **comprehensive review of 10 publicly available skin disease datasets** that can serve as valuable resources for AI research. Whether you are a data scientist, healthcare AI developer, or entrepreneur in the digital health sector, this guide will help you navigate the landscape of dermatology datasets, understand their strengths and limitations, and make informed decisions for your AI model development.

For each dataset, we analyze:

- **The number of images and variety of skin conditions covered**
- **The source and labelling quality of the data**
- **The image types (clinical vs. dermoscopic) and resolution quality**
- **The dataset’s licensing terms and accessibility**
- **Key advantages and drawbacks**

Furthermore, we explore **why publicly available datasets often fall short of commercial AI solutions**, including issues like limited image diversity, class imbalances, and legal constraints. We also discuss the critical next steps in AI development—data preprocessing, model training, regulatory compliance, and deployment.

Finally, we introduce **Skinive.Cloud**, a cutting-edge [AI-powered skin analysis API](https://skinive.com/for-developers/) engine that provides an alternative to building an AI model from scratch. With access to a big proprietary dataset of millions of images, **CE-Mark certification**, and **seamless Whitelabel API integration**, Skinive.Cloud allows Skin Health & Beauty businesses to implement AI-driven skin analysis solutions **quickly, cost-effectively, and without regulatory roadblocks**.

![](https://skinive.com/wp-content/uploads/2025/02/Dermatology-API-small.jpg)

If you’re looking to develop a dermatology AI solution, this article is your starting point. Read on to discover the best datasets for your project and learn how to accelerate your AI development with industry-leading technology.

* * *

## **Top 10 Opensource Skin Disease Datasets**

### **1\. ISIC Archive**

- **URL:** [https://www.isic-archive.co](https://www.isic-archive.com/) [m](https://www.isic-archive.com/)
- **Number of Images:** 85,000+
- **Disease Categories:** Melanoma, [basal cell carcinoma](https://skinive.com/dermatlas/cancer/id3-basal-cell-carcinoma/), [squamous cell carcinoma](https://skinive.com/dermatlas/cancer/id9-squamous-cell-carcinoma/), and [benign skin lesions](https://skinive.com/dermatlas/benign-formations/)
- **Data Collection & Labeling:** Dermatologists and oncologists
- **Image Type & Quality:** High-resolution dermoscopic images
- **Usage Conditions:** Free for research use
- **Strengths:** Large dataset, expert annotations, widely used in AI research
- **Limitations:** Imbalanced classes (more benign lesions than malignant cases)

### **2\. HAM10000**

- **URL:** [htt](https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000) [ps://www.kaggle.com/kmader/skin-cancer-mnist-ham10000](https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000)
- **Number of Images:** 10,015
- **Disease Categories:** 7 skin conditions, including melanoma and [dermatofibroma](https://skinive.com/dermatlas/benign-formations/id7-dermatofibroma/)
- **Data Collection & Labeling:** Dermatologists
- **Image Type & Quality:** High-resolution dermoscopic images
- **Usage Conditions:** Open-source (Kaggle)
- **Strengths:** Well-labeled dataset with balanced classes
- **Limitations:** Limited number of images

### **3\. DermaMNIST**

- **URL:** [https://medmnist.co](https://medmnist.com/) [m](https://medmnist.com/)
- **Number of Images:** 10,015 (resized for AI training)
- **Disease Categories:** 7 skin conditions
- **Data Collection & Labeling:** Medical professionals
- **Image Type & Quality:** Lower-resolution dermoscopic images
- **Usage Conditions:** Open-access
- **Strengths:** Lightweight dataset ideal for quick experiments
- **Limitations:** Lower image resolution affects model accuracy

### **4\. SD-198**

- **URL:** [https://derm.cs.sfu.c](https://derm.cs.sfu.ca/) [a](https://derm.cs.sfu.ca/)
- **Number of Images:** 6,584
- **Disease Categories:** 198 skin conditions
- **Data Collection & Labeling:** Stanford University researchers
- **Image Type & Quality:** Clinical images (macro photos)
- **Usage Conditions:** Request-based access
- **Strengths:** Wide variety of conditions
- **Limitations:** Limited public access

### **5\. PAD-UFES-20**

- **URL:** [https://www.kaggle.com/datasets/mahdavi1202/skin-canc](https://www.kaggle.com/datasets/mahdavi1202/skin-cancer) [er](https://www.kaggle.com/datasets/mahdavi1202/skin-cancer)
- **Description**: A dataset from the Federal University of Espírito Santo with real-world clinical images.
- **Size**: 2,298 images.
- **Categories**: 8 disease types.
- **Annotations**: Metadata with demographic information.
- **Availability**: Publicly available.
- **Best for**: General dermatology AI applications.

### **6\. PH^2 Dataset**

- **URL:** [https://www.fc.up.pt/addi/ph2%20data](https://www.fc.up.pt/addi/ph2%20database.html) [base.html](https://www.fc.up.pt/addi/ph2%20database.html)
- **Description**: A dermoscopic dataset for melanoma analysis.
- **Size**: 200 images.
- **Categories**: Includes melanoma, atypical nevi, and [Benign Nevus](https://skinive.com/dermatlas/benign-formations/id23-benign-nevus/).
- **Annotations**: Pixel-level segmentation masks.
- **Availability**: Available upon request.
- **Best for**: Segmentation and melanoma classification research.

### **7\. Derm7pt Dataset**

- **URL:** [https://github.com/jeremykawahara/derm7p](https://github.com/jeremykawahara/derm7pt) [t](https://github.com/jeremykawahara/derm7pt)
- **Description**: Focuses on the seven-point melanoma checklist criteria.
- **Size**: 1,011 images.
- **Categories**: Melanoma and non-melanoma [skin cancer](https://skinive.com/dermatlas/cancer/).
- **Annotations**: Detailed feature annotations.
- **Availability**: Free for research use.
- **Best for**: Explainable AI and feature-based classification.

### **8\. Fitzpatrick 17K**

- **URL:** [https://github.com/mattgroh/fitzpatrick1](https://github.com/mattgroh/fitzpatrick17k) [7k](https://github.com/mattgroh/fitzpatrick17k)
- **Description**: A dataset addressing skin tone diversity in AI models.
- **Size**: 16,577 images.
- **Categories**: Covers a broad range of skin conditions.
- **Annotations**: Labeled with [Fitzpatrick skin types](https://skinive.com/what-are-the-fitzpatrick-skin-types/).
- **Availability**: Available via Google Dataset Search.
- **Best for**: Reducing AI bias in skin disease detection.

### **9\. BCN20000**

- **URL:** [https://paperswithcode.com/dataset/bcn-200](https://paperswithcode.com/dataset/bcn-20000) [00](https://paperswithcode.com/dataset/bcn-20000)
- **Description**: A dataset for skin cancer classification developed by the Barcelona Supercomputing Center.
- **Size**: 26,426 images.
- **Categories**: 8 types of skin lesions.
- **Annotations**: Diagnosed by dermatologists.
- **Availability**: Free for academic use.
- **Best for**: AI model training for [clinical dermatology](https://skinive.com/for-specialists/).

### **10\. SIIM-ISIC Melanoma Classification Dataset**

- **URL:** [https://www.kaggle.com/competitions/siim-isic-melanoma-classification](https://www.kaggle.com/competitions/siim-isic-melanoma-classification)
- **Description**: A Kaggle-hosted dataset designed for melanoma classification challenges.
- **Size**: 33,126 images.
- **Categories**: Melanoma vs. benign lesions.
- **Annotations**: Binary classification labels.
- **Availability**: Available on Kaggle.
- **Best for**: Benchmarking AI models in melanoma detection.

* * *

## ▶️ Video: How to Build a World-Class ML Model for Melanoma Detection

If you’re looking to apply AI techniques in dermatology, check out the YouTube video **“How to Build a World-Class ML Model for Skin Cancer Detection.”** It’s an excellent resource for learning about advanced machine learning strategies in skin disease diagnosis.

![](https://i.ytimg.com/vi/L1QKTPb6V_I/hqdefault.jpg)

* * *

## **The Next Steps in AI Development for Dermatology**

Even with a dataset, AI model training requires:

- **Preprocessing & Augmentation:** Cleaning and standardizing images.
- **Hiring Data Scientists:** Skilled professionals to build and fine-tune AI models.
- **Computational Resources:** High-performance GPUs and cloud computing for training deep learning models.
- **Continuous Experimentation:** Multiple iterations to achieve optimal accuracy.

Once the AI model is trained, the next step is to develop a mobile, web, or desktop application with skin analysis functionality. However, before launching the product, it must pass rigorous medical certification processes, including **CE-Mark, FDA, ISO 13485**, **HIPPA, GDPR**… ensuring compliance as a medical device.

![](https://skinive.com/wp-content/uploads/2025/02/unnamed-4.png)

The entire process, from dataset collection to certification, can take years and cost hundreds of thousands or even millions of dollars…

* * *

### **Why Free Datasets Are Often Insufficient for AI Training?**

While these publicly available datasets provide a solid foundation for research, they often fall short in real-world applications due to:

- **Data Imbalance:** Most datasets contain more benign lesions than malignant cases, affecting model training.
- **Low Image Quality:** Many datasets have varied resolutions, limiting AI accuracy.
- **Limited Diversity:** Public datasets often lack images across different age groups, ethnicities, and skin types.
- **Legal & Ethical Restrictions:** Using some datasets in commercial applications may require additional permissions.

For commercial applications, it is often necessary to collect and label data independently, ensuring high-quality, diverse, and legally compliant datasets.

* * *

## **A Faster and More Cost-Effective Solution: Skinive.Cloud**

**Skinive.Cloud** offers an [AI-powered skin analysis API](https://skinive.com/for-developers/) with significant advantages:

- **Built on a massive dataset (3+ million images) verified by dermatologists and oncologists.**
- **CE-Mark and GDPR-compliant (medical-grade software), ready for commercial use.**
- **Whitelabel solution:** Easily customizable for your brand.
- **Seamless API integration** into mobile, web, and desktop applications.
- **Continuously improving AI models** without additional development costs.
- **Cost-effective:** Avoid the high costs of developing your own AI solution.

[![](https://skinive.com/wp-content/uploads/2025/02/ai-skin-analysis-API.jpg)](https://skinive.com/for-developers/)

### **Beyond Technology: Expert Support for Your Business**

At Skinive, we provide not just technical support but also business consultation to help you achieve your goals. We have extensive experience in integrating AI-powered skin analysis into various industries, including:

- **Health & Beauty Apps** (like [AI Skin Scanner app](https://skinive.com/for-patients/))
- **Telemedicine Platforms (EMR/EHR Systems)**
- **E-commerce for Skincare Products**
- **Insurance Companies**
- **Hospitals & Diagnostic Labs**
- **Beauty Clinics & SPAs**

* * *

## **Start Your AI-Powered Skin Analysis Journey Today**

Instead of spending years on research, development, and certification, you can integrate Skinive.Cloud today and bring an AI-driven skin analysis solution to market faster and more affordably.

🔗 **Learn more at** [**Skinive.Cloud**](https://skinive.com/for-developers/)

📞 **[Schedule a call](https://calendly.com/vera-pu6s/30min) with our sales team today!**

## Recommended articles preview:

[![blog-image](https://skinive.com/wp-content/uploads/2024/08/portrait-abstract-overstimulated-feelings-scaled.jpg)\\
\\
How to Prevent Wrinkles and Fine Lines: Your Guide to Youthful Skin\\
\\
04.08.2024\\
\\
Read more](https://skinive.com/wrinkles/) [![blog-image](https://skinive.com/wp-content/uploads/2022/06/mycosis.jpg)\\
\\
Getting rid of mycosis: diagnosis and treatment of fungal diseases\\
\\
02.06.2022\\
\\
Read more](https://skinive.com/mycosis-fungus/) [![blog-image](https://skinive.com/wp-content/uploads/2018/12/ML.jpg)\\
\\
How Machine Learning (AI) Technology Detects Skin Diseases?\\
\\
10.12.2018\\
\\
Read more](https://skinive.com/how-machine-learning-technology-detects-skin-diseases/) [![blog-image](https://skinive.com/wp-content/uploads/2021/04/dermatologist-appointment.jpg)\\
\\
Addressing Dermatologists Shortage & Easing Appointment Wait\\
\\
22.04.2021\\
\\
Read more](https://skinive.com/dermatologist-appointment/) [![blog-image](https://skinive.com/wp-content/uploads/2018/12/skin-type.jpg)\\
\\
What Are the Fitzpatrick Skin Types?\\
\\
10.12.2018\\
\\
Read more](https://skinive.com/what-are-the-fitzpatrick-skin-types/) [![blog-image](https://skinive.com/wp-content/uploads/2018/12/skin-types2.jpg)\\
\\
Identify your skin type online!\\
\\
10.12.2018\\
\\
Read more](https://skinive.com/iidentify-your-skin-type-online/) [![blog-image](https://skinive.com/wp-content/uploads/2024/05/young-woman-being-confident-with-her-acne.jpg)\\
\\
Understanding Adult Acne: Causes and Solutions\\
\\
02.05.2024\\
\\
Read more](https://skinive.com/adult-acne/) [![blog-image](https://skinive.com/wp-content/uploads/2018/12/maxresdefault.jpg)\\
\\
How to get clear skin fast: three trusted home remedies\\
\\
10.12.2018\\
\\
Read more](https://skinive.com/how-to-get-clear-skin-fast-three-trusted-home-remedieshow-to-get-clear-skin-fast-three-trusted-home-remedies/) [![blog-image](https://skinive.com/wp-content/uploads/2024/12/close-up-skin-pores-face-care-routine-Medium.jpeg)\\
\\
Acne Scars: How to Get Rid of them?\\
\\
20.12.2024\\
\\
Read more](https://skinive.com/acne-scars/)

Get Skin Scanner app

[Download](https://apps.apple.com/gb/app/skinive-skincare-ai-scanner/id1633219654)[Download](https://play.google.com/store/apps/details?id=com.skinive.App)

---

## Source 2: www.kaggle.com {#source-2}

**URL:** https://www.kaggle.com/datasets/shubhamgoel27/dermnet
**Content Type:** Web Content
**Content Length:** 16,876 characters
**Scraped At:** 2025-06-29T11:25:57.292Z

**Detected Structure:** Tables

### Content:

menu

[Skip to\\
\\
content](https://www.kaggle.com/datasets/shubhamgoel27/dermnet#site-content)

[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)

Create

search​

- [explore\\
\\
Home](https://www.kaggle.com/)

- [emoji\_events\\
\\
Competitions](https://www.kaggle.com/competitions)

- [table\_chart\\
\\
Datasets](https://www.kaggle.com/datasets)

- [tenancy\\
\\
Models](https://www.kaggle.com/models)

- [code\\
\\
Code](https://www.kaggle.com/code)

- [comment\\
\\
Discussions](https://www.kaggle.com/discussions)

- [school\\
\\
Learn](https://www.kaggle.com/learn)


- [expand\_more\\
\\
More](https://www.kaggle.com/datasets/shubhamgoel27/dermnet#)


auto\_awesome\_motion

View Active Events

menu

[Skip to\\
\\
content](https://www.kaggle.com/datasets/shubhamgoel27/dermnet#site-content)

[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)

search​

[Sign In](https://www.kaggle.com/account/login?phase=startSignInTab&returnUrl=%2Fdatasets%2Fshubhamgoel27%2Fdermnet)

[Register](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2Fdatasets%2Fshubhamgoel27%2Fdermnet)

Shubham Goel and 1 collaborator · Updated 5 years ago

arrow\_drop\_up248

codeCode

file\_downloadDownload

![](https://www.kaggle.com/static/images/medals/datasets/silverl@2x.png)

more\_vert

# Dermnet

Image data for 23 categories of skin diseases

![](https://storage.googleapis.com/kaggle-datasets-images/735911/1276317/ca6c3f48c7155c0babddc4802c43446c/dataset-cover.jpg?t=2020-08-20-13-00-49)

## Dermnet

[Data Card](https://www.kaggle.com/datasets/shubhamgoel27/dermnet/data) [Code (107)](https://www.kaggle.com/datasets/shubhamgoel27/dermnet/code) [Discussion (4)](https://www.kaggle.com/datasets/shubhamgoel27/dermnet/discussion) [Suggestions (0)](https://www.kaggle.com/datasets/shubhamgoel27/dermnet/suggestions)

## About Dataset

### Context

The data consists of images of 23 types of skin diseases taken from [http://www.dermnet.com/dermatology-pictures-skin-disease-pictures](http://www.dermnet.com/dermatology-pictures-skin-disease-pictures). The total number of images are around 19,500, out of which approximately 15,500 have been split in the training set and the remaining in the test set.

### Content

The images are in JPEG format, consisting of 3 channels, i.e. RGB. The resolutions vary from image to image, and from category to category, but overall these are not extremely high resolution imagery.

The categories include acne, melanoma, Eczema, Seborrheic Keratoses, Tinea Ringworm, Bullous disease, Poison Ivy, Psoriasis, Vascular Tumors, etc.

### Acknowledgements

The images are taken from the public portal Dermnet ( [http://www.dermnet.com/](http://www.dermnet.com/)) which is the largest dermatology source online built for the purpose of providing online medical education.

### Inspiration

There are several use cases of the dataset

1. Build a robust image classifier to categorize any image in one of the 23 mentioned categories.
2. EDA over categories to understand visual differences and make generic inferences
3. Clustering images from multiple diseases in a bigger umbrella category.
4. And many others…

expand\_moreView more

## Usability

info

8.75

## License

[Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)](https://creativecommons.org/licenses/by-nc-nd/4.0/)

## Expected update frequency

Annually

## Tags

[Image](https://www.kaggle.com/datasets?tags=14102-Image) [Deep Learning](https://www.kaggle.com/datasets?tags=13310-Deep+Learning) [Hospitals and Treatment Centers](https://www.kaggle.com/datasets?tags=16532-Hospitals+and+Treatment+Centers)

## test(23 directories)

get\_app

fullscreen

chevron\_right

About this directory

All diseases are categorized in different folders here

folder

Acne and Rosacea Photos

312 files

folder

Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions

288 files

folder

Atopic Dermatitis Photos

123 files

folder

Bullous Disease Photos

113 files

folder

Cellulitis Impetigo and other Bacterial Infections

73 files

folder

Eczema Photos

309 files

folder

Exanthems and Drug Eruptions

101 files

folder

Hair Loss Photos Alopecia and other Hair Diseases

60 files

folder

Herpes HPV and other STDs Photos

102 files

folder

Light Diseases and Disorders of Pigmentation

143 files

folder

Lupus and other Connective Tissue diseases

105 files

folder

Melanoma Skin Cancer Nevi and Moles

116 files

folder

Nail Fungus and other Nail Disease

261 files

folder

Poison Ivy Photos and other Contact Dermatitis

65 files

folder

Psoriasis pictures Lichen Planus and related diseases

352 files

folder

Scabies Lyme Disease and other Infestations and Bites

108 files

folder

Seborrheic Keratoses and other Benign Tumors

343 files

folder

Systemic Disease

152 files

folder

Tinea Ringworm Candidiasis and other Fungal Infections

325 files

folder

Urticaria Hives

53 files

folder

Vascular Tumors

121 files

folder

Vasculitis Photos

105 files

folder

Warts Molluscum and other Viral Infections

272 files

## Data Explorer

Version 1 (1.85 GB)

- arrow\_drop\_down



folder






test






  - arrow\_right



    folder






    Acne and Rosacea Photos

  - arrow\_right



    folder






    Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions

  - arrow\_right



    folder






    Atopic Dermatitis Photos

  - arrow\_right



    folder






    Bullous Disease Photos

  - arrow\_right



    folder






    Cellulitis Impetigo and other Bacterial Infections

  - arrow\_right



    folder






    Eczema Photos

  - arrow\_right



    folder






    Exanthems and Drug Eruptions

  - arrow\_right



    folder






    Hair Loss Photos Alopecia and other Hair Diseases

  - arrow\_right



    folder






    Herpes HPV and other STDs Photos

  - arrow\_right



    folder






    Light Diseases and Disorders of Pigmentation

  - arrow\_right



    folder






    Lupus and other Connective Tissue diseases

  - arrow\_right



    folder






    Melanoma Skin Cancer Nevi and Moles

  - arrow\_right



    folder






    Nail Fungus and other Nail Disease

  - arrow\_right



    folder






    Poison Ivy Photos and other Contact Dermatitis

  - arrow\_right



    folder






    Psoriasis pictures Lichen Planus and related diseases

  - arrow\_right



    folder






    Scabies Lyme Disease and other Infestations and Bites

  - arrow\_right



    folder






    Seborrheic Keratoses and other Benign Tumors

  - arrow\_right



    folder






    Systemic Disease

  - arrow\_right



    folder






    Tinea Ringworm Candidiasis and other Fungal Infections

  - arrow\_right



    folder






    Urticaria Hives

  - arrow\_right



    folder






    Vascular Tumors

  - arrow\_right



    folder






    Vasculitis Photos

  - arrow\_right



    folder






    Warts Molluscum and other Viral Infections
- arrow\_right



folder






train


## Summary

arrow\_right

folder

19.6k files

lightbulb

## See what others are saying about this dataset

### What have you used this dataset for?

Learning 17Research 32Application 0LLM Fine-Tuning 1

### How would you describe this dataset?

Well-documented 11Well-maintained 2Clean data 14Original 6High-quality notebooks 6Other

text\_snippet

## Metadata

unfold\_moreExpand All

### Collaborators

keyboard\_arrow\_down

### Authors

keyboard\_arrow\_down

### Coverage

keyboard\_arrow\_down

### DOI Citation

keyboard\_arrow\_down

### Provenance

keyboard\_arrow\_down

### License

keyboard\_arrow\_down

### Expected Update Frequency

keyboard\_arrow\_down

insights

## Activity Overview

visibility

### Views

183K

| date | Views |
| --- | --- |
| May 30, 2025 | 82 |
| May 31, 2025 | 69 |
| Jun 1, 2025 | 88 |
| Jun 2, 2025 | 119 |
| Jun 3, 2025 | 150 |
| Jun 4, 2025 | 130 |
| Jun 5, 2025 | 65 |
| Jun 6, 2025 | 86 |
| Jun 7, 2025 | 73 |
| Jun 8, 2025 | 124 |
| Jun 9, 2025 | 90 |
| Jun 10, 2025 | 82 |
| Jun 11, 2025 | 89 |
| Jun 12, 2025 | 86 |
| Jun 13, 2025 | 79 |
| Jun 14, 2025 | 99 |
| Jun 15, 2025 | 95 |
| Jun 16, 2025 | 115 |
| Jun 17, 2025 | 89 |
| Jun 18, 2025 | 117 |
| Jun 19, 2025 | 95 |
| Jun 20, 2025 | 146 |
| Jun 21, 2025 | 113 |
| Jun 22, 2025 | 96 |
| Jun 23, 2025 | 114 |
| Jun 24, 2025 | 98 |
| Jun 25, 2025 | 132 |
| Jun 26, 2025 | 68 |
| Jun 27, 2025 | 89 |

trending\_up2878in the last 30 days

download

### Downloads

27.1K

| date | Downloads |
| --- | --- |
| May 30, 2025 | 16 |
| May 31, 2025 | 23 |
| Jun 1, 2025 | 37 |
| Jun 2, 2025 | 17 |
| Jun 3, 2025 | 42 |
| Jun 4, 2025 | 30 |
| Jun 5, 2025 | 33 |
| Jun 6, 2025 | 25 |
| Jun 7, 2025 | 21 |
| Jun 8, 2025 | 32 |
| Jun 9, 2025 | 13 |
| Jun 10, 2025 | 12 |
| Jun 11, 2025 | 41 |
| Jun 12, 2025 | 23 |
| Jun 13, 2025 | 19 |
| Jun 14, 2025 | 28 |
| Jun 15, 2025 | 43 |
| Jun 16, 2025 | 47 |
| Jun 17, 2025 | 24 |
| Jun 18, 2025 | 23 |
| Jun 19, 2025 | 22 |
| Jun 20, 2025 | 47 |
| Jun 21, 2025 | 13 |
| Jun 22, 2025 | 32 |
| Jun 23, 2025 | 38 |
| Jun 24, 2025 | 22 |
| Jun 25, 2025 | 18 |
| Jun 26, 2025 | 15 |
| Jun 27, 2025 | 36 |

trending\_up792in the last 30 days

downloading

### Engagement

0.14797

downloads per view

forum

### Comments

13

posted

person

### Top Contributors

[Khaled Elbahnasy's profile](https://www.kaggle.com/khaledelbhnasy)[Akshit Gupta's profile](https://www.kaggle.com/akshitgupta146)[Mediano Sandie's profile](https://www.kaggle.com/medianosandie)

### Detail View

keyboard\_arrow\_up

#### Views

Last month

06/0206/0906/1606/23050100150

| date | Views |
| --- | --- |
| May 30, 2025 | 82 |
| May 31, 2025 | 69 |
| Jun 1, 2025 | 88 |
| Jun 2, 2025 | 119 |
| Jun 3, 2025 | 150 |
| Jun 4, 2025 | 130 |
| Jun 5, 2025 | 65 |
| Jun 6, 2025 | 86 |
| Jun 7, 2025 | 73 |
| Jun 8, 2025 | 124 |
| Jun 9, 2025 | 90 |
| Jun 10, 2025 | 82 |
| Jun 11, 2025 | 89 |
| Jun 12, 2025 | 86 |
| Jun 13, 2025 | 79 |
| Jun 14, 2025 | 99 |
| Jun 15, 2025 | 95 |
| Jun 16, 2025 | 115 |
| Jun 17, 2025 | 89 |
| Jun 18, 2025 | 117 |
| Jun 19, 2025 | 95 |
| Jun 20, 2025 | 146 |
| Jun 21, 2025 | 113 |
| Jun 22, 2025 | 96 |
| Jun 23, 2025 | 114 |
| Jun 24, 2025 | 98 |
| Jun 25, 2025 | 132 |
| Jun 26, 2025 | 68 |
| Jun 27, 2025 | 89 |

...

#### Downloads

Last month

06/0206/0906/1606/230204060

| date | Downloads |
| --- | --- |
| May 30, 2025 | 16 |
| May 31, 2025 | 23 |
| Jun 1, 2025 | 37 |
| Jun 2, 2025 | 17 |
| Jun 3, 2025 | 42 |
| Jun 4, 2025 | 30 |
| Jun 5, 2025 | 33 |
| Jun 6, 2025 | 25 |
| Jun 7, 2025 | 21 |
| Jun 8, 2025 | 32 |
| Jun 9, 2025 | 13 |
| Jun 10, 2025 | 12 |
| Jun 11, 2025 | 41 |
| Jun 12, 2025 | 23 |
| Jun 13, 2025 | 19 |
| Jun 14, 2025 | 28 |
| Jun 15, 2025 | 43 |
| Jun 16, 2025 | 47 |
| Jun 17, 2025 | 24 |
| Jun 18, 2025 | 23 |
| Jun 19, 2025 | 22 |
| Jun 20, 2025 | 47 |
| Jun 21, 2025 | 13 |
| Jun 22, 2025 | 32 |
| Jun 23, 2025 | 38 |
| Jun 24, 2025 | 22 |
| Jun 25, 2025 | 18 |
| Jun 26, 2025 | 15 |
| Jun 27, 2025 | 36 |

60

code

## Related Notebooks

See all

[![](https://www.kaggleusercontent.com/kf/139909686/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..qWPCRe-muCzNaxiqLeeJPg.L-Sft1bVG37Z3n5o5_rVeP0Oh6oPFb8HLvH0y3n2A6D4bt_DQBWGD6LeHKBa-uf8Ms3aMoiPfE9swM3Wzq7cP9aWzzzlRMp_EbPAb1sP9mzyEqYwRIHGq71nTkOtwsRhm9vPjDz0_82yvmY4b4IvFwnwZSCLwcosAOanogCf1sik9pnn34Cyl19ydwH5qqWziNbXWJu1TksklQHZfX2tzYNKafKap6ohknakNtvXdKwk2cmj_2znzABvgurxVEBlJCUUbOrmSHCcjbcz5gVLBf51doMm4-YpO4h84zQJCB9J7jONKeP3FtKmBtJKIxHhtBBII5tSG9wGd354vfpuxX11zNYoRg5Vuun4oRUZLBf2sbvvZVW6BF6moRniODdQ9a9uK759sX_dal7v14K8JAj3RbJKo3L0kLXOaHIuzhKktcudPtkS3iGbc5qmhHtJbIlb3gUjIXPU_jnjdsEPog2MQl3wZpARQubB9DF95MdRBeSMzmy-VWJOM_mZoZUQnF6jHT3Y40oiO5d1fWw_6PcbNCCVsLAKN1AIBPTAL65LUGcv2HqFHA8Xi3tBmmFoK7NZT3gUPXn0BMJpWONkYlbd899c-1r27okImvq7Qti9I8jCkwntu1p-ndVdpAZuHQsV0nGcfZd1M9GhmynCMA.Y_g89x-47RktaMuTYvisHQ/__results___files/__results___11_0.png)\\
\\
skin detection acc=98%\\
\\
more\_vert\\
\\
Updated 2 years ago\\
\\
Dermnet+1](https://www.kaggle.com/code/khaledelbhnasy/skin-detection-acc-98)

arrow\_drop\_up43

![bronze medal](https://www.kaggle.com/static/images/medals/notebooks/bronzes@2x.png)[Khaled Elbahnasy's profile (opens in a new tab)](https://www.kaggle.com/khaledelbhnasy)

[![](https://www.kaggleusercontent.com/kf/183404904/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..IY_iCgjLmfwkdo9emkl38w.stKb2uZmerARwiqDIj9DCWrrIIaZjXAt5gQWiLHVriVOb_1Z58AnuARkKmFzJwTESSu5GXiYkI0tqdrC7vi9RxXFERLT9PSw7WyyRJCjw90UMYEiRQ1CnrHbqqgUilevH8XWgZ_rgnpLHt-5ZY4izj-USBq71aZ0avo1COUpDsFijEEctseVDF4ID18H39GIRgQyo2BnLGHGny2bzX-f5RaPMFy9Fh5xl7MDN1SvQiqb_HPhcIGozpFXvh2o37NaEL57_Tg4cxnUPeObR-AxDgyh85OU6qnAPZNuly1pSYNXw8whR_7ni6C-7IBKDe8e7yGzlL36qr27jCqwOromSMERHKRvaB5EtqdF2i_ECGECi3mdpKY_EDqCRfuDQVX2qnOE1S0Vv8byWS-RPDquNC7rzxwfLWlMYwX2N_kkV0pKFAtG1MLZxeM59cEzqhrn7q9n5XisjJQm5cV59AYNFAtX3zgih14q_DIFPQmnoZWtxS7ETG6FPUpmaI_Ub3Abw7PU947Q2FFLc-xMGgYp5Kj_B5FzQD9AgkmAyRYlSbVIJXR4r_qImAViC8sLJ88e8jJMyeeLdMfaoAytatdlHG4Kr1n2fiFSy9LJAyb1KIaFVMtqTAlh1rR8Rzlv6xsTiJmGlHfzSTmzLkDfK0LnWw.SdoCU-1Eu68uylwHGO-DUQ/__results___files/__results___11_0.png)\\
\\
⚕️Dermnet Skin Disease Dataset \| EDA\\
\\
more\_vert\\
\\
Updated a year ago\\
\\
Dermnet](https://www.kaggle.com/code/akshitgupta146/dermnet-skin-disease-dataset-eda)

arrow\_drop\_up35

![silver medal](https://www.kaggle.com/static/images/medals/notebooks/silvers@2x.png)[Akshit Gupta's profile (opens in a new tab)](https://www.kaggle.com/akshitgupta146)

[![](https://www.kaggleusercontent.com/kf/96990114/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..W-vJy1E0GneDmI1Oh8fdmg.HBcW2qVxD8wazRymoOLkMFBp9K58Zxf0EG2neLmP_l4ib2fDWhNRNYzLQhyL1J6IE2BiG66kaba_LeYAhXvh3MnvTT-STS-sBI4gi7THb4YbI4E-4NlRhpDrIBVyejnXaKXdHnp_T3_ZcPN7UiYFEbRDKIadu7zm8Yu6WsVG0sxnJ1KifzphdTd-3EoIhNjIU_zf_qkzzZyE7BkQ2uuhuufvQuH17R9lMFVY9m1NDRAwJQYrG7dsO6uhE4GM0r2NFOkKuEsIEuTM9Qjb_DjUCKF7CnVDaIf6jttUjxariMPg5JIhg4QIToCWrD28IYgCv_g17TaDx3vx4jSllGg917YrcpIO5BCY6KWt4No_m0PUstaAhLQP_HMxpbc-C_xQQ_gybYm8ffWcQqgYvdpF3__Y_eNlWb1J82wKZm4SaIhTBrCtHf5jt-9I26dssXr1d6ntHRqes73ktZyDiPgMJ6U3zZ7EHoxXqIlDK9oThzvAsfLXFcFJXjgOBV419vrEeCGWSyflXhUkE78Aldl4INX2aRbtdHJwXGS6vFYbYFO9fURzNRp_HE7Pk8tSL3cuXJWo4xBWm-Ad-KQ94MiolId5lYc6_fqnrf8XYYmUKJnd83fi0zlmLvzGX0BJCFCvnJxweOTec2biPIJGKw2bAQ.eFKR00_4IQBpxWYmcvDXBQ/__results___files/__results___14_0.png)\\
\\
Skin Diseases Classification\\
\\
more\_vert\\
\\
Updated 3 years ago\\
\\
Dermnet](https://www.kaggle.com/code/medianosandie/skin-diseases-classification)

arrow\_drop\_up20

[Mediano Sandie's profile (opens in a new tab)](https://www.kaggle.com/medianosandie)

table\_chart

## Similar Datasets

[![](https://storage.googleapis.com/kaggle-datasets-images/new-version-temp-images/default-backgrounds-85.png-21279043/dataset-thumbnail.png)](https://www.kaggle.com/datasets/aealemran/skin-disease-dataset-22-class)

[Skin Disease Dataset 22 class\\
\\
more\_vert](https://www.kaggle.com/datasets/aealemran/skin-disease-dataset-22-class)

[ae al emran](https://www.kaggle.com/aealemran) · Updated 3 months ago

Usability 3.1 · 1 GB

15445 Files (other)

arrow\_drop\_up0

[ae al emran's profile (opens in a new tab)](https://www.kaggle.com/aealemran)

[![](https://storage.googleapis.com/kaggle-datasets-images/7460999/11872226/acafcf716133a480a1ba13ef84ef0d42/dataset-thumbnail.jpg?t=2025-05-20-08-52-05)](https://www.kaggle.com/datasets/mgmitesh/skin-disease-detection-dataset)

[Skin Disease Detection Dataset\\
\\
more\_vert](https://www.kaggle.com/datasets/mgmitesh/skin-disease-detection-dataset)

[Mitesh](https://www.kaggle.com/mgmitesh) · Updated a month ago

Usability 6.9 · 3 GB

48233 Files (other)

arrow\_drop\_up3

[Mitesh's profile (opens in a new tab)](https://www.kaggle.com/mgmitesh)

[![](https://storage.googleapis.com/kaggle-datasets-images/new-version-temp-images/default-backgrounds-92.png-10645185/dataset-thumbnail.png)](https://www.kaggle.com/datasets/chetantirumala/skin-diseases-dermnet)

[Skin Diseases Dermnet\\
\\
more\_vert](https://www.kaggle.com/datasets/chetantirumala/skin-diseases-dermnet)

[Chetan Tirumala](https://www.kaggle.com/chetantirumala) · Updated a year ago

Usability 6.9 · 518 MB

5543 Files (other)

arrow\_drop\_up3

[Chetan Tirumala's profile (opens in a new tab)](https://www.kaggle.com/chetantirumala)

[![](https://storage.googleapis.com/kaggle-datasets-images/4856196/8198031/d8e3ca25300f943e65480e767b289cd9/dataset-thumbnail.jpg?t=2024-04-24-15-34-07)](https://www.kaggle.com/datasets/haonanchn2323/skinrash)

[Comprehensive Skin Rash Image Dataset\\
\\
more\_vert](https://www.kaggle.com/datasets/haonanchn2323/skinrash)

[Haonan CHN2323](https://www.kaggle.com/haonanchn2323) · Updated a year ago

Usability 7.5 · 36 MB

172 Files (other)

arrow\_drop\_up3

[Haonan CHN2323's profile (opens in a new tab)](https://www.kaggle.com/haonanchn2323)

---

## Source 3: arxiv.org {#source-3}

**URL:** https://arxiv.org/html/2405.18004v1
**Content Type:** Web Content
**Content Length:** 35,534 characters
**Scraped At:** 2025-06-29T11:25:57.292Z

**Detected Structure:** Tables

### Content:

HTML conversions [sometimes display errors](https://info.dev.arxiv.org/about/accessibility_html_error_messages.html) due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.

- failed: floatrow

Authors: achieve the best HTML results from your LaTeX submissions by following these [best practices](https://info.arxiv.org/help/submit_latex_best_practices.html).

[License: CC BY-NC-ND 4.0](https://info.arxiv.org/help/license/index.html#licenses-available)

arXiv:2405.18004v1 \[cs.CV\] 28 May 2024

\\floatsetup

\[table\]capposition=top

Report issue for preceding element

# SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions

Report issue for preceding element

Juexiao Zhou1,2,3,†, Liyuan Sun5,†, Yan Xu6,†, Wenbin Liu7,†, Shawn Afvari3,8,†, Zhongyi Han1,2, Jiaoyan Song9, Yongzhi Ji10,∗, Xiaonan He4,∗, Xin Gao1,2,∗1Computer Science Program, Computer, Electrical and Mathematical Sciences and Engineering Division, King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Kingdom of Saudi Arabia

2Computational Bioscience Research Center, King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Kingdom of Saudi Arabia

3DermAssure, LLC, New York, NY, USA.

4Emergency Critical Care Center, Beijing AnZhen Hospital, Affiliated to Capital Medical University, Beijing 100029, China

5Department of Dermatology, Beijing AnZhen Hospital, Affiliated to Capital Medical University, Beijing 100029, China

6Department of Dermatology, Tianjin lnstitute of lntegrative Dermatology,Tianjin Academy of Traditional Chinese Medicine Affiliated Hospital, China

7Department of Dermatology, Beijing Aerospace General Hospital, China

8School of Medicine, New York Medical College, Valhalla, NY, USA.

9Capital Medical University, Beijing 100029, China

10Department of Dermatology, Second Hospital of Jilin University, 218 Ziqiang Street, Changchun 130041, China.

†These authors contributed equally.

∗Corresponding author. e-mail: xin.gao@kaust.edu.sa

Report issue for preceding element

###### Abstract

Report issue for preceding element

With the widespread application of artificial intelligence (AI), particularly deep learning (DL) and vision-based large language models (VLLMs), in skin disease diagnosis, the need for interpretability becomes crucial. However, existing dermatology datasets are limited in their inclusion of concept-level meta-labels, and none offer rich medical descriptions in natural language. This deficiency impedes the advancement of LLM-based methods in dermatological diagnosis. To address this gap and provide a meticulously annotated dermatology dataset with comprehensive natural language descriptions, we introduce SkinCAP: a multi-modal dermatology dataset annotated with rich medical captions. SkinCAP comprises 4,000 images sourced from the Fitzpatrick 17k skin disease dataset and the Diverse Dermatology Images dataset, annotated by board-certified dermatologists to provide extensive medical descriptions and captions. Notably, SkinCAP represents the world’s first such dataset and is publicly available at [https://huggingface.co/datasets/joshuachou/SkinCAP](https://huggingface.co/datasets/joshuachou/SkinCAP "").

Report issue for preceding element

###### Index Terms:

Report issue for preceding element
Dermatology, Multi-modal dataset, Large language model

## 1 Background & Summary

Report issue for preceding element

Skin diseases rank as the fourth most prevalent among all human ailments and represent a significant global health burden\[ [1](https://arxiv.org/html/2405.18004v1#bib.bib1 "")\], impacting approximately one-third of the world’s population\[ [2](https://arxiv.org/html/2405.18004v1#bib.bib2 ""), [3](https://arxiv.org/html/2405.18004v1#bib.bib3 "")\]. In recent years, artificial intelligence (AI), particularly deep learning (DL) and vision-based large language models (VLLMs), have been widely applied in the realm of skin disease diagnosis. These technologies are increasingly utilized for tasks such as skin disease classification and skin lesion segmentation\[ [4](https://arxiv.org/html/2405.18004v1#bib.bib4 ""), [5](https://arxiv.org/html/2405.18004v1#bib.bib5 ""), [6](https://arxiv.org/html/2405.18004v1#bib.bib6 "")\].

Report issue for preceding element

However, in the track of skin disease classification, the majority of research efforts have primarily focused on categorizing skin disease types based solely on visual cues from images, while far little attention has been given to the medical features and clinical description of those skin diseases. This oversight significantly hampers the interpretability of developed methods in skin disease diagnosis. SkinGPT-4\[ [5](https://arxiv.org/html/2405.18004v1#bib.bib5 "")\] is the sole dermatological assessment method trained on a large-scale multi-modal dataset with VLLMs. This unique capability enables SkinGPT-4 to not only provide descriptions of skin disease images but also facilitate natural language interaction with users. However, the unavailability of SkinGPT-4’s proprietary in-house data due to privacy concerns impedes progress in open-source research endeavors in this direction.

Report issue for preceding element

![Refer to caption](https://arxiv.org/html/x1.png)Figure 1: Summary of SkinCAP. a) Illustration of the construction of the SkinCAP dataset, involving five board-certified dermatologists in annotation. b) Distribution of samples for each type of skin disease in SkinCAP with sample size ≥\\geq≥ 20\. c) Five randomly selected examples from the SkinCAP dataset. d) Distribution of samples across the Fitzpatrick Scale in SkinCAP. e) Illustration of the response of SkinGPT-4 fine-tuned with SkinCAP on a case of acne.Report issue for preceding elementTABLE I: Comparison of SkinCAP with existing dermatology datasets.

|     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- |
| Dataset | No. of Samples | Class label? | Medical feature? | Caption? | Available? |
| PH2\[ [7](https://arxiv.org/html/2405.18004v1#bib.bib7 "")\] | 200 | ✓ | ✓(limited) | - | ✓ |
| Dermofit\[ [8](https://arxiv.org/html/2405.18004v1#bib.bib8 "")\] | 1,300 | ✓ | - | - | ✓ |
| ISIC2016\[ [9](https://arxiv.org/html/2405.18004v1#bib.bib9 "")\] | 1,297 | ✓ | - | - | ✓ |
| ISIC2017\[ [10](https://arxiv.org/html/2405.18004v1#bib.bib10 "")\] | 2,750 | ✓ | ✓(limited) | - | ✓ |
| ISIC2018\[ [11](https://arxiv.org/html/2405.18004v1#bib.bib11 "")\] | 12,500 | ✓ | ✓(limited) | - | ✓ |
| ISIC2019\[ [12](https://arxiv.org/html/2405.18004v1#bib.bib12 ""), [10](https://arxiv.org/html/2405.18004v1#bib.bib10 ""), [13](https://arxiv.org/html/2405.18004v1#bib.bib13 "")\] | 33,569 | ✓ | ✓(limited) | - | ✓ |
| ISIC2020\[ [14](https://arxiv.org/html/2405.18004v1#bib.bib14 "")\] | 33,126 | ✓ | ✓(limited) | - | ✓ |
| HAM10000\[ [12](https://arxiv.org/html/2405.18004v1#bib.bib12 "")\] | 10,015 | ✓ | ✓(limited) | - | ✓ |
| IAD\[ [15](https://arxiv.org/html/2405.18004v1#bib.bib15 "")\] | 2,800 | ✓ | - | - | ✓ |
| MED-NODE\[ [16](https://arxiv.org/html/2405.18004v1#bib.bib16 "")\] | 170 | ✓ | - | - | ✓ |
| Hallym\[ [17](https://arxiv.org/html/2405.18004v1#bib.bib17 "")\] | 152 | ✓ | - | - | ✓ |
| Derm101\[ [18](https://arxiv.org/html/2405.18004v1#bib.bib18 "")\] | 22,979 | ✓ | - | - | ✓ |
| Dermnet\[ [19](https://arxiv.org/html/2405.18004v1#bib.bib19 "")\] | 23,000 | ✓ | - | - | ✓ |
| SD-198\[ [20](https://arxiv.org/html/2405.18004v1#bib.bib20 "")\] | 6,584 | ✓ | - | - | ✓ |
| MoleMap\[ [21](https://arxiv.org/html/2405.18004v1#bib.bib21 "")\] | 102,451 | ✓ | - | - | ✓ |
| Asan\[ [17](https://arxiv.org/html/2405.18004v1#bib.bib17 "")\] | 17,125 | ✓ | - | - | ✓ |
| DermIS\[ [22](https://arxiv.org/html/2405.18004v1#bib.bib22 "")\] | 7,172 | ✓ | - | - | ✓ |
| AtlasDerm\[ [23](https://arxiv.org/html/2405.18004v1#bib.bib23 "")\] | 12,338 | ✓ | - | - | ✓ |
| Danderm\[ [24](https://arxiv.org/html/2405.18004v1#bib.bib24 "")\] | >>>3000 | ✓ | - | - | ✓ |
| XiangyaDerm\[ [25](https://arxiv.org/html/2405.18004v1#bib.bib25 "")\] | 107,565 | ✓ | - | - | - |
| PAD-UFES-20\[ [26](https://arxiv.org/html/2405.18004v1#bib.bib26 "")\] | 2,298 | ✓ | ✓(limited) | - | ✓ |
| Esteva\[ [27](https://arxiv.org/html/2405.18004v1#bib.bib27 "")\] | 129,450 | ✓ | - | - | - |
| DDI\[ [28](https://arxiv.org/html/2405.18004v1#bib.bib28 "")\] | 656 | ✓ | - | - | ✓ |
| Fitzpatrick 17k\[ [29](https://arxiv.org/html/2405.18004v1#bib.bib29 "")\] | 16,577 | ✓ | - | - | ✓ |
| SKINCON\[ [30](https://arxiv.org/html/2405.18004v1#bib.bib30 "")\] | 4,346 | ✓ | ✓(comprehensive) | - | ✓ |
| SkinCAP (ours) | 4,000 | ✓ | ✓(comprehensive) | ✓ | ✓ |

Report issue for preceding elementTABLE II: Distribution of samples for each type of skin disease in SkinCAP with sample size <<< 20

|     |     |     |     |
| --- | --- | --- | --- |
| Skin Disease | #Samples | Skin Disease | #Samples |
| Acrochordon | 19 | Blue nevus | 6 |
| Nevus sebaceous of jadassohn | 19 | Basal cell carcinoma nodular | 6 |
| Dyshidrotic eczema | 19 | Nevus lipomatosus superficialis | 6 |
| Acquired autoimmune bullous diseaseherpes gestationis | 19 | Molluscum contagiosum | 6 |
| Erythema nodosum | 19 | Melanoma in situ | 5 |
| Keratosis pilaris | 18 | Metastatic carcinoma | 5 |
| Striae | 18 | Eczema spongiotic dermatitis | 4 |
| Perioral dermatitis | 18 | Solar lentigo | 4 |
| Superficial spreading melanoma ssm | 18 | Hyperpigmentation | 3 |
| Hidradenitis | 18 | Abrasions ulcerations and physical injuries | 3 |
| Aplasia cutis | 17 | Trichilemmoma | 3 |
| Mucinosis | 17 | Benign keratosis | 3 |
| Congenital nevus | 17 | Arteriovenous hemangioma | 3 |
| Calcinosis cutis | 17 | Basal cell carcinoma superficial | 2 |
| Port wine stain | 17 | Foreign body granuloma | 2 |
| Dysplastic nevus | 16 | Acquired digital fibrokeratoma | 2 |
| Acanthosis nigricans | 16 | Syringocystadenoma papilliferum | 2 |
| Xanthomas | 16 | Onychomycosis | 2 |
| Pityriasis lichenoides chronica | 16 | Trichofolliculoma | 2 |
| Paronychia | 15 | Scar | 2 |
| Nevocytic nevus | 15 | Xanthogranuloma | 2 |
| Solid cystic basal cell carcinoma | 15 | Condyloma accuminatum | 2 |
| Seborrheic keratosis irritated | 14 | Fibrous papule | 2 |
| Behcets disease | 14 | Graft vs host disease | 2 |
| Basal cell carcinoma morpheiform | 14 | Subcutaneous t cell lymphoma | 1 |
| Langerhans cell histiocytosis | 14 | Focal acral hyperkeratosis | 1 |
| Stasis edema | 13 | Wart | 1 |
| Factitial dermatitis | 13 | Lymphocytic infiltrations | 1 |
| Naevus comedonicus | 13 | Angioleiomyoma | 1 |
| Neurotic excoriations | 13 | Hematoma | 1 |
| Epidermolysis bullosa | 13 | Atypical spindle cell nevus of reed | 1 |
| Ichthyosis vulgaris | 13 | Acne cystic | 1 |
| Neurofibroma | 12 | Verruciform xanthoma | 1 |
| Pustular psoriasis | 12 | Morphea | 1 |
| Neurodermatitis | 12 | Neuroma | 1 |
| Erythema elevatum diutinum | 12 | Nodular melanoma (nm) | 1 |
| Myiasis | 12 | Pigmented spindle cell nevus of reed | 1 |
| Disseminated actinic porokeratosis | 12 | Glomangioma | 1 |
| Pilomatricoma | 12 | Cellular neurothekeoma | 1 |
| Angioma | 11 | Lichenoid keratosis | 1 |
| Becker nevus | 11 | Reactive lymphoid hyperplasia | 1 |
| Drug induced pigmentary changes | 11 | Coccidioidomycosis | 1 |
| Eccrine poroma | 10 | Leukemia cutis | 1 |
| Granuloma pyogenic | 10 | Sebaceous carcinoma | 1 |
| Livedo reticularis | 10 | Chondroid syringoma | 1 |
| Sun damaged skin | 9 | Tinea pedis | 1 |
| Squamous cell carcinoma keratoacanthoma | 8 | Clear cell acanthoma | 1 |
| Melanoma acral lentiginous | 7 | Abscess | 1 |
| Inverted follicular keratosis | 6 | Blastic plasmacytoid dendritic cell neoplasm | 1 |
| Lipoma | 6 | Acral melanotic macule | 1 |

Report issue for preceding elementTABLE III: Column names and corresponding descriptions in SkinCAP.

|     |     |
| --- | --- |
| Column Name | Description |
| id | Internal identifier for SkinCAP samples |
| skincap\_file\_path | File name of SkinCAP samples |
| ori\_file\_path | Original file name corresponding to Fitzpatrick and DDI datasets |
| disease | Disease label related to the sample |
| caption\_zh | Caption annotated by dermatologists in Chinese |
| caption\_zh\_polish | Converted caption annotated by dermatologists in Chinese |
| caption\_zh\_polish\_en | Converted caption in English |
| remark | Extra notes from dermatologists |
| source | Source of the sample |
| skin\_tone | Skin tone of the sample (only for cases from DDI dataset) |
| malignant | Indicates if the sample is malignant (only for cases from DDI dataset) |
| fitzpatrick\_scale | Fitzpatrick scale value (only for cases from Fitzpatrick dataset) |
| fitzpatrick\_centaur | Fitzpatrick centaur value (only for cases from Fitzpatrick dataset) |
| nine\_partition\_label | Label based on nine-partition method (only for cases from Fitzpatrick dataset) |
| three\_partition\_label | Label based on three-partition method (only for cases from Fitzpatrick dataset) |
| url | URL of the sample image |
| Remaining columns∗ | 48 clinical concepts proposed by SKINCON, including Vesicle, Papule, Macule,Plaque, Abscess, Pustule, Bulla, Patch, Nodule, Ulcer, Crust, Erosion, Excoriation,Atrophy, Exudate, Purpura/Petechiae, Fissure, Induration, Xerosis,Telangiectasia, Scale, Scar, Friable, Sclerosis, Pedunculated, Exophytic/Fungating,Warty/Papillomatous, Dome-shaped, Flat-topped, Brown (Hyperpigmentation),Translucent, White (Hypopigmentation), Purple, Yellow, Black, Erythema,Comedo, Lichenification, Blue, Umbilicated, Poikiloderma, Salmon, Wheal,Acuminate, Burrow, Gray, Pigmented, and Cyst |

Report issue for preceding element

While several publicly available datasets, such as ISIC\[ [9](https://arxiv.org/html/2405.18004v1#bib.bib9 "")\], Dermnet, XiangyaDerm\[ [25](https://arxiv.org/html/2405.18004v1#bib.bib25 "")\], Fitzpatrick 17k\[ [29](https://arxiv.org/html/2405.18004v1#bib.bib29 "")\], and Diverse Dermatology Images (DDI)\[ [28](https://arxiv.org/html/2405.18004v1#bib.bib28 "")\], exist, they primarily offer simple classification labels and lack comprehensive medical descriptions (Table [I](https://arxiv.org/html/2405.18004v1#S1.T1 "TABLE I ‣ 1 Background & Summary ‣ SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions")). SKINCON\[ [30](https://arxiv.org/html/2405.18004v1#bib.bib30 "")\] is the only publicly accessible medical dataset densely annotated by dermatologists with 48 clinical concepts. However, the labeling of images in SKINCON is based on the attribute level, which may not fully capture the nuanced characteristics of skin diseases and differs significantly from the natural language-based diagnostic reports produced by dermatologists.

Report issue for preceding element

To the best of our knowledge, there is currently no publicly available skin disease database that offers comprehensive medical descriptions in natural language alongside skin disease images. The availability of such open-access data holds immense potential for advancing research in the field of multi-modal LLMs for skin disease diagnosis, as exemplified by SkinGPT-4. In this study, we augmented 4,000 images sourced from the Fitzpatrick 17k skin disease dataset and the Diverse Dermatology Images dataset with dense annotations provided by multi-centric board-certified dermatologists. These annotations include rich medical descriptions or captions, resulting in the creation of the SkinCAP dataset consisting of 4,000 samples. Notably, SkinCAP represents the world’s first such dataset (Table [I](https://arxiv.org/html/2405.18004v1#S1.T1 "TABLE I ‣ 1 Background & Summary ‣ SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions")) and is publicly accessible at [https://huggingface.co/datasets/joshuachou/SkinCAP](https://huggingface.co/datasets/joshuachou/SkinCAP "").

Report issue for preceding element

## 2 Methods

Report issue for preceding element

Data collection. Skin disease images and pre-annotated information were collected from three publicly available skin disease databases: Fitzpatrick 17k\[ [29](https://arxiv.org/html/2405.18004v1#bib.bib29 "")\], Diverse Dermatology Images (DDI)\[ [28](https://arxiv.org/html/2405.18004v1#bib.bib28 "")\] and SKINCON\[ [30](https://arxiv.org/html/2405.18004v1#bib.bib30 "")\].

Report issue for preceding element

The Fitzpatrick 17k dataset comprises 16,577 clinical images annotated with skin condition labels and Ftzpatrick skin type labels. These images are sourced from two online open-source dermatology atlases: 12,672 images from DermaAmin and 3,905 images from Atlas Dermatologico.

Report issue for preceding element

The DDI dataset includes a total of 208 images classified for Fitzpatrick skin types I–II (159 benign and 49 malignant), 241 images for Fitzpatrick skin types III–IV (167 benign and 74 malignant), and 207 images for Fitzpatrick skin types V–VI (159 benign and 48 malignant).

Report issue for preceding element

SKINCON, developed using images from Fitzpatrick 17k and DDI, comprises 3,690 images from the Fitzpatrick 17k skin disease dataset and 656 skin disease images from the DDI dataset. These images are densely annotated with 48 clinical concepts, with 22 concepts represented by at least 50 images each.

Report issue for preceding element

We build upon these skin disease images and pre-annotated information to enrich the dataset with detailed medical descriptions provided by four board-certified dermatologists. Annotation and verification were carried out in a multi-centric approach, involving dermatologists from various institutions including Beijing AnZhen Hospital, Affiliated with Capital Medical University, China; Tianjin Institute of Integrative Dermatology, Tianjin Academy of Traditional Chinese Medicine Affiliated Hospital, China; Beijing Aerospace General Hospital, China; Second Hospital of Jilin University, China; One dermatologist from each center participated in the annotation and verification process.

Report issue for preceding element

Ethics. Ethical approval (No. ID 2024002X) was obtained from the Ethics Committee of Beijing AnZhen Hospital, affiliated with Capital Medical University in Beijing, China, and ethical approval (No. ID 23IBEC100) was obtained from the Ethics Committee of King Abdullah University of Science and Technology. The research was conducted in accordance with the principles outlined in the Declaration of Helsinki. As we did not collect new skin disease images but rather utilized existing ones under the Terms of Use, written informed consent was waived by the Ethics Committee.

Report issue for preceding element

Annotation protocol. Dermatologists were presented with a series of skin disease images devoid of additional medical context. Their task involved furnishing comprehensive descriptions of the medical attributes specific to the area affected by the skin disease in each image. These descriptions encompass details such as location, distribution, color, morphology, and other pertinent characteristics. Additionally, dermatologists were asked to articulate these features in natural language to formulate a diagnostic caption. In cases where applicable, dermatologists provided the most likely diagnosis among their differential. All raw annotations were provided in Chinese (Figure [1](https://arxiv.org/html/2405.18004v1#S1.F1 "Figure 1 ‣ 1 Background & Summary ‣ SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions")a).

Report issue for preceding element

Annotation conversion and quality assurance. Each raw caption underwent further refinement and translation from Chinese to English using custom software developed with LangChain and GPT-4. The software utilized the following prompt design: system: I will provide a diagnosis in Chinese. You should polish and extend the provided diagnosis in Chinese and ensure the medical information and terminology are accurate. Then translate the polished sentence into English. You should separate the two responses with <<<SEP>>>. user: {raw\_caption}. The term {raw\_caption} denotes the raw caption annotated by board-certified dermatologists. The post-processed captions subsequently underwent manual secondary inspection and cross-validation among dermatologists to uphold quality standards. Each image is ensured to be checked by at least two experts. The board-certified dermatologists involved in this study possessed 24, 18, 21, and 18 years of experience, respectively.

Report issue for preceding element

Currently, SkinCAP comprises 4,000 skin disease images representing 178 types of skin diseases (Figure [1](https://arxiv.org/html/2405.18004v1#S1.F1 "Figure 1 ‣ 1 Background & Summary ‣ SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions") b and Table [II](https://arxiv.org/html/2405.18004v1#S1.T2 "TABLE II ‣ 1 Background & Summary ‣ SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions")) along with the most extensive annotation in natural language compared to existing dermatology datasets (Figure [1](https://arxiv.org/html/2405.18004v1#S1.F1 "Figure 1 ‣ 1 Background & Summary ‣ SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions") c and Table [I](https://arxiv.org/html/2405.18004v1#S1.T1 "TABLE I ‣ 1 Background & Summary ‣ SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions")). SkinCAP encompasses all skin tones on the Fitzpatrick scale from I to VI (Figure [1](https://arxiv.org/html/2405.18004v1#S1.F1 "Figure 1 ‣ 1 Background & Summary ‣ SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions") d).

Report issue for preceding element

## 3 Data Records

Report issue for preceding element

All data files within SkinCAP are archived and permanently accessible to the public through Hugging Face at ( [https://huggingface.co/datasets/joshuachou/SkinCAP](https://huggingface.co/datasets/joshuachou/SkinCAP "") and [https://doi.org/10.57967/hf/2256](https://doi.org/10.57967/hf/2256 "")). It is released under a Creative Commons Attribution Non-Commercial Share Alike 4.0 International (CC-BY-NC-SA 4.0) license ( [https://creativecommons.org/licenses/by-nc-sa/4.0/](https://creativecommons.org/licenses/by-nc-sa/4.0/ "")). As of now, no modifications have been made to the dataset. However, any changes to metadata or images will be duly noted on the DOI landing page.

Report issue for preceding element

Dataset format. Clinical dermatological images within the repository are encoded in the Portable Network Graphics (PNG) format. Metadata is provided in a linked comma-separated values (CSV) file, comprehensively delineating annotations related to skin disease images. Access to the raw images of skin diseases requires an additional application for entry, facilitated by Fitzpatrick 17k ( [https://github.com/mattgroh/fitzpatrick17k](https://github.com/mattgroh/fitzpatrick17k "")) and DDI ( [https://ddi-dataset.github.io/](https://ddi-dataset.github.io/ "")).

Report issue for preceding element

We have implemented an internal ID for all skin disease images, assigning a unique identifier to each entry within the initial column of the CSV file named id. Files detailing fundamental components include supplementary attributes such as the type of skin disease, raw captions, converted captions, and corresponding ID numbers sourced from other databases, encapsulated within subsequent columns (Table [III](https://arxiv.org/html/2405.18004v1#S1.T3 "TABLE III ‣ 1 Background & Summary ‣ SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions")).

Report issue for preceding element

## 4 Technical Validation

Report issue for preceding element

The skin disease images within the SkinCAP datasets were sourced from several public databases, notably Fitzpatrick 17k and DDI. Partial annotations were also obtained from SKINCON. Ground truth categorical labels for all skin diseases in the dataset were derived from Fitzpatrick 17k and the DDI dataset. These images underwent further dense annotation by board-certified dermatologists to furnish rich medical descriptions and captions within SkinCAP. Our dataset serves as a valuable resource for training multi-modal Large Language Models (LLMs), such as SkinGPT-4\[ [5](https://arxiv.org/html/2405.18004v1#bib.bib5 "")\], for accurate skin disease assessment (see Figure [1](https://arxiv.org/html/2405.18004v1#S1.F1 "Figure 1 ‣ 1 Background & Summary ‣ SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions") e), and future research in VLLMs\[ [31](https://arxiv.org/html/2405.18004v1#bib.bib31 "")\].

Report issue for preceding element

## 5 Usage Notes

Report issue for preceding element

Users could use SkinCAP to train multi-modal LLMs such as BLIP-2 and SkinGPT-4\[ [5](https://arxiv.org/html/2405.18004v1#bib.bib5 "")\], for direct medical evaluation of skin disease images. This process utilizes both the image data and the natural language descriptions provided under the ’caption\_zh\_polish\_en’ field within SkinCAP. Additionally, users have the flexibility to integrate other medical features and metadata from SkinCAP into a customized text description for enhanced analysis and evaluation.

Report issue for preceding element

## 6 Acknowledgements

Report issue for preceding element

Funding: Juexiao Zhou, Zhongyi Han, and Xin Gao were supported in part by grants from the Office of Research Administration (ORA) at King Abdullah University of Science and Technology (KAUST) under award number FCC/1/1976-44-01, FCC/1/1976-45-01, REI/1/5202-01-01, REI/1/5234-01-01, REI/1/4940-01-01, RGC/3/4816-01-01, and REI/1/0018-01-01. Xiaonan He was supported by the foundation of the National Natural Science Foundation of China (No. 62272327).

Report issue for preceding element

Author Contribution Statements: J.Z. and X.G. conceived of the presented idea. J.Z. designed the custom software for post-processing data. J.Z, X.H. L.S., Y.X., W.L., S.A., Z.H., Y.J., J.S. conducted the data collection and evaluation. X.G. supervised the findings of this work. J.Z. and X.G. took the lead in writing the manuscript. All authors discussed the results and contributed to the final manuscript.

Report issue for preceding element

Competing Interests: The authors have declared no competing interests.

Report issue for preceding element

Data availability: The data that support the findings of this study can be accessed at [https://huggingface.co/datasets/joshuachou/SkinCAP](https://huggingface.co/datasets/joshuachou/SkinCAP "") and [https://doi.org/10.57967/hf/2256](https://doi.org/10.57967/hf/2256 "").

Report issue for preceding element

Code availability: The code supporting this study’s findings is available at [https://huggingface.co/datasets/joshuachou/SkinCAP](https://huggingface.co/datasets/joshuachou/SkinCAP "").

Report issue for preceding element

The scripts and packages used for the SkinCAP rely on open-source packages such as Python 3.10, LangChain, OpenAI API, and custom Python scripts.

Report issue for preceding element

## References

Report issue for preceding element

- \[1\]↑
M. R. Laughter, M. B. Maymone, C. Karimkhani, C. Rundle, S. Hu, S. Wolfe, K. Abuabara, P. Hollingsworth, G. S. Weintraub, C. A. Dunnick _et al._, “The burden of skin and subcutaneous diseases in the united states from 1990 to 2017,” _JAMA dermatology_, vol. 156, no. 8, pp. 874–881, 2020.

- \[2\]↑
C. Karimkhani, R. P. Dellavalle, L. E. Coffeng, C. Flohr, R. J. Hay, S. M. Langan, E. O. Nsoesie, A. J. Ferrari, H. E. Erskine, J. I. Silverberg _et al._, “Global skin disease morbidity and mortality: an update from the global burden of disease study 2013,” _JAMA dermatology_, vol. 153, no. 5, pp. 406–412, 2017.

- \[3\]↑
C. Flohr and R. Hay, “Putting the burden of skin diseases on the global map,” pp. 189–190, 2021.

- \[4\]↑
S. P. Choy, B. J. Kim, A. Paolino, W. R. Tan, S. M. L. Lim, J. Seo, S. P. Tan, L. Francis, T. Tsakok, M. Simpson _et al._, “Systematic review of deep learning image analyses for the diagnosis and monitoring of skin disease,” _NPJ Digital Medicine_, vol. 6, no. 1, p. 180, 2023.

- \[5\]↑
J. Zhou, X. He, L. Sun, J. Xu, X. Chen, Y. Chu, L. Zhou, X. Liao, B. Zhang, and X. Gao, “Skingpt-4: an interactive dermatology diagnostic system with visual large language model,” 2023.

- \[6\]↑
A. H. Thieme, Y. Zheng, G. Machiraju, C. Sadee, M. Mittermaier, M. Gertler, J. L. Salinas, K. Srinivasan, P. Gyawali, F. Carrillo-Perez _et al._, “A deep-learning algorithm to classify skin lesions from mpox virus infection,” _Nature medicine_, vol. 29, no. 3, pp. 738–747, 2023.

- \[7\]↑
T. Mendonça, P. M. Ferreira, J. S. Marques, A. R. Marcal, and J. Rozeira, “Ph 2-a dermoscopic image database for research and benchmarking,” in _2013 35th annual international conference of the IEEE engineering in medicine and biology society (EMBC)_.   IEEE, 2013, pp. 5437–5440.

- \[8\]↑
L. Ballerini, R. B. Fisher, B. Aldridge, and J. Rees, “A color and texture based hierarchical k-nn approach to the classification of non-melanoma skin lesions,” _Color medical image analysis_, pp. 63–86, 2013.

- \[9\]↑
D. Gutman, N. C. Codella, E. Celebi, B. Helba, M. Marchetti, N. Mishra, and A. Halpern, “Skin lesion analysis toward melanoma detection: A challenge at the international symposium on biomedical imaging (isbi) 2016, hosted by the international skin imaging collaboration (isic),” _arXiv preprint arXiv:1605.01397_, 2016.

- \[10\]↑
N. C. Codella, D. Gutman, M. E. Celebi, B. Helba, M. A. Marchetti, S. W. Dusza, A. Kalloo, K. Liopyris, N. Mishra, H. Kittler _et al._, “Skin lesion analysis toward melanoma detection: A challenge at the 2017 international symposium on biomedical imaging (isbi), hosted by the international skin imaging collaboration (isic),” in _2018 IEEE 15th international symposium on biomedical imaging (ISBI 2018)_.   IEEE, 2018, pp. 168–172.

- \[11\]↑
N. Codella, V. Rotemberg, P. Tschandl, M. E. Celebi, S. Dusza, D. Gutman, B. Helba, A. Kalloo, K. Liopyris, M. Marchetti _et al._, “Skin lesion analysis toward melanoma detection 2018: A challenge hosted by the international skin imaging collaboration (isic),” _arXiv preprint arXiv:1902.03368_, 2019.

- \[12\]↑
P. Tschandl, C. Rosendahl, and H. Kittler, “The ham10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions,” _Scientific data_, vol. 5, no. 1, pp. 1–9, 2018.

- \[13\]↑
M. Combalia, N. C. Codella, V. Rotemberg, B. Helba, V. Vilaplana, O. Reiter, C. Carrera, A. Barreiro, A. C. Halpern, S. Puig _et al._, “Bcn20000: Dermoscopic lesions in the wild,” _arXiv preprint arXiv:1908.02288_, 2019.

- \[14\]↑
V. Rotemberg, N. Kurtansky, B. Betz-Stablein, L. Caffery, E. Chousakos, N. Codella, M. Combalia, S. Dusza, P. Guitera, D. Gutman _et al._, “A patient-centric dataset of images and metadata for identifying melanomas using clinical context,” _Scientific data_, vol. 8, no. 1, p. 34, 2021.

- \[15\]↑
G. Argenziano, H. Soyer, V. De Giorgi, D. Piccolo, P. Carli, M. Delfino _et al._, “Dermoscopy: a tutorial. edra,” 2002.

- \[16\]↑
I. Giotis, N. Molders, S. Land, M. Biehl, M. F. Jonkman, and N. Petkov, “Med-node: A computer-assisted melanoma diagnosis system using non-dermoscopic images,” _Expert systems with applications_, vol. 42, no. 19, pp. 6578–6585, 2015.

- \[17\]↑
S. S. Han, M. S. Kim, W. Lim, G. H. Park, I. Park, and S. E. Chang, “Classification of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm,” _Journal of Investigative Dermatology_, vol. 138, no. 7, pp. 1529–1538, 2018.

- \[18\]↑
A. Boer and K. Nischal, “www. derm101. com: A growing online resource for learning dermatology and dermatopathology,” _Indian Journal of Dermatology, Venereology and Leprology_, vol. 73, p. 138, 2007.

- \[19\]↑
Dermnet. (2020) Dermnet. \[Online\]. Available: [https://dermnetnz.org/](https://dermnetnz.org/ "")
- \[20\]↑
X. Sun, J. Yang, M. Sun, and K. Wang, “A benchmark for automatic visual classification of clinical skin disease images,” in _Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VI 14_.   Springer, 2016, pp. 206–222.

- \[21\]↑
X. Yi, E. Walia, and P. Babyn, “Unsupervised and semi-supervised learning with categorical generative adversarial networks assisted by wasserstein distance for dermoscopy image classification,” _arXiv preprint arXiv:1804.03700_, 2018.

- \[22\]↑
D. I. System. (2012) Dermatology information system. \[Online\]. Available: [https://www.dermis.net/dermisroot/en/home/index.htm](https://www.dermis.net/dermisroot/en/home/index.htm "")
- \[23\]↑
AtlasDerm. Atlasderm. \[Online\]. Available: [http://www.atlasdermatologico.com.br/](http://www.atlasdermatologico.com.br/ "")
- \[24\]↑
Danderm. (1995) Danderm. \[Online\]. Available: [https://danderm-pdv.is.kkh.dk](https://danderm-pdv.is.kkh.dk/ "")
- \[25\]↑
B. Xie, X. He, S. Zhao, Y. Li, J. Su, X. Zhao, Y. Kuang, Y. Wang, and X. Chen, “Xiangyaderm: a clinical image dataset of asian race for skin disease aided diagnosis,” in _Large-Scale Annotation of Biomedical Data and Expert Label Synthesis and Hardware Aware Learning for Medical Imaging and Computer Assisted Intervention: International Workshops, LABELS 2019, HAL-MICCAI 2019, and CuRIOUS 2019, Held in Conjunction with MICCAI 2019, Shenzhen, China, October 13 and 17, 2019, Proceedings 4_.   Springer, 2019, pp. 22–31.

- \[26\]↑
A. G. Pacheco, G. R. Lima, A. S. Salomao, B. Krohling, I. P. Biral, G. G. de Angelo, F. C. Alves Jr, J. G. Esgario, A. C. Simora, P. B. Castro _et al._, “Pad-ufes-20: A skin lesion dataset composed of patient data and clinical images collected from smartphones,” _Data in brief_, vol. 32, p. 106221, 2020.

- \[27\]↑
A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau, and S. Thrun, “Dermatologist-level classification of skin cancer with deep neural networks,” _nature_, vol. 542, no. 7639, pp. 115–118, 2017.

- \[28\]↑
R. Daneshjou, K. Vodrahalli, R. A. Novoa, M. Jenkins, W. Liang, V. Rotemberg, J. Ko, S. M. Swetter, E. E. Bailey, O. Gevaert _et al._, “Disparities in dermatology ai performance on a diverse, curated clinical image set,” _Science advances_, vol. 8, no. 31, p. eabq6147, 2022.

- \[29\]↑
M. Groh, C. Harris, L. Soenksen, F. Lau, R. Han, A. Kim, A. Koochek, and O. Badri, “Evaluating deep neural networks trained on clinical images in dermatology with the fitzpatrick 17k dataset,” in _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, 2021, pp. 1820–1828.

- \[30\]↑
R. Daneshjou, M. Yuksekgonul, Z. R. Cai, R. Novoa, and J. Y. Zou, “Skincon: A skin disease dataset densely annotated by domain experts for fine-grained debugging and analysis,” _Advances in Neural Information Processing Systems_, vol. 35, pp. 18 157–18 167, 2022.

- \[31\]↑
Z. Han, G. Zhou, R. He, J. Wang, X. Xie, T. Wu, Y. Yin, S. Khan, L. Yao, T. Liu _et al._, “How well does gpt-4v (ision) adapt to distribution shifts? a preliminary investigation,” _arXiv preprint arXiv:2312.07424_, 2023.


Report IssueReport Issue for Selection

Generated by
[L\\
A\\
T\\
Exml![[LOGO]](<Base64-Image-Removed>)](https://math.nist.gov/~BMiller/LaTeXML/)

---

## Source 4: pmc.ncbi.nlm.nih.gov {#source-4}

**URL:** https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/
**Content Type:** Web Content
**Content Length:** 81,166 characters
**Scraped At:** 2025-06-29T11:25:57.292Z

**Detected Structure:** Tables

### Content:

[Skip to main content](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#main-content)

![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-dot-gov.svg)

**Official websites use .gov**

A
**.gov** website belongs to an official
government organization in the United States.


![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-https.svg)

**Secure .gov websites use HTTPS**

A **lock** (
Lock
Locked padlock icon
) or **https://** means you've safely
connected to the .gov website. Share sensitive
information only on official, secure websites.


[Home](https://pmc.ncbi.nlm.nih.gov/ "Home")

Search PMC Full-Text Archive

Search in PMC![Search](https://pmc.ncbi.nlm.nih.gov/static/img/usa-icons-bg/search--white.svg)

- [Advanced Search](https://www.ncbi.nlm.nih.gov/pmc/advanced/)
- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)
- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)

NewTry this search in PMC Beta Search

- [View on publisher site](https://doi.org/10.3390/bioengineering12030275) View on publisher site
- [Download PDF](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/pdf/bioengineering-12-00275.pdf) Download PDF
- Add to Collections
- Cite
- Permalink




## PERMALINK



Copy


As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
the contents by NLM or the National Institutes of Health.

Learn more:
[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)
\|
[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)

![Bioengineering logo](https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-bioeng.png)

Bioengineering (Basel)

. 2025 Mar 11;12(3):275. doi: [10.3390/bioengineering12030275](https://doi.org/10.3390/bioengineering12030275)

# Enhanced Skin Disease Classification via Dataset Refinement and Attention-Based Vision Approach

[Muhammad Nouman Noor](https://pubmed.ncbi.nlm.nih.gov/?term=%22Noor%20MN%22%5BAuthor%5D)

### Muhammad Nouman Noor

1School of Computing, National University of Computer & Emerging Sciences (FAST-NUCES), Islamabad 44000, Pakistan

Conceptualization, Methodology, Software, Writing – original draft, Supervision

Find articles by [Muhammad Nouman Noor](https://pubmed.ncbi.nlm.nih.gov/?term=%22Noor%20MN%22%5BAuthor%5D)

1,\*, [Farah Haneef](https://pubmed.ncbi.nlm.nih.gov/?term=%22Haneef%20F%22%5BAuthor%5D)

### Farah Haneef

2Department of Software Engineering, Capital University of Science and Technology (CUST), Islamabad 44000, Pakistan

Conceptualization, Methodology, Software, Data curation, Visualization

Find articles by [Farah Haneef](https://pubmed.ncbi.nlm.nih.gov/?term=%22Haneef%20F%22%5BAuthor%5D)

2, [Imran Ashraf](https://pubmed.ncbi.nlm.nih.gov/?term=%22Ashraf%20I%22%5BAuthor%5D)

### Imran Ashraf

1School of Computing, National University of Computer & Emerging Sciences (FAST-NUCES), Islamabad 44000, Pakistan

Validation, Formal analysis, Resources, Data curation, Writing – review & editing

Find articles by [Imran Ashraf](https://pubmed.ncbi.nlm.nih.gov/?term=%22Ashraf%20I%22%5BAuthor%5D)

1, [Muhammad Masud](https://pubmed.ncbi.nlm.nih.gov/?term=%22Masud%20M%22%5BAuthor%5D)

### Muhammad Masud

3Department of Electrical Engineering, College of Engineering, University of Business and Technology, Jeddah 21361, Saudi Arabia

Validation, Formal analysis, Investigation, Data curation, Writing – review & editing

Find articles by [Muhammad Masud](https://pubmed.ncbi.nlm.nih.gov/?term=%22Masud%20M%22%5BAuthor%5D)

3,\*

Editors: Jorge Mateo, Ana María Torres Aranda, Ryan Halter

- Author information
- Article notes
- Copyright and License information

1School of Computing, National University of Computer & Emerging Sciences (FAST-NUCES), Islamabad 44000, Pakistan

2Department of Software Engineering, Capital University of Science and Technology (CUST), Islamabad 44000, Pakistan

3Department of Electrical Engineering, College of Engineering, University of Business and Technology, Jeddah 21361, Saudi Arabia

\*

Correspondence: nouman.noor@isb.nu.edu.pk (M.N.N.); m.masud@ubt.edu.sa (M.M.)

#### Roles

**Muhammad Nouman Noor**: Conceptualization, Methodology, Software, Writing – original draft, Supervision

**Farah Haneef**: Conceptualization, Methodology, Software, Data curation, Visualization

**Imran Ashraf**: Validation, Formal analysis, Resources, Data curation, Writing – review & editing

**Muhammad Masud**: Validation, Formal analysis, Investigation, Data curation, Writing – review & editing

**Jorge Mateo**: Academic Editor

**Ana María Torres Aranda**: Academic Editor

**Ryan Halter**: Academic Editor

Received 2025 Feb 5; Revised 2025 Mar 4; Accepted 2025 Mar 8; Collection date 2025 Mar.

© 2025 by the authors.

Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ( [https://creativecommons.org/licenses/by/4.0/](https://creativecommons.org/licenses/by/4.0/)).

[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)

PMCID: PMC11939559  PMID: [40150739](https://pubmed.ncbi.nlm.nih.gov/40150739/)

## Abstract

Skin diseases are listed among the most frequently encountered diseases. Skin diseases such as eczema, melanoma, and others necessitate early diagnosis to avoid further complications. This study aims to enhance the diagnosis of skin disease by utilizing advanced image processing techniques and an attention-based vision approach to support dermatologists in solving classification problems. Initially, the image is being passed through various processing steps to enhance the quality of the dataset. These steps are adaptive histogram equalization, binary cross-entropy with implicit averaging, gamma correction, and contrast stretching. Afterwards, enhanced images are passed through the attention-based approach for performing classification which is based on the encoder part of the transformers and multi-head attention. Extensive experimentation is performed to collect the various results on two publicly available datasets to show the robustness of the proposed approach. The evaluation of the proposed approach on two publicly available datasets shows competitive results as compared to a state-of-the-art approach.

**Keywords:** skin disease, preprocessing, classification, vision transformer, skin cancer

## 1\. Introduction

Addressing the fact that the skin is the largest organ in the human body, dermatological diseases are listed among the most frequently encountered illnesses \[ [1](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B1-bioengineering-12-00275)\]. Some of them are evident and do not pose a terrible threat when treated, while other ones are critical and can be life-threatening if not treated in time. In fact, when they are diagnosed at the terminal stages, approximately 30% to 70% of individuals belong to high-risk groups \[ [2](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B2-bioengineering-12-00275)\]. Currently, there are estimated to be approximately 2 to 3 million new cases of non-melanoma skin cancers, as well as approximately 132,000 new cases of melanoma skin cancers annually \[ [3](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B3-bioengineering-12-00275)\]. Malignant melanoma is one of the most dangerous forms of the disease that leads to 10,000 mortalities per year all over the world \[ [4](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B4-bioengineering-12-00275)\]. Early detection of any abnormality in the melanocytes has a high rate of survival of 96% when diagnosed in the early stages, as compared to 5% in the late stages \[ [5](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B5-bioengineering-12-00275)\]. The WHO has estimated that, on average, death occurs to the tune of forty per one hundred thousand population with skin diseases, according to epidemiological findings \[ [6](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B6-bioengineering-12-00275)\]. Due to the thinning of the ozone layer, and its acting as a shield to the sun rays, the increased radiation with UV-B and UV-C has become more common on the surface of the earth. Therefore, this higher UV exposure increases non-melanoma skin cancers that play a major role in the development of malignant melanoma \[ [7](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B7-bioengineering-12-00275)\]. Many AI-based systems have been developed to help doctors like OPD, OR systems, and advanced health data analysis systems like IBM Watson, Tempus, and Cerner for medical research, finding cancer treatments and electronic health records, respectively \[ [8](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B8-bioengineering-12-00275)\]. But doctors still rely on their ability to diagnose the disease by drawing their attention to visually detected symptoms such as color and scaling of the lesions as well as their distribution.

Lack of awareness and over-optimistic attitudes cause people to think their skin diseases are not severe, and so they try home remedies \[ [9](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B9-bioengineering-12-00275)\], potentially worsening the condition \[ [10](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B10-bioengineering-12-00275)\]. Since skin diseases are easily communicable, it becomes important that they are treated in their early stages \[ [11](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B11-bioengineering-12-00275)\]. As a result, there is a clear need to solve this problem and guarantee the appropriate and timely treatment of skin diseases at the initial stage to avoid further damage. Furthermore, despite the fact that existing systems are impressive in terms of accuracy, they show certain restrictions if the number of diseases, which can be detected in one analysis, is concerned. These systems often focus on a comparatively narrow number of diseases, and this is typically not more than three or five diseases in most cases.

Despite promising advancements, some issues and challenges remain with regard to AI-based skin disease diagnosis. One major challenge is that some skin diseases like skin cancer and vitiligo manifest minimal pathological symptoms in their early stages \[ [12](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B12-bioengineering-12-00275), [13](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B13-bioengineering-12-00275), [14](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B14-bioengineering-12-00275)\]. Many conventional diagnostic techniques used in dermatology are based on observation and gross examination, resulting in a lack of well-defined standards, measures, and quantity, which can potentially lead to misdiagnosis, even by dermatologists with many years of experience \[ [15](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B15-bioengineering-12-00275), [16](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B16-bioengineering-12-00275)\]. The lack of dermatologists in remote areas means that other clinicians, who may not have adequate understanding and skills in the diagnosis and management of dermatological diseases, conduct these procedures, thus worsening the possibility of incorrect diagnosis. This is compounded by the fact that there is an inequality in the distribution of healthcare facilities, thus it becomes hard to make an accurate diagnosis.

Despite the potential of AI technology, especially image recognition \[ [17](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B17-bioengineering-12-00275), [18](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B18-bioengineering-12-00275), [19](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B19-bioengineering-12-00275), [20](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B20-bioengineering-12-00275), [21](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B21-bioengineering-12-00275)\], several drawbacks should be noted. For instance, patterns used in the AI models have to be carefully coded as well as tested to eliminate bias when making diagnoses. Both ML and DL can effectively recognize and outline similar characteristics of skin lesions and therefore lead to the correct identification of the moles; however, their efficiency depends on the volume and heterogeneity of the data set. DL algorithms tend to be more effective when a large dataset is available while ML is effective when the data volume is small \[ [22](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B22-bioengineering-12-00275)\].

The main contributions of this research are as follows:

- Utilization of advanced image processing techniques to improve the quality of the images. Quality of the images is evaluated using peak-signal-to-noise-ratio (PSNR) and mean squared error (MSE).

- Development of attention-based framework for efficient skin disease classification. The proposed framework utilizes the encoder part of transformers with multi-head attention for improved performance.

- Evaluation of proposed framework on various performance measures using two publicly available datasets.


The rest of the paper is organized as follows: The next section presents literature, afterwards methodology is explained, and subsequently results are presented. Finally, the conclusion of the paper is shown.

## 2\. Related Literature

Skin disease recognition and classification have been investigated in detail with such approaches through different AI methods, which indicates promising incremental improvements in terms of accuracy and time. Chen et al. \[ [23](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B23-bioengineering-12-00275)\] proposed skin disease recognition through the closed loop learning model with wide data acquisition from itself. Their study employed large datasets processed using LeNet-5, AlexNet, and VGG16, which proved to be quite efficient in identifying skin conditions. Kawahara et al. \[ [24](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B24-bioengineering-12-00275)\] proposed an architecture of a multi-resolution-tract convolutional neural network (CNN) with both pretrained and skin-lesion-trained layers. The combination of analysis for skin texture classification yielded higher accuracy as compared to the existing techniques of machine learning, thereby underlining the benefits of MTM in improving the classification rate of hybrid models. Ismael et al. \[ [25](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B25-bioengineering-12-00275)\] addressed an advanced deep learning technique for the classification of brain cancer MRI images using residual network, and information is available as the utility of deep learning techniques for classification of various types of skin diseases such as meningiomas, gliomas, and pituitary tumors. This is a testimony of how DL models are flexible when performing analysis of hologram medical images. Garnavi et al. \[ [26](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B26-bioengineering-12-00275)\] focused on thermal, surface, and dermoscopy images and formed the basis of border detection for dermoscopy images using hybrid thresholding on optimized color channels, intending to offer further automated border detection to aid diagnostic accuracy. It marks that their work belongs to the earlier studies of dataset collections and improves the accuracy of skin disease prediction. Chieregato et al. \[ [27](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B27-bioengineering-12-00275)\] proposed the use of a combination of machine learning and deep learning in predicting COVID-19 severity based on CT scans and patients’ clinical information, proving that AI-based models could be used to predict the outcomes from medical imaging data. Hence, this research paper supports the possible use of AI in diagnosing skin diseases as well as managing them, in conformation with the general enhancements in AI-based healthcare solutions.

Based on classification, convolutional neural networks (CNNs) have been widely applied in dermostoscopic image analysis (DIA) since 2015. Recent studies of computer vision and digital image processing have highlighted the importance of deep learning procedures in attaining precision in segmentation, detection, and classification, especially for challenging tasks. Codella et al. \[ [28](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B28-bioengineering-12-00275)\] have demonstrated the usefulness of deep residual networks and CNN models to distinguish malignant lesions, therefore exhibiting high performance in dermatological applications. Hybrid deep neural networks have also indicated potential in improving the performance of the diagnosis. Thomas et al. \[ [29](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B29-bioengineering-12-00275)\] proposed a deep learning architecture for skin lesion segmentation and classification which includes categorizing the tissues into 12 dermatologist classes. When applied to dermoscopy images, this framework established a computer-generated accuracy of 97% compared to the clinical method, which was 93.6%. Implementing a deep learning model with the incorporation of other standard models has been shown to enhance the results in classification. Amin et al. \[ [30](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B30-bioengineering-12-00275)\] proposed an integration approach for deep feature fusion that makes use of preprocessing, segmentation, and feature-extracting methodologies. To increase the efficiency of the segmentation process, they resize images, convert RGB to the luminance channel, and use Otsu and Biorthogonal 2D wavelet transform, etc. To overcome these problems, the authors used deep feature extraction techniques from the pretrained models of AlexNet and VGG16 and applied principal component analysis (PCA) for feature selection and reduced the dimensionality of the features with good classification accuracy. Masni et al. \[ [31](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B31-bioengineering-12-00275)\] designed a deep learning architecture which assimilates all these phases, with FRCN for segmentation and various classifiers such as Inception-v3, ResNet-50, or Inception-ResNet-v2 for classification. The high accuracy of their method was evident in the ISIC2016, ISIC2017, and ISIC2018 datasets, and the authors rightly noted the importance of integrated deep-learning models in dermatological applications. In another study, El-Khatib et al. \[ [32](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B32-bioengineering-12-00275)\] used the ResNet-101 model for skin lesion classification on the PH2 database, as they used fine-tuned CNN models with transfer learning to detect various types of skin lesions. This approach came to around 90% accuracy, which shows how useful it is to use a pretrained model for skin disease detection.

## 3\. Material and Methods

Initially, the dataset is collected, and subsequently the multiple preprocessing techniques like adaptive histogram equalization (AHI), binary cross-entropy with implicit averaging (BCEI), gamma correction, and contrast stretching are performed on the images. Subsequently, a deep-learning framework based on vision transformers (ViT) is applied to the preprocessed images. Finally, classification is performed.

The research encompasses a structured approach and brings out a sequence of specific procedures in analyzing images. The initial process comprises detailed image preprocessing, which is very important when it comes to enhancing the image quality and, hence, improving the accuracy. This is a very important step that includes removing noise from the images and resizing and normalizing the images and data for it to go through the various other analyses that are required. Lastly, as envisioned earlier, the vision transformer (ViT) classification model is used after the data preprocessing stage is completed. ViT is a novel paradigm shift in the analysis of images where the given transformer architectures operate on images as sequences of patches. This model is unique and notably so in terms of evaluating images from a perspective that isolates them through the identification of traits that make the images unique in relation to the rest of the images which aids in classifying the images. The steps followed for the given methodology are shown in [Figure 1](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-f001).

### Figure 1.

[![Figure 1](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/7481ab1a5551/bioengineering-12-00275-g001.jpg)](https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=11939559_bioengineering-12-00275-g001.jpg)

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/figure/bioengineering-12-00275-f001/)

Methodology diagram.

### 3.1. Dataset Description

This study employed two datasets: the skin disease image dataset \[ [33](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B33-bioengineering-12-00275)\] as well as HAM10000 \[ [34](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B34-bioengineering-12-00275)\] dataset, each serving specific purposes in classification in the domain of skin diseases. The dataset was dedicated to the classification problem and involved 10 significant dermatological diseases. Eczema, warts, molluscum and other viral infections, melanoma, atopic dermatitis, basal cell carcinoma, melanocytic nevi, benign keratosis-like lesions, psoriasis, lichen planus and related diseases, seborrheic keratoses, and tinea ringworm candidiasis are the skin diseases which differ by their intensity and importance.

These diseases are all important in the field of dermatology as well as the general healthcare field. Eczema, for instance, refers to a type of skin inflammation that is quite common and known to affect millions of people in different parts of the world, thus leading to a lot of discomfort and reduced quality of life. While basal cell carcinoma and squamous cell carcinoma are relatively non-threatening, melanoma is one of the most dangerous skin cancers, which underlines the problem of accurate classification to enhance diagnosis. Basal cell carcinoma is the most frequently occurring skin cancer and to some extent is less dangerous than melanoma; nevertheless, it is important for clinics and medical practices to be aware, as accurate diagnosis methods are needed. Furthermore, psoriasis and atopic dermatitis are types of skin diseases where patients have to live a long time with pain and a changed appearance of skin. Distribution of images across various skin disease classes are shown in [Table 1](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-t001).

#### Table 1.

Distribution of images across skin disease image dataset.

| Class | Sample Images | Number of Images |
| :-: | :-: | :-: |
| Eczema | ![graphic file with name bioengineering-12-00275-i001.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/e56d5df124b1/bioengineering-12-00275-i001.jpg) | 1677 |
| Warts Molluscum and Other Viral Infections | ![graphic file with name bioengineering-12-00275-i002.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/6252a84e9c33/bioengineering-12-00275-i002.jpg) | 2103 |
| Melanoma | ![graphic file with name bioengineering-12-00275-i003.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/f79687013dbe/bioengineering-12-00275-i003.jpg) | 3140 |
| Atopic Dermatitis | ![graphic file with name bioengineering-12-00275-i004.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/24cd94a66f7d/bioengineering-12-00275-i004.jpg) | 1257 |
| Basal Cell Carcinoma | ![graphic file with name bioengineering-12-00275-i005.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/b803c1f7759b/bioengineering-12-00275-i005.jpg) | 3323 |
| Melanocytic Nevi | ![graphic file with name bioengineering-12-00275-i006.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/0c15a11cc9a0/bioengineering-12-00275-i006.jpg) | 7970 |
| Benign Keratosis-like Lesions | ![graphic file with name bioengineering-12-00275-i007.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/d46a483425ce/bioengineering-12-00275-i007.jpg) | 2079 |
| Psoriasis, Lichen Planus and related diseases | ![graphic file with name bioengineering-12-00275-i008.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/06f20e4d41fd/bioengineering-12-00275-i008.jpg) | 2055 |
| Seborrheic Keratoses | ![graphic file with name bioengineering-12-00275-i009.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/21ebd70dd254/bioengineering-12-00275-i009.jpg) | 1847 |
| Tinea Ringworm Candidiasis | ![graphic file with name bioengineering-12-00275-i010.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/f2277bb0ac6b/bioengineering-12-00275-i010.jpg) | 1702 |

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/table/bioengineering-12-00275-t001/)

The work relied on the HAM10000 dataset to establish skin diseases, which are rich in numbers and kinds of images. This set of images includes a vast array of dermatological pathologies necessary for realistic object detection. The diseases identified in the HAM10000 dataset are actinic keratosis clinical (AKIEC), basal cell carcinoma (BCC), benign keratosis (BKL), dermatofibroma (DF), melanoma (MEL), melanocytic vevi (MN), and vascular malformations (VASC).

The diseases presented in the HAM10000 dataset are grouped into different categories, and each of them has its own challenges and things to consider in terms of diagnosis. The samples images from HAM10000 are shown in [Figure 2](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-f002). Actinic keratoses (AKIEC) are photocarcinomas resulting from acts of sun irradiation, which require identification from the early stages to prevent transition to carcinoma. Another study is needed on another type of frequent skin cancer, basal cell carcinoma (BCC), which has several subtypes with different clinical manifestations that demand correctly identifying algorithms. This article discovers that benign keratosis (BKL) and dermatofibroma (DF) are skin lesions that can mimic malignant skin lesions; therefore, a precise object detection method is crucial in differentiating benign and malignant skin lesions. As noted earlier, MEL is such a crucial object of detection concerns due to its invasive and metastasizing potential. Melanocytic nevi or common moles are benign growths but sometimes can very closely mimic melanoma and, therefore, needs more refined diagnostic approaches. Furthermore, vascular malformations (VASC) refer to common skin afflictions that must, therefore, be diagnosed correctly for appropriate treatment methods to be applied.

#### Figure 2.

[![Figure 2](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/17b0cf6c6a33/bioengineering-12-00275-g002.jpg)](https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=11939559_bioengineering-12-00275-g002.jpg)

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/figure/bioengineering-12-00275-f002/)

Sample images from HAM10000 dataset.

### 3.2. Image Preprocessing

The methodology employed in this study involved various techniques in the processing of image data so as to improve the quality and interpretability of skin disease images. It was possible to achieve that by choosing four techniques, the potential of which lies in enhancing the contrast, sharpness, and overall quality of the image. These techniques were selected for use in order to meet the task of correct picture recognition of various skin ailments while taking into account peculiarities and difficulties inherent in image dermatology.

The choice of these image processing techniques was guided by the fact that skin disease images required some preprocessing to enhance the features needed in the classification stage and object detection stages. The reason why adaptive histogram equalization has been chosen is the capacity to redistribute pixel intensities and the necessity to improve contrast in regional sections of images, which is essential when identifying various characteristics of skin lesions. Binary cross-entropy with implicit averaging (BCEI) was added as its enhanced version because of the inclusion of both brightness and contrast enhancement, making it a rounded method for normalizing the intensity values of images and enhancing the appearance of the images. Furthermore, the mechanism of gamma correction was added to define brightness and contrast so that visually appealing images that could be compatible with a variety of display devices that were possessed. Contrast stretching was the most appropriate to enhance the contrast and make images visually clear and interpretable; therefore, it has useful applications in medical diagnostics and research in skin diseases.

#### 3.2.1. Adaptive Histogram Equalization (AHE)

Adaptive histogram equalization that is also known as local histogram equalization aims at enhancing the contrast of an image with the help of redistributing pixel intensities. It uses the histogram equalization method and applies this to specific regions of an image so that the contrast adjustment is wise. This technique aims to improve the image resolution for improved computer usage for interpretation and analysis.

#### 3.2.2. Binary Cross-Entropy with Implicit Averaging (BCEI)

BCEI is another preprocessing technique that incorporates several brightness and contrast enhancement procedures to bring the intensity levels of an image to a similar range. It entails processes such as histogram regulation, and contrast expansion that help enhance the look of images. BCEI is also concerned with raising the standard of images to enable proper interpretation and analysis.

The implicit averaging of the data is calculated when we have noisy data in the image \[ [35](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B35-bioengineering-12-00275)\]. To denoise the image, implicit averaging \[ [36](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B36-bioengineering-12-00275)\] is utilized, and the improvement among the pixels is calculated using binary cross entropy to further optimize the noisy image. Binary cross entropy is measured using the given equation.

|     |
| --- |
| 𝐵⁢𝐶⁢𝐸=−1𝑁𝑁∑𝑖=1(𝑃𝑜⁢𝑟⁢𝑖⁢𝑔⋅𝑙⁢𝑜⁢𝑔⁡(𝑃𝑁⁢𝑒⁢𝑤)+(1−𝑃𝑜⁢𝑟⁢𝑖⁢𝑔)⋅𝑙⁢𝑜⁢𝑔⁡(1−𝑃𝑁⁢𝑒⁢𝑤)) |

Here, 𝑃o⁢r⁢i⁢g is the original pixel value, and 𝑃N⁢e⁢w represents the value after the implicit averaging, and 𝑁 is the total number of pixels in the image.

#### 3.2.3. Gamma Correction

Gamma correction is a process of brightness and contrast enhancement as an image processing technique to optimize the appearance of images and their suitability for use on any display hardware. Converting pixel values enhances visibility and accurate depiction on screens, which is useful in computer vision, graphical interfaces, and imaging.

#### 3.2.4. Contrast Stretching

Contrast stretching is a preprocessing technique that increases the span of subtle strength settings in an image, making hidden areas more visible and giving a better picture quality. This technique has applications in computer vision and remote sensing as well as in the medical field.

### 3.3. Classification

In the realm of image classification, this study utilized vision transformers as the deep-learning model for analyzing images which are newly developed, especially in the field of image processing. The term vision transformers refers to the model that applies to the transformer networks, which are efficient in realizing sequential data to image classification problems. While conventional CNNs feed images as two-dimensional grids of pixels, vision transformers feed images as sequences of fixed-region patches. As for the differences between the discussed vision transformers and the classic CNN models, the latter take pixel grids of the images as input or feed, while the former works with patches. This capability allows the network to establish long-range connections within the image to improve the performance of various image classification tasks. The framework of vision transformers is shown in [Figure 3](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-f003).

#### Figure 3.

[![Figure 3](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/14de55daf5c4/bioengineering-12-00275-g003.jpg)](https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=11939559_bioengineering-12-00275-g003.jpg)

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/figure/bioengineering-12-00275-f003/)

Framework of vision transformers.

The selection of vision transformers was informed by the results, proving the efficacy of the models in various image classification undertakings such as the ILSVRC or ImageNet. Also, it is important in object and scene analysis and therefore makes it a suitable algorithm for different forms of image classification. Moreover, several advantages can be derived from using vision transformers in comparison to the usual deep-learning frameworks; training them with limited data samples is quite possible, and it can accept input images of any dimension possible without the need to crop or resize the input image by hand options, which are quite common in practical applications.

In this work, the vision transformer model under study operates as it detects patches of images instead of CNN architectures. Each patch is flattened into a linear embedding, on which these learnable feature vectors are dropped through a transformer for prediction. The extracted patches are transformed and fed into the model by permutations without the loss of information, and, in the classification, the phase aids the model to capture the long-range dependency and context.

Unlike traditional computer vision models that work directly on images, in-vision transformer images are split into patches and then fed through the transformer architecture that incorporates attention layers, which opens up new possibilities of how images can be processed. Such architectural design starts with the subdivision of the input image into small regions called grid cells. In this approach, each patch is then represented as a vector. The transformation process involves several steps outlined along with equations.

#### 3.3.1. Patch Embeddings

Initially, the image is divided among the fixed size patches. In our case, the patch size was set to 16. The patch is then flattened into a 1D vector, which for an RGB image will result in a 768-dimensional vector. Every patch which is flattened is linearly embedded into the vector. Positional embeddings are further added with each patch.

Each patch xi is flattened into a vector 𝑥𝑖𝐸. These flattened patches are then projected through an embedding matrix F to produce a linear patch projection, which represents the projection dimension. This can be represented as

|     |
| --- |
| 𝑧0=\[𝐼c⁢l⁢a⁢s⁢s;𝑥𝐸1;𝑥𝐸2;…;𝑥𝐸𝑛+𝐸p⁢o⁢s\] |

Here, 𝐸p⁢o⁢s is the learnable class embedding, and 𝐼c⁢l⁢a⁢s⁢s represents the class tokens concatenated with the patch embeddings.

#### 3.3.2. Transformer Encoder

These patch embeddings are then passed into a model called ‘transformer encoder’, which contains as the key components what is also known as multi-headed self-attention (MSA) that consists of multiple linear self-attention/linear projection blocks and multi-layer perceptron (MLP) blocks. Self-attention could allow residual skip connections to be added in conduit through layer normalization (LN) after each transformer encoder block. The operations of MSA and MLP blocks can be expressed as expressions of the MSA and MLP block operations:

|     |
| --- |
| 𝑧′𝑙=M⁢S⁢A⁢(L⁢N⁡(𝑧𝑙−1)+𝑧𝑙−1) |

|     |
| --- |
| 𝑧𝑙=M⁢L⁢P⁢(L⁢N⁡(𝑧′𝑙)+𝑧′𝑙) |

#### 3.3.3. Self-Attention Mechanism

The MSA block computes attention weights using queries 𝑄 keys, and values 𝑉 matrices obtained from the input vectors. The attention matrix SA is calculated as

|     |
| --- |
| S⁢A=S⁢o⁢f⁡t⁢m⁢a⁢x⁢(𝑄⁢𝐾𝑇⋅√𝑑𝑘)⋅𝑉=A⁢t⁢t⁢e⁢n⁢t⁢i⁢o⁢n⋅𝑉 |

The dot product attention is scaled by √{𝑑𝑘} to accommodate the dimension of the keys. The scaled dot product attention is then passed through the SoftMax function to compute attention weights.

#### 3.3.4. Multi-Head Attention (MHA)

The MSA block combines results from multiple attention heads and applies a feed-forward layer with learnable weights 𝑊0 to generate the final output:

|     |
| --- |
| M⁢H⁡A=C⁢o⁢n⁢c⁢a⁢t⁡(𝑆⁢𝐴1,𝑆⁢𝐴2,𝑆⁢𝐴3,…,𝑆⁢𝐴ℎ)⋅𝑊0 |

Each attention head produces an attention matrix, and the concatenated results are fed into the feed-forward layer with weights 𝑊0. A total of 16 heads are applied.

#### 3.3.5. Output Logits

The final output from the transformer encoder, denoted as 𝑍𝐿, is fed into an external linear classifier to predict class labels for image classification.

During training, the stochastic gradient is used as an optimizer, weighted categorical cross entropy is applied as a loss function, and dropout rate remains 0.2. During training, the batch is set to 32, and the learning rate remains 0.001.

## 4\. Results and Discussion

For evaluating the preprocessing results, we have used two performance measures: mean squared error (MSE) as well as peak-signal-to-noise-ratio (PSNR). The MSE represents the squared cumulative error between the original and improved images. The quality of a picture improves when the MSE value is low. PSNR is used to compare the quality of two images: the original and the reconstructed picture. The higher the PSNR, the greater the quality of the reconstructed image. Similarly, for the classification performance, we have accessed accuracy as well as recall. Accuracy is a reliable assessment criterion for classification issues if the data are equally distributed, not skewed, and there is no class imbalance. In general, accuracy might produce too optimistic results, particularly on imbalanced datasets. Recall assesses the ability to discern across classes.

### 4.1. Preprocessing Results

The sequence of applying the preprocessing techniques is shown in [Figure 4](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-f004). Initially, we applied the AHE and obtained the resultant image. That image was then passed to the BCEI; afterwards, gamma correction was applied to the image, and finally contrast stretching was performed. The numerical result of each technique is shown in [Table 2](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-t002). We can see that after the image is passed through the techniques, the value of PSNR increases, and the values of MSE start decreasing, which shows that the quality of the image became better after each step.

#### Figure 4.

[![Figure 4](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/cfe2d31de2a3/bioengineering-12-00275-g004.jpg)](https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=11939559_bioengineering-12-00275-g004.jpg)

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/figure/bioengineering-12-00275-f004/)

Preprocessing steps sequence.

#### Table 2.

Numerical results of contrast enhancement.

| Performance Measure | AHE | BCEI | Gamma Correction | Contrast Stretching |
| :-: | :-: | :-: | :-: | :-: |
| PSNR | 0.3205 | 0.4987 | 0.7044 | 0.8136 |
| MSE | 362.87 | 281.32 | 199.20 | 110.31 |

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/table/bioengineering-12-00275-t002/)

Initially, upon applying the AHE, the value of PSNR was 0.3205, which was not very bad, but the value of MSE 362.87 was large. After applying the BCEI, the value of PSNR became better, and the MSE reduced. After applying the final contrast stretching on the image, it was evident that the value of PSNR became 0.8136, which was far better and shows that the quality of the image became much better as compared to the original one, which was also proved by the lower MSE value.

### 4.2. Classification Results

The preprocessing images were then passed through vision transformers, and the classification results in the form of accuracy and recall were collected using various train-to-test ratios and across different steps of the methodology. The proposed model was trained on 150 epochs, and the loss function was a stochastic gradient with a learning rate of 0.001. The model was trained in Jupyter Notebook 2.7 with Python 3.13.1 libraries. Tensorflow 2.18, Keras 3.0, Numpy 2.2.0, and Matplotlib 3.10.0 are the major libraries used for performing experimentations.

The results were collected on various train-to-test ratios for the skin disease classification dataset, shown in [Table 3](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-t003). It is evident while looking at the table that the best results are achieved using a 70/30 train-to-test ratio. It can be seen that performance on a 90/10 train-to-test ratio is less, because the model gets overfitted and stop properly generalizing, and there is another reason that the model is tested on less data, which might be the reason as well. On a 50/50 ratio, the model performance also deteriorates, because the model starts underfitting and is not completely learned. Although the results are up to the marks, they are less, because the dataset is highly imbalanced, and no augmentation was performed to balance it as well as no extra steps for it were performed. If augmentation can be performed as well as other regularization techniques, if applied, the results might increase. The accuracy throughout the training process is shown in [Figure 5](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-f005). By analyzing the figure, we can assess that, mostly, the graph of accuracy was rising throughout the training process, but for the 70/30 ratio, the sudden jump in the accuracy was seen after the 70th epoch, after which the model generalized better afterwards.

#### Table 3.

Classification performance on various train/test ratios for skin disease classification dataset.

| Train-to-Test Ratio | Recall | Accuracy | Precision | F1-Score |
| :-: | :-: | :-: | :-: | :-: |
| 90/10 | 81.26% | 82.13% | 83.44% | 82.34% |
| 80/20 | 85.82% | 87.10% | 87.29% | 86.55% |
| 70/30 | 89.11% | 91.64% | 93.01% | 91.02% |
| 60/40 | 84.73% | 84.21% | 86.33% | 85.52% |
| 50/50 | 80.41% | 81.66% | 82.55% | 81.47% |

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/table/bioengineering-12-00275-t003/)

#### Figure 5.

[![Figure 5](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/4cae1cb11b43/bioengineering-12-00275-g005.jpg)](https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=11939559_bioengineering-12-00275-g005.jpg)

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/figure/bioengineering-12-00275-f005/)

Accuracy during the training process on skin disease classification dataset.

The results are collected on various train-to-test ratios for the HAM10000 dataset, shown in [Table 4](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-t004). The results on the given dataset are better than the previous one. It is evident while looking at the table that, on this dataset, the best results are also achieved using a 70/30 train-to-test ratio. It can be seen that, again, the performance on a 90/10 train-to-test ratio is less, because the model gets overfitted and stops properly generalizing, and there is another reason that the model is tested on less data, which might be the reason as well. Again, on a 50/50 ratio, the model performance also deteriorates, because the model starts underfitting and is not completely learned. The accuracy throughout the training process is shown in [Figure 6](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-f006). By analyzing the figure, we can assess that mostly the graph of accuracy was rising throughout the training process, but for the 60/40 and 80/20, a sudden fall in the accuracies is observed in middle epochs and then raised above.

#### Table 4.

Classification performance on various train/test ratios for HAM10000 dataset.

| Train-to-Test Ratio | Recall | Accuracy | Precision | F1-Score |
| :-: | :-: | :-: | :-: | :-: |
| 90/10 | 82.26% | 84.93% | 85.12% | 83.67% |
| 80/20 | 86.19% | 89.02% | 90.23% | 88.16% |
| 70/30 | 94.44% | 95.20% | 96.87% | 95.64% |
| 60/40 | 84.02% | 87.36% | 87.96% | 85.95% |
| 50/50 | 80.50% | 82.71% | 84.01% | 82.22% |

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/table/bioengineering-12-00275-t004/)

#### Figure 6.

[![Figure 6](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/03555106f6b3/bioengineering-12-00275-g006.jpg)](https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=11939559_bioengineering-12-00275-g006.jpg)

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/figure/bioengineering-12-00275-f006/)

Accuracy during the training process on HAM10000 dataset.

As we know, the best performance on both datasets was achieved in a 70/30 train-to-test ratio; therefore, we consider it a model. Finally, the results collected before and after preprocessing were gathered to compare the classification performance and analyze the importance of the preprocessing steps. The results are shown in [Table 5](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-t005); these results are collected on 70/30 train-to-test ratios. It is evident that, after the preprocessing part, both the accuracy and recall rate jumped over 8%, compared with the dataset without preprocessing, which shows the importance of the step. Moreover, we have seen that the accuracy jumped by a definite proportion for each preprocessing step. A greater jump in accuracy is observed when BCEI is applied to the dataset after AHE. Furthermore, in the last preprocessing step where we have applied contrast stretching, the accuracy jump is also significant.

#### Table 5.

Classification performance comparison.

| Dataset | Steps | Recall | Accuracy |
| :-: | :-: | :-: | :-: |
| Skin Disease Classification Dataset | Initial Input Dataset (Without Preprocessing) | 75.18% | 76.20% |
| After Processing the Dataset by Applying only AHE | 78.32% | 79.64% |
| After Processing the Dataset by Applying AHE and BCEI | 84.43% | 85.01% |
| After Processing the Dataset by Applying AHE, BCEI, and Gamma Correction | 86.71% | 87.55% |
| After Complete Preprocessing | 89.11% | 91.64% |
| HAM10000 Dataset | Initial Input Dataset (Without Preprocessing) | 86.28% | 86.98% |
| After Processing the Dataset by Applying only AHE | 87.33% | 87.55% |
| After Processing the Dataset by Applying AHE and BCEI | 90.20% | 91.98% |
| After Processing the Dataset by Applying AHE, BCEI, and Gamma Correction | 92.61% | 93.04% |
| After Complete Preprocessing | 94.44% | 95.20% |

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/table/bioengineering-12-00275-t005/)

For the explanation of the model, predictions are interpreted using the lime framework. The lime framework is used in the research as a technique to explain the model predictions for clinical interpretation \[ [37](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B37-bioengineering-12-00275)\]. [Figure 7](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-f007) explains the predictions of the model using lime.

#### Figure 7.

[![Figure 7](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2b55/11939559/3656ff18972b/bioengineering-12-00275-g007.jpg)](https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=11939559_bioengineering-12-00275-g007.jpg)

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/figure/bioengineering-12-00275-f007/)

Proposed model explanations using lime.

Finally, we compared our proposed approach with the state-of-the art model, as shown in [Table 6](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#bioengineering-12-00275-t006).

#### Table 6.

Performance comparison.

| Reference | Model | Accuracy |
| :-: | :-: | :-: |
| \[ [38](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B38-bioengineering-12-00275)\] | CNN | 92.9% |
| \[ [39](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B39-bioengineering-12-00275)\] | AlexNet | 93.3% |
| \[ [40](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B40-bioengineering-12-00275)\] | Deep CNN | 90.42% |
| \[ [41](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B41-bioengineering-12-00275)\] | ResNet and SVM | 94.5% |
| \[ [42](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B42-bioengineering-12-00275)\] | Inception | 82.8% |
| \[ [43](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/#B43-bioengineering-12-00275)\] | Vision Transformer | 93.8% |
| Proposed Model | 95.20% |

[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/table/bioengineering-12-00275-t006/)

## 5\. Conclusions

The research process in this study focuses on a framework for skin disease classification. The idea behind the foundation of the framework originated from the realization that the existing systems are, though efficient and precise, not very versatile, especially in terms of the number of diseases that the system can identify. This research, therefore, sought to address this gap using advanced image processing techniques with specific reference to vision transformers. Based on the presented results, it is concluded that each preprocessing technique significantly improves the classification performance. In the future, the postprocessing techniques on the classification results may be applied to evaluate the impact.

## Author Contributions

Conceptualization, M.N.N. and F.H.; methodology, M.N.N. and F.H.; validation, I.A. and M.M.; formal analysis, I.A. and M.M.; investigation, M.M.; resources, I.A.; data curation, I.A., F.H. and M.M.; writing—original draft preparation, M.N.N.; writing—review and editing, I.A. and M.M.; visualization, F.H.; supervision, M.N.N.; software, M.N.N. and F.H. All authors have read and agreed to the published version of the manuscript.

## Institutional Review Board Statement

Not applicable, as research was conducted on publicly available dataset.

## Informed Consent Statement

Not applicable.

## Data Availability Statement

The original contributions presented in the study are included in the article; further inquiries can be directed to the corresponding author.

## Conflicts of Interest

The authors declare no conflicts of interest.

## Funding Statement

This research received no external funding.

## Footnotes

**Disclaimer/Publisher’s Note:** The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.

## References

- 1.Gulzar M.A., Iqbal S., Jamil A., Hameed A.A., Soleimani F. Intelligent Data Analytics for Bioinformatics and Biomedical Systems. Wiley; Hoboken, NJ, USA: 2024. Skin Disease Detection and Classification; pp. 67–92. \[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Intelligent%20Data%20Analytics%20for%20Bioinformatics%20and%20Biomedical%20Systems&author=M.A.%20Gulzar&author=S.%20Iqbal&author=A.%20Jamil&author=A.A.%20Hameed&author=F.%20Soleimani&publication_year=2024&)\]
- 2.Li Q., Patrick M.T., Sreeskandarajan S., Kang J., Kahlenberg J.M., Gudjonsson J.E., He Z., Tsoi L.C. Large-scale epidemiological analysis of common skin diseases to identify shared and unique comorbidities and demographic factors. Front. Immunol. 2024;14:1309549. doi: 10.3389/fimmu.2023.1309549. \[ [DOI](https://doi.org/10.3389/fimmu.2023.1309549)\] \[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10800546/)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/38259463/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Front.%20Immunol.&title=Large-scale%20epidemiological%20analysis%20of%20common%20skin%20diseases%20to%20identify%20shared%20and%20unique%20comorbidities%20and%20demographic%20factors&author=Q.%20Li&author=M.T.%20Patrick&author=S.%20Sreeskandarajan&author=J.%20Kang&author=J.M.%20Kahlenberg&volume=14&publication_year=2024&pages=1309549&pmid=38259463&doi=10.3389/fimmu.2023.1309549&)\]
- 3.Aboulmira A., Hamid H., Mohamed L. Skin Diseases Classification with Machine Learning and Deep Learning Techniques: A Systematic Review. Int. J. Adv. Comput. Sci. Appl. 2024;15:1155. doi: 10.14569/IJACSA.2024.01510118. \[ [DOI](https://doi.org/10.14569/IJACSA.2024.01510118)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Int.%20J.%20Adv.%20Comput.%20Sci.%20Appl.&title=Skin%20Diseases%20Classification%20with%20Machine%20Learning%20and%20Deep%20Learning%20Techniques:%20A%20Systematic%20Review&author=A.%20Aboulmira&author=H.%20Hamid&author=L.%20Mohamed&volume=15&publication_year=2024&pages=1155&doi=10.14569/IJACSA.2024.01510118&)\]
- 4.Pulsipher K.J., Szeto M.D., Rundle C.W., Presley C.L., Laughter M.R., Dellavalle R.P. Global Burden of Skin Disease Representation in the Literature: Bibliometric Analysis. JMIR Dermatol. 2021;4:e29282. doi: 10.2196/29282. \[ [DOI](https://doi.org/10.2196/29282)\] \[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10334954/)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/37632830/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=JMIR%20Dermatol.&title=Global%20Burden%20of%20Skin%20Disease%20Representation%20in%20the%20Literature:%20Bibliometric%20Analysis&author=K.J.%20Pulsipher&author=M.D.%20Szeto&author=C.W.%20Rundle&author=C.L.%20Presley&author=M.R.%20Laughter&volume=4&publication_year=2021&pages=e29282&pmid=37632830&doi=10.2196/29282&)\]
- 5.Carr S., Smith C., Wernberg J. Epidemiology and Risk Factors of Melanoma. Surg. Clin. 2020;100:1–12. doi: 10.1016/j.suc.2019.09.005. \[ [DOI](https://doi.org/10.1016/j.suc.2019.09.005)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/31753105/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Surg.%20Clin.&title=Epidemiology%20and%20Risk%20Factors%20of%20Melanoma&author=S.%20Carr&author=C.%20Smith&author=J.%20Wernberg&volume=100&publication_year=2020&pages=1-12&pmid=31753105&doi=10.1016/j.suc.2019.09.005&)\]
- 6.Karimkhani C., Dellavalle R.P., Coffeng L.E., Flohr C., Hay R.J., Langan S.M., Nsoesie E.O., Ferrari A.J., Erskine H.E., Silverberg J.I., et al. Global Skin Disease Morbidity and Mortality: An Update From the Global Burden of Disease Study 2013. JAMA Dermatol. 2017;153:406–412. doi: 10.1001/jamadermatol.2016.5538. \[ [DOI](https://doi.org/10.1001/jamadermatol.2016.5538)\] \[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC5817488/)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/28249066/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=JAMA%20Dermatol.&title=Global%20Skin%20Disease%20Morbidity%20and%20Mortality:%20An%20Update%20From%20the%20Global%20Burden%20of%20Disease%20Study%202013&author=C.%20Karimkhani&author=R.P.%20Dellavalle&author=L.E.%20Coffeng&author=C.%20Flohr&author=R.J.%20Hay&volume=153&publication_year=2017&pages=406-412&pmid=28249066&doi=10.1001/jamadermatol.2016.5538&)\]
- 7.Yadav R., Aruna B. A systematic literature survey on skin disease detection and classification using machine learning and deep learning. Multimed. Tools Appl. 2024;83:78093–78124. doi: 10.1007/s11042-024-18119-w. \[ [DOI](https://doi.org/10.1007/s11042-024-18119-w)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Multimed.%20Tools%20Appl.&title=A%20systematic%20literature%20survey%20on%20skin%20disease%20detection%20and%20classification%20using%20machine%20learning%20and%20deep%20learning&author=R.%20Yadav&author=B.%20Aruna&volume=83&publication_year=2024&pages=78093-78124&doi=10.1007/s11042-024-18119-w&)\]
- 8.Dip S.A., Arif K.H.I., Shuvo U.A., Khan I.A., Meng N. Equitable Skin Disease Prediction Using Transfer Learning and Domain Adaptation; Proceedings of the AAAI Symposium Series; Arlington, Virginia. 7–9 November 2024; pp. 259–266. \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%20AAAI%20Symposium%20Series&title=Equitable%20Skin%20Disease%20Prediction%20Using%20Transfer%20Learning%20and%20Domain%20Adaptation&author=S.A.%20Dip&author=K.H.I.%20Arif&author=U.A.%20Shuvo&author=I.A.%20Khan&author=N.%20Meng&volume=Volume%204&pages=259-266&)\]
- 9.Fuqua T. Essentials of Human Diseases and Conditions-E-Book: Essentials of Human Diseases and Conditions-E-Book. Elsevier Health Sciences; Amsterdam, The Netherlands: 2024.  \[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Essentials%20of%20Human%20Diseases%20and%20Conditions-E-Book:%20Essentials%20of%20Human%20Diseases%20and%20Conditions-E-Book&author=T.%20Fuqua&publication_year=2024&)\]
- 10.Brown M., Williams A., Chilcott R.P., Brady B., Lenn J., Evans C., Allen L., McAuley W.J., Beebeejaun M., Haslinger J., et al. Topically applied therapies for the treatment of skin disease: Past, present, and future. Pharmacol. Rev. 2024;76:689–790. doi: 10.1124/pharmrev.123.000549. \[ [DOI](https://doi.org/10.1124/pharmrev.123.000549)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/38914467/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Pharmacol.%20Rev.&title=Topically%20applied%20therapies%20for%20the%20treatment%20of%20skin%20disease:%20Past,%20present,%20and%20future&author=M.%20Brown&author=A.%20Williams&author=R.P.%20Chilcott&author=B.%20Brady&author=J.%20Lenn&volume=76&publication_year=2024&pages=689-790&pmid=38914467&doi=10.1124/pharmrev.123.000549&)\]
- 11.Jaworek A.K., Pełka K., Kozicka K., Kaleta K., Suchy W., Wójkowska-Mach J., Wojas-Pelc A. Current challenges in diagnosing and treating infectious skin diseases—A case series. Przegląd Epidemiol. 2024;78:27–43. doi: 10.32394/pe.77.47. \[ [DOI](https://doi.org/10.32394/pe.77.47)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/38904310/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Przegl%C4%85d%20Epidemiol.&title=Current%20challenges%20in%20diagnosing%20and%20treating%20infectious%20skin%20diseases%E2%80%94A%20case%20series&author=A.K.%20Jaworek&author=K.%20Pe%C5%82ka&author=K.%20Kozicka&author=K.%20Kaleta&author=W.%20Suchy&volume=78&publication_year=2024&pages=27-43&pmid=38904310&doi=10.32394/pe.77.47&)\]
- 12.Sreekala K., Rajkumar N., Sugumar R., Sagar K.D., Shobarani R., Krishnamoorthy K.P., Saini A.K., Palivela H., Yeshitla A. Skin Diseases Classification Using Hybrid AI Based Localization Approach. Comput. Intell. Neurosci. 2022;2022:6138490. doi: 10.1155/2022/6138490. \[ [DOI](https://doi.org/10.1155/2022/6138490)\] \[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC9444379/)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/36072725/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Comput.%20Intell.%20Neurosci.&title=Skin%20Diseases%20Classification%20Using%20Hybrid%20AI%20Based%20Localization%20Approach&author=K.%20Sreekala&author=N.%20Rajkumar&author=R.%20Sugumar&author=K.D.%20Sagar&author=R.%20Shobarani&volume=2022&publication_year=2022&pages=6138490&pmid=36072725&doi=10.1155/2022/6138490&)\]
- 13.Hemanth D.J., Deperlioglu O., Kose U. An enhanced diabetic retinopathy detection and classification approach using deep convolutional neural network. Neural Comput. Appl. 2019;32:707–721. doi: 10.1007/s00521-018-03974-0. \[ [DOI](https://doi.org/10.1007/s00521-018-03974-0)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Neural%20Comput.%20Appl.&title=An%20enhanced%20diabetic%20retinopathy%20detection%20and%20classification%20approach%20using%20deep%20convolutional%20neural%20network&author=D.J.%20Hemanth&author=O.%20Deperlioglu&author=U.%20Kose&volume=32&publication_year=2019&pages=707-721&doi=10.1007/s00521-018-03974-0&)\]
- 14.Zhang J., Zhong F., He K., Ji M., Li S., Li C. Recent Advancements and Perspectives in the Diagnosis of Skin Diseases Using Machine Learning and Deep Learning: A Review. Diagnostics. 2023;13:3506. doi: 10.3390/diagnostics13233506. \[ [DOI](https://doi.org/10.3390/diagnostics13233506)\] \[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10706240/)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/38066747/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Diagnostics&title=Recent%20Advancements%20and%20Perspectives%20in%20the%20Diagnosis%20of%20Skin%20Diseases%20Using%20Machine%20Learning%20and%20Deep%20Learning:%20A%20Review&author=J.%20Zhang&author=F.%20Zhong&author=K.%20He&author=M.%20Ji&author=S.%20Li&volume=13&publication_year=2023&pages=3506&pmid=38066747&doi=10.3390/diagnostics13233506&)\]
- 15.Rodrigues M., Ezzedine K., Hamzavi I., Pandya A.G., Harris J.E., Vitiligo Working Group New discoveries in the pathogenesis and classification of vitiligo. J. Am. Acad. Dermatol. 2017;77:1–13. doi: 10.1016/j.jaad.2016.10.048. \[ [DOI](https://doi.org/10.1016/j.jaad.2016.10.048)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/28619550/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=J.%20Am.%20Acad.%20Dermatol.&title=New%20discoveries%20in%20the%20pathogenesis%20and%20classification%20of%20vitiligo&author=M.%20Rodrigues&author=K.%20Ezzedine&author=I.%20Hamzavi&author=A.G.%20Pandya&author=J.E.%20Harris&volume=77&publication_year=2017&pages=1-13&pmid=28619550&doi=10.1016/j.jaad.2016.10.048&)\]
- 16.Singh M. Cytokines: The yin and yang of vitiligo pathogenesis. Expert Rev. Clin. Immunol. 2019;15:177–188. doi: 10.1080/1744666X.2019.1550358. \[ [DOI](https://doi.org/10.1080/1744666X.2019.1550358)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/30462555/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Expert%20Rev.%20Clin.%20Immunol.&title=Cytokines:%20The%20yin%20and%20yang%20of%20vitiligo%20pathogenesis&author=M.%20Singh&volume=15&publication_year=2019&pages=177-188&pmid=30462555&doi=10.1080/1744666X.2019.1550358&)\]
- 17.Nouman Noor M., Nazir M., Khan S.A., Song O.-Y., Ashraf I. Efficient Gastrointestinal Disease Classification Using Pretrained Deep Convolutional Neural Network. Electronics. 2023;12:1557. doi: 10.3390/electronics12071557. \[ [DOI](https://doi.org/10.3390/electronics12071557)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Electronics&title=Efficient%20Gastrointestinal%20Disease%20Classification%20Using%20Pretrained%20Deep%20Convolutional%20Neural%20Network&author=M.%20Nouman%20Noor&author=M.%20Nazir&author=S.A.%20Khan&author=O.-Y.%20Song&author=I.%20Ashraf&volume=12&publication_year=2023&pages=1557&doi=10.3390/electronics12071557&)\]
- 18.Alhajlah M., Noor M.N., Nazir M., Mahmood A., Ashraf I., Karamat T. Gastrointestinal diseases classification using deep transfer learning and features optimization. Comput. Mater. Contin. 2023;75:2227–2245. doi: 10.32604/cmc.2023.031890. \[ [DOI](https://doi.org/10.32604/cmc.2023.031890)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Comput.%20Mater.%20Contin&title=Gastrointestinal%20diseases%20classification%20using%20deep%20transfer%20learning%20and%20features%20optimization&author=M.%20Alhajlah&author=M.N.%20Noor&author=M.%20Nazir&author=A.%20Mahmood&author=I.%20Ashraf&volume=75&publication_year=2023&pages=2227-2245&doi=10.32604/cmc.2023.031890&)\]
- 19.Noor M.N., Nazir M., Ashraf I., Almujally N.A., Aslam M., Fizzah Jilani S. GastroNet: A robust attention-based deep learning and cosine similarity feature selection framework for gastrointestinal disease classification from endoscopic images. CAAI Trans. Intell. Technol. 2023:1–14. doi: 10.1049/cit2.12231. \[ [DOI](https://doi.org/10.1049/cit2.12231)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=CAAI%20Trans.%20Intell.%20Technol.&title=GastroNet:%20A%20robust%20attention-based%20deep%20learning%20and%20cosine%20similarity%20feature%20selection%20framework%20for%20gastrointestinal%20disease%20classification%20from%20endoscopic%20images&author=M.N.%20Noor&author=M.%20Nazir&author=I.%20Ashraf&author=N.A.%20Almujally&author=M.%20Aslam&publication_year=2023&pages=1-14&doi=10.1049/cit2.12231&)\]
- 20.Nouman Noor M., Nazir M., Khan S.A., Ashraf I., Song O.Y. Localization and classification of gastrointestinal tract disorders using explainable AI from endoscopic images. Appl. Sci. 2023;13:9031. doi: 10.3390/app13159031. \[ [DOI](https://doi.org/10.3390/app13159031)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Appl.%20Sci.&title=Localization%20and%20classification%20of%20gastrointestinal%20tract%20disorders%20using%20explainable%20AI%20from%20endoscopic%20images&author=M.%20Nouman%20Noor&author=M.%20Nazir&author=S.A.%20Khan&author=I.%20Ashraf&author=O.Y.%20Song&volume=13&publication_year=2023&pages=9031&doi=10.3390/app13159031&)\]
- 21.Noor M.N., Nazir M., Rehman S., Tariq J. Sketch-recognition using pre-trained model; Proceedings of the National Conference on Engineering and Computing Technology; Islamabad, Pakistan. 8 January 2021. \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%20National%20Conference%20on%20Engineering%20and%20Computing%20Technology&title=Sketch-recognition%20using%20pre-trained%20model&author=M.N.%20Noor&author=M.%20Nazir&author=S.%20Rehman&author=J.%20Tariq&)\]
- 22.Du-Harpur X., Watt F.M., Luscombe N.M., Lynch M.D. What is AI? Applications of artificial intelligence to dermatology. Br. J. Dermatol. 2020;183:423–430. doi: 10.1111/bjd.18880. \[ [DOI](https://doi.org/10.1111/bjd.18880)\] \[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC7497072/)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/31960407/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Br.%20J.%20Dermatol.&title=What%20is%20AI?%20Applications%20of%20artificial%20intelligence%20to%20dermatology&author=X.%20Du-Harpur&author=F.M.%20Watt&author=N.M.%20Luscombe&author=M.D.%20Lynch&volume=183&publication_year=2020&pages=423-430&pmid=31960407&doi=10.1111/bjd.18880&)\]
- 23.Chen M., Zhou P., Wu D., Hu L., Hassan M.M., Alamri A. AI-Skin: Skin disease recognition based on self-learning and wide data collection through a closed-loop framework. Inf. Fusion. 2020;54:1–9. doi: 10.1016/j.inffus.2019.06.005. \[ [DOI](https://doi.org/10.1016/j.inffus.2019.06.005)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Inf.%20Fusion&title=AI-Skin:%20Skin%20disease%20recognition%20based%20on%20self-learning%20and%20wide%20data%20collection%20through%20a%20closed-loop%20framework&author=M.%20Chen&author=P.%20Zhou&author=D.%20Wu&author=L.%20Hu&author=M.M.%20Hassan&volume=54&publication_year=2020&pages=1-9&doi=10.1016/j.inffus.2019.06.005&)\]
- 24.Kawahara J., Hamarneh G. Multi-Resolution-Tract CNN with Hybrid Pretrained and Skin-Lesion Trained Layers. Springer Nature; Berlin/Heidelberg, Germany: 2016.  \[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Multi-Resolution-Tract%20CNN%20with%20Hybrid%20Pretrained%20and%20Skin-Lesion%20Trained%20Layers&author=J.%20Kawahara&author=G.%20Hamarneh&publication_year=2016&)\]
- 25.Ismael S.A.A., Mohammed A., Hefny H. An enhanced deep learning approach for brain cancer MRI images classification using residual networks. Artif. Intell. Med. 2020;102:101779. doi: 10.1016/j.artmed.2019.101779. \[ [DOI](https://doi.org/10.1016/j.artmed.2019.101779)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/31980109/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Artif.%20Intell.%20Med.&title=An%20enhanced%20deep%20learning%20approach%20for%20brain%20cancer%20MRI%20images%20classification%20using%20residual%20networks&author=S.A.A.%20Ismael&author=A.%20Mohammed&author=H.%20Hefny&volume=102&publication_year=2020&pages=101779&pmid=31980109&doi=10.1016/j.artmed.2019.101779&)\]
- 26.Garnavi R., Aldeen M., Celebi M.E., Varigos G., Finch S. Border detection in dermoscopy images using hybrid thresholding on optimized color channels. Comput. Med. Imaging Graph. Off. J. Comput. Med. Imaging Soc. 2021;35:105–115. doi: 10.1016/j.compmedimag.2010.08.001. \[ [DOI](https://doi.org/10.1016/j.compmedimag.2010.08.001)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/20832992/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Comput.%20Med.%20Imaging%20Graph.%20Off.%20J.%20Comput.%20Med.%20Imaging%20Soc.&title=Border%20detection%20in%20dermoscopy%20images%20using%20hybrid%20thresholding%20on%20optimized%20color%20channels&author=R.%20Garnavi&author=M.%20Aldeen&author=M.E.%20Celebi&author=G.%20Varigos&author=S.%20Finch&volume=35&publication_year=2021&pages=105-115&pmid=20832992&doi=10.1016/j.compmedimag.2010.08.001&)\]
- 27.Chieregato M., Frangiamore F., Morassi M., Baresi C., Nici S., Bassetti C., Bnà C., Galelli M. A hybrid machine learning/deep learning COVID-19 severity predictive model from CT images and clinical data. Sci. Rep. 2022;12:4329. doi: 10.1038/s41598-022-07890-1. \[ [DOI](https://doi.org/10.1038/s41598-022-07890-1)\] \[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC8919158/)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/35288579/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Sci.%20Rep.&title=A%20hybrid%20machine%20learning/deep%20learning%20COVID-19%20severity%20predictive%20model%20from%20CT%20images%20and%20clinical%20data&author=M.%20Chieregato&author=F.%20Frangiamore&author=M.%20Morassi&author=C.%20Baresi&author=S.%20Nici&volume=12&publication_year=2022&pages=4329&pmid=35288579&doi=10.1038/s41598-022-07890-1&)\]
- 28.Codella N.C., Nguyen Q.B., Pankanti S., Gutman D.A., Helba B., Halpern A.C., Smith J.R. Deep learning ensembles for melanoma recognition in dermoscopy images. IEEE Xplore. 2017;61:5:1–5:15. doi: 10.1147/JRD.2017.2708299. \[ [DOI](https://doi.org/10.1147/JRD.2017.2708299)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=IEEE%20Xplore&title=Deep%20learning%20ensembles%20for%20melanoma%20recognition%20in%20dermoscopy%20images&author=N.C.%20Codella&author=Q.B.%20Nguyen&author=S.%20Pankanti&author=D.A.%20Gutman&author=B.%20Helba&volume=61&publication_year=2017&pages=5:1-5:15&doi=10.1147/JRD.2017.2708299&)\]
- 29.Amin J., Sharif A., Gul N., Anjum M.A., Nisar M.W., Azam F., Bukhari S.A.C. Integrated design of deep features fusion for localization and classification of skin cancer. Pattern Recognit. Lett. 2020;131:63–70. doi: 10.1016/j.patrec.2019.11.042. \[ [DOI](https://doi.org/10.1016/j.patrec.2019.11.042)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Pattern%20Recognit.%20Lett.&title=Integrated%20design%20of%20deep%20features%20fusion%20for%20localization%20and%20classification%20of%20skin%20cancer&author=J.%20Amin&author=A.%20Sharif&author=N.%20Gul&author=M.A.%20Anjum&author=M.W.%20Nisar&volume=131&publication_year=2020&pages=63-70&doi=10.1016/j.patrec.2019.11.042&)\]
- 30.Thomas S.M., Lefevre J.G., Baxter G., Hamilton N.A. Interpretable deep learning systems for multi-class segmentation and classification of non-melanoma skin cancer. Med. Image Anal. 2021;68:101915. doi: 10.1016/j.media.2020.101915. \[ [DOI](https://doi.org/10.1016/j.media.2020.101915)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/33260112/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Med.%20Image%20Anal.&title=Interpretable%20deep%20learning%20systems%20for%20multi-class%20segmentation%20and%20classification%20of%20non-melanoma%20skin%20cancer&author=S.M.%20Thomas&author=J.G.%20Lefevre&author=G.%20Baxter&author=N.A.%20Hamilton&volume=68&publication_year=2021&pages=101915&pmid=33260112&doi=10.1016/j.media.2020.101915&)\]
- 31.Al-Masni M.A., Kim D.H., Kim T.S. Multiple skin lesions diagnostics via integrated deep convolutional networks for segmentation and classification. Comput. Methods Programs Biomed. 2020;190:105351. doi: 10.1016/j.cmpb.2020.105351. \[ [DOI](https://doi.org/10.1016/j.cmpb.2020.105351)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/32028084/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Comput.%20Methods%20Programs%20Biomed.&title=Multiple%20skin%20lesions%20diagnostics%20via%20integrated%20deep%20convolutional%20networks%20for%20segmentation%20and%20classification&author=M.A.%20Al-Masni&author=D.H.%20Kim&author=T.S.%20Kim&volume=190&publication_year=2020&pages=105351&pmid=32028084&doi=10.1016/j.cmpb.2020.105351&)\]
- 32.El-Khatib H., Popescu D., Ichim L. Deep Learning–Based Methods for Automatic Diagnosis of Skin Lesions. Sensors. 2020;20:1753. doi: 10.3390/s20061753. \[ [DOI](https://doi.org/10.3390/s20061753)\] \[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC7147720/)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/32245258/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Sensors&title=Deep%20Learning%E2%80%93Based%20Methods%20for%20Automatic%20Diagnosis%20of%20Skin%20Lesions&author=H.%20El-Khatib&author=D.%20Popescu&author=L.%20Ichim&volume=20&publication_year=2020&pages=1753&pmid=32245258&doi=10.3390/s20061753&)\]
- 33. \[(accessed on 12 March 2024)\]. Available online: [https://www.kaggle.com/datasets/ismailpromus/skin-diseases-image-dataset](https://www.kaggle.com/datasets/ismailpromus/skin-diseases-image-dataset).
- 34.Tschandl P. The HAM10000 Dataset, a Large Collection of Multi-Source Dermatoscopic Images of Common Pigmented Skin Lesions. Harvard Dataverse; Cambridge, MA, USA: 2018.  \[ [DOI](https://doi.org/10.7910/DVN/DBW86T)\] \[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC6091241/)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/30106392/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=The%20HAM10000%20Dataset,%20a%20Large%20Collection%20of%20Multi-Source%20Dermatoscopic%20Images%20of%20Common%20Pigmented%20Skin%20Lesions&author=P.%20Tschandl&publication_year=2018&)\]
- 35.Ahrari A., Elsayed S., Sarker R., Essam D., Coello C.A.C. Revisiting Implicit and Explicit Averaging for Noisy Optimization. IEEE Trans. Evol. Comput. 2023;27:1250–1259. doi: 10.1109/TEVC.2022.3201090. \[ [DOI](https://doi.org/10.1109/TEVC.2022.3201090)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Evol.%20Comput.&title=Revisiting%20Implicit%20and%20Explicit%20Averaging%20for%20Noisy%20Optimization&author=A.%20Ahrari&author=S.%20Elsayed&author=R.%20Sarker&author=D.%20Essam&author=C.A.C.%20Coello&volume=27&publication_year=2023&pages=1250-1259&doi=10.1109/TEVC.2022.3201090&)\]
- 36.Beliakov G., Sola H.B., Sánchez T.C. A Practical Guide to Averaging Functions. Volume 329 Springer International Publishing; Cham, Switzerland: 2016.  \[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=A%20Practical%20Guide%20to%20Averaging%20Functions&author=G.%20Beliakov&author=H.B.%20Sola&author=T.C.%20S%C3%A1nchez&publication_year=2016&)\]
- 37.Metta C., Beretta A., Guidotti R., Yin Y., Gallinari P., Rinzivillo S., Giannotti F. Advancing Dermatological Diagnostics: Interpretable AI for Enhanced Skin Lesion Classification. Diagnostics. 2024;14:753. doi: 10.3390/diagnostics14070753. \[ [DOI](https://doi.org/10.3390/diagnostics14070753)\] \[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC11011805/)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/38611666/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Diagnostics&title=Advancing%20Dermatological%20Diagnostics:%20Interpretable%20AI%20for%20Enhanced%20Skin%20Lesion%20Classification&author=C.%20Metta&author=A.%20Beretta&author=R.%20Guidotti&author=Y.%20Yin&author=P.%20Gallinari&volume=14&publication_year=2024&pages=753&pmid=38611666&doi=10.3390/diagnostics14070753&)\]
- 38.Polat K., Kaan O.K. Detection of skin diseases from dermoscopy image using the combination of convolutional neural network and one-versus-all. J. Artif. Intell. Syst. 2020;2:80–97. doi: 10.33969/AIS.2020.21006. \[ [DOI](https://doi.org/10.33969/AIS.2020.21006)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=J.%20Artif.%20Intell.%20Syst.&title=Detection%20of%20skin%20diseases%20from%20dermoscopy%20image%20using%20the%20combination%20of%20convolutional%20neural%20network%20and%20one-versus-all&author=K.%20Polat&author=O.K.%20Kaan&volume=2&publication_year=2020&pages=80-97&doi=10.33969/AIS.2020.21006&)\]
- 39.Shanthi T., Sabeenian R.S., Anand R. Automatic diagnosis of skin diseases using convolution neural network. Microprocess. Microsyst. 2020;76:103074. doi: 10.1016/j.micpro.2020.103074. \[ [DOI](https://doi.org/10.1016/j.micpro.2020.103074)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Microprocess.%20Microsyst.&title=Automatic%20diagnosis%20of%20skin%20diseases%20using%20convolution%20neural%20network&author=T.%20Shanthi&author=R.S.%20Sabeenian&author=R.%20Anand&volume=76&publication_year=2020&pages=103074&doi=10.1016/j.micpro.2020.103074&)\]
- 40.Kaur R., GholamHosseini H., Sinha R., Lindén M. Melanoma classification using a novel deep convolutional neural network with dermoscopic images. Sensors. 2022;22:1134. doi: 10.3390/s22031134. \[ [DOI](https://doi.org/10.3390/s22031134)\] \[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC8838143/)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/35161878/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Sensors&title=Melanoma%20classification%20using%20a%20novel%20deep%20convolutional%20neural%20network%20with%20dermoscopic%20images&author=R.%20Kaur&author=H.%20GholamHosseini&author=R.%20Sinha&author=M.%20Lind%C3%A9n&volume=22&publication_year=2022&pages=1134&pmid=35161878&doi=10.3390/s22031134&)\]
- 41.Zhang L., Yang W., Chen Y. ResNet and SVM for skin disease classification on DermNet dataset with data augmentation. Appl. Soft. Comput. 2022;121:108728. \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Appl.%20Soft.%20Comput.&title=ResNet%20and%20SVM%20for%20skin%20disease%20classification%20on%20DermNet%20dataset%20with%20data%20augmentation&author=L.%20Zhang&author=W.%20Yang&author=Y.%20Chen&volume=121&publication_year=2022&pages=108728&)\]
- 42.Yu H.Q., Reiff-Marganiec S. Targeted ensemble machine classification approach for supporting IoT enabled skin disease detection. IEEE Access. 2021;9:50244–50252. doi: 10.1109/ACCESS.2021.3069024. \[ [DOI](https://doi.org/10.1109/ACCESS.2021.3069024)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=IEEE%20Access&title=Targeted%20ensemble%20machine%20classification%20approach%20for%20supporting%20IoT%20enabled%20skin%20disease%20detection&author=H.Q.%20Yu&author=S.%20Reiff-Marganiec&volume=9&publication_year=2021&pages=50244-50252&doi=10.1109/ACCESS.2021.3069024&)\]
- 43.Xin C., Liu Z., Zhao K., Miao L., Ma Y., Zhu X., Zhou Q., Wang S., Li L., Yang F., et al. An improved transformer network for skin cancer classification. Comput. Biol. Med. 2022;149:105939. doi: 10.1016/j.compbiomed.2022.105939. \[ [DOI](https://doi.org/10.1016/j.compbiomed.2022.105939)\] \[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/36037629/)\] \[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Comput.%20Biol.%20Med.&title=An%20improved%20transformer%20network%20for%20skin%20cancer%20classification&author=C.%20Xin&author=Z.%20Liu&author=K.%20Zhao&author=L.%20Miao&author=Y.%20Ma&volume=149&publication_year=2022&pages=105939&pmid=36037629&doi=10.1016/j.compbiomed.2022.105939&)\]

## Associated Data

_This section collects any data citations, data availability statements, or supplementary materials included in this article._

### Data Availability Statement

The original contributions presented in the study are included in the article; further inquiries can be directed to the corresponding author.

![Close](https://pmc.ncbi.nlm.nih.gov/static/img/usa-icons/close.svg)

## ACTIONS

- [View on publisher site](https://doi.org/10.3390/bioengineering12030275)
- [PDF (7.1 MB)](https://pmc.ncbi.nlm.nih.gov/articles/PMC11939559/pdf/bioengineering-12-00275.pdf)
- Cite
- Collections
- Permalink




## PERMALINK



Copy


## RESOURCES

### Similar articles

### Cited by other articles

### Links to NCBI Databases

Back to Top

---

## Content Analysis Summary

- **Total Sources Processed:** 4
- **Average Content Length:** 37,159 characters
- **Content Types Found:** Plain Text, Tables
